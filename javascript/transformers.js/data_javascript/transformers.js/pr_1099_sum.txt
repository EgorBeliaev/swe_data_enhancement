The PR titled "Add support for Moonshine ASR" introduces support for the Moonshine family of speech-to-text models, optimized for automatic speech recognition on resource-constrained devices. This is particularly suitable for live transcription and voice command recognition in real-time, on-device, and in-browser applications. The PR employs a development branch of Transformers and Optimum for ONNX conversion.

**Instructions:**

1. Integrate Moonshine ASR models into the repository for speech-to-text processing:
   - Ensure compatibility with both pipeline and non-pipeline APIs.
   
2. In the pipeline API example, demonstrate how to use the `onnx-community/moonshine-tiny-ONNX` model:
   - Provide a JavaScript snippet of speech-to-text transcription from an audio source.

3. For non-pipeline API usage:
   - Demonstrate loading and using the `MoonshineForConditionalGeneration` model and `AutoProcessor`.
   - Show loading of audio and generation of text output, with batch decoding excluding special tokens.

4. Update documentation and ensure it reflects the changes, accessible via [this link](https://moon-ci-docs.huggingface.co/docs/transformers.js/pr_1099), available until 30 days post the last update.

5. Verify Moonshine ASR model functionality for both standard usage and WebGPU adaptation, as noted by its application in a real-time demo. Ensure it performs faster than the existing whisper version.

6. Close issue #990 upon the successful integration and verification of these changes.