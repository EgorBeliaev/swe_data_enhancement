[
    {
        "title": "Add support for grounding dino"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "**Example:** Zero-shot object detection with `onnx-community/grounding-dino-tiny-ONNX` using the `pipeline` API.\r\n```js\r\nimport { pipeline } from \"@huggingface/transformers\";\r\n\r\nconst detector = await pipeline(\"zero-shot-object-detection\", \"onnx-community/grounding-dino-tiny-ONNX\");\r\n\r\nconst url = \"http://images.cocodataset.org/val2017/000000039769.jpg\";\r\nconst candidate_labels = [\"a cat.\"];\r\nconst output = await detector(url, candidate_labels, {\r\n  threshold: 0.3,\r\n});\r\n```\r\n\r\n\r\n<details>\r\n\r\n<summary>See example output</summary>\r\n\r\n```\r\n[\r\n  { score: 0.45316222310066223, label: \"a cat\", box: { xmin: 343, ymin: 23, xmax: 637, ymax: 372 } },\r\n  { score: 0.36190420389175415, label: \"a cat\", box: { xmin: 12, ymin: 52, xmax: 317, ymax: 472 } },\r\n]\r\n```\r\n\r\n</details>\r\n\r\n\r\n**Example:** Zero-shot object detection with `onnx-community/grounding-dino-tiny-ONNX` using the `AutoModel` API.\r\n```js\r\nimport { AutoModelForZeroShotObjectDetection, AutoProcessor, load_image } from \"@huggingface/transformers\";\r\n\r\n// Load model and processor\r\nconst model_id = \"onnx-community/grounding-dino-tiny-ONNX\";\r\nconst processor = await AutoProcessor.from_pretrained(model_id);\r\nconst model = await AutoModelForZeroShotObjectDetection.from_pretrained(model_id, { dtype: \"fp32\" });\r\n\r\n// Prepare image and text inputs\r\nconst image = await load_image(\"http://images.cocodataset.org/val2017/000000039769.jpg\");\r\nconst text = \"a cat.\"; // NB: text query needs to be lowercased + end with a dot\r\n\r\n// Preprocess image and text\r\nconst inputs = await processor(image, text);\r\n\r\n// Run model\r\nconst outputs = await model(inputs);\r\n\r\n// Post-process outputs\r\nconst results = processor.post_process_grounded_object_detection(\r\n  outputs,\r\n  inputs.input_ids,\r\n  {\r\n    box_threshold: 0.3,\r\n    text_threshold: 0.3,\r\n    target_sizes: [image.size.reverse()],\r\n  },\r\n);\r\nconsole.log(results);\r\n```\r\n\r\n<details>\r\n\r\n<summary>See example output</summary>\r\n\r\n```\r\n[\r\n  {\r\n    scores: [ 0.45316222310066223, 0.36190420389175415 ],\r\n    boxes: [\r\n      [ 343.7238121032715, 23.02229404449463, 637.0737648010254, 372.6510000228882 ],\r\n      [ 12.311229705810547, 52.27128982543945, 317.4389839172363, 472.60459899902344 ]\r\n    ],\r\n    labels: [ 'a cat', 'a cat' ]\r\n  }\r\n]\r\n```\r\n\r\n</details>\r\n"
    },
    {
        "author": {
            "login": "HuggingFaceDocBuilderDev"
        },
        "body": "The docs for this PR live [here](https://moon-ci-docs.huggingface.co/docs/transformers.js/pr_1137). All of your documentation changes will be reflected on that endpoint. The docs are available until 30 days after the last update."
    },
    {
        "author": {
            "login": "sabman"
        },
        "body": "Nice can't wait to try it... were you planning to add tests? If so I can have a crack at it too."
    },
    {
        "author": {
            "login": "xenova"
        },
        "body": "Hey @sabman! \ud83d\udc4b I'm busy adding the final unit tests now :)"
    }
]