diff --git a/LLama.KernelMemory/BuilderExtensions.cs b/LLama.KernelMemory/BuilderExtensions.cs
index 30f678cd..3c230873 100644
--- a/LLama.KernelMemory/BuilderExtensions.cs
+++ b/LLama.KernelMemory/BuilderExtensions.cs
@@ -73,7 +73,6 @@ public static IKernelMemoryBuilder WithLLamaSharpDefaults(this IKernelMemoryBuil
             {
                 ContextSize = config.ContextSize ?? 2048,
                 GpuLayerCount = config.GpuLayerCount ?? 20,
-                Embeddings = true,
                 MainGpu = config.MainGpu,
                 SplitMode = config.SplitMode
             };
diff --git a/LLama.KernelMemory/LLamaSharp.KernelMemory.csproj b/LLama.KernelMemory/LLamaSharp.KernelMemory.csproj
index 250c4e57..1eb7426d 100644
--- a/LLama.KernelMemory/LLamaSharp.KernelMemory.csproj
+++ b/LLama.KernelMemory/LLamaSharp.KernelMemory.csproj
@@ -27,7 +27,7 @@
   </PropertyGroup>
 
   <ItemGroup>
-    <PackageReference Include="Microsoft.KernelMemory.Abstractions" Version="0.95.241216.1" />
+    <PackageReference Include="Microsoft.KernelMemory.Abstractions" Version="0.96.250120.1" />
   </ItemGroup>
 
   <ItemGroup>
diff --git a/LLama.KernelMemory/LlamaSharpTextGenerator.cs b/LLama.KernelMemory/LlamaSharpTextGenerator.cs
index 3fc96db9..db7f7444 100644
--- a/LLama.KernelMemory/LlamaSharpTextGenerator.cs
+++ b/LLama.KernelMemory/LlamaSharpTextGenerator.cs
@@ -1,6 +1,7 @@
 using LLama;
 using LLama.Common;
 using LLama.Sampling;
+using Microsoft.KernelMemory;
 using Microsoft.KernelMemory.AI;
 
 namespace LLamaSharp.KernelMemory
@@ -73,9 +74,11 @@ public void Dispose()
         }
 
         /// <inheritdoc/>
-        public IAsyncEnumerable<string> GenerateTextAsync(string prompt, TextGenerationOptions options, CancellationToken cancellationToken = default)
+        public IAsyncEnumerable<GeneratedTextContent> GenerateTextAsync(string prompt, TextGenerationOptions options, CancellationToken cancellationToken = default)
         {
-            return _executor.InferAsync(prompt, OptionsToParams(options, _defaultInferenceParams), cancellationToken: cancellationToken);
+            return _executor
+                  .InferAsync(prompt, OptionsToParams(options, _defaultInferenceParams), cancellationToken: cancellationToken)
+                  .Select(a => new GeneratedTextContent(a));
         }
 
         private static InferenceParams OptionsToParams(TextGenerationOptions options, InferenceParams? defaultParams)
