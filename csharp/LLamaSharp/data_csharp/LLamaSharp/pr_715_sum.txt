**Instructions for Changes:**

1. **Add LLamaTemplate Class:** Implement the `LLamaTemplate` class to efficiently format a series of messages according to the model template.

2. **Fix Method:** Correct the `llama_chat_apply_template` method which currently has an incorrect entry point and cannot handle null models.

3. **Rebase and Merge:** This PR has been rebased on the master and can be merged independently of PR #712, which is expected to be delayed.

4. **Tokenization Enhancement (Discussion Point):** Consider a future enhancement where text tokenization is handled differently for different parts of the template. Specifically, ensure that template-specific tokenization (`special=true`) does not apply to user messages to avoid unintended formatting issues. This change is not required in this PR but might be a future consideration for llama.cpp enhancements.