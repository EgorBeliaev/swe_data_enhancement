[
    {
        "title": "BatchedExecutor LLava"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "Added support for embeddings prompting to `BatchedExecutor`, allowing support for Llava!\r\n\r\n - Switched batch queue in `BatchedExecutor` to have 2 possible types - token batches and embeddings batches.\r\n - Switched inference lock to a integer using Interlocked, this interacts better with async.\r\n - Added `Conversation.Prompt` method for `Span<float>` (raw embeddings) and `SafeLlavaImageEmbedHandle`.\r\n - Added `LLamaBatchEmbeddings`, equivalent to `LLamaBatch` for embeddings instead of for tokens.\r\n\r\n<img width=\"750\" alt=\"VsDebugConsole_2024-05-30_19-33-38\" src=\"https://github.com/SciSharp/LLamaSharp/assets/177519/3823632d-b39d-4bf0-a352-9fc957888f53\">\r\n"
    },
    {
        "author": {
            "login": "SignalRT"
        },
        "body": ""
    },
    {
        "author": {
            "login": "SignalRT"
        },
        "body": "@martindevans, The PR seems ok for me. \r\n\r\nNot related with this PR and more generally speaking is hard to me to have an \"Executor\" that doesn't implement the ILlamaExecutor interface. If seems to be a lower level of abstraction that ILlamaExecutor and more difficult to use for the final user.\r\n\r\n\r\n"
    },
    {
        "author": {
            "login": "martindevans"
        },
        "body": "> Not related with this PR and more generally speaking is hard to me to have an \"Executor\" that doesn't implement the ILlamaExecutor interface. If seems to be a lower level of abstraction that ILlamaExecutor and more difficult to use for the final user.\r\n\r\nRinne had the same issue too. It is a lower level of abstraction, intended as the new foundation that high level executors (replacements for the current ones) can be built on. Since you've both been confused by this, any ideas for better names?"
    }
]