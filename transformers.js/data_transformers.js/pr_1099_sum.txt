**Instructions for Changes:**

1. **Add Support for Moonshine ASR Models:**
   - Integrate the Moonshine family of speech-to-text models optimized for resource-constrained devices.
   - Ensure compatibility with live transcription and voice command recognition, with a focus on in-browser use.

2. **Utilize Development Branch Dependencies:**
   - Use the development branch of Transformers (by @eustlb) and Optimum for ONNX conversion.

3. **ONNX Model Integration:**
   - Include ONNX models:
     - `moonshine-tiny-ONNX` from [Hugging Face](https://huggingface.co/onnx-community/moonshine-tiny-ONNX).
     - `moonshine-base-ONNX` from [Hugging Face](https://huggingface.co/onnx-community/moonshine-base-ONNX).

4. **Example Usage Implementation:**
   - Provide examples for both pipeline API and non-pipeline API usage.
   - Verify script compatibility for translating audio input to text output as demonstrated.

5. **Add Documentation:**
   - Ensure documentation is live and up-to-date as referenced [here](https://moon-ci-docs.huggingface.co/docs/transformers.js/pr_1099).

6. **Real-Time WebGPU Demo:**
   - Adapt the model to work with WebGPU and ensure it is significantly faster compared to existing Whisper versions, referencing the demo [here](https://huggingface.co/spaces/Xenova/realtime-whisper-webgpu).

This PR closes issue #990 and improves real-time ASR applications.