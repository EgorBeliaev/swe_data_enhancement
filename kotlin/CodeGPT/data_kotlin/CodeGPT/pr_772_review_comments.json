[
    {
        "title": "Use the Ollama generate API for FIM templates"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "The Ollama `/api/generate` API supports prefix + suffix now, let's use that.\r\n\r\nNote that there isn't currently a proper API for context files, I opened https://github.com/ollama/ollama/issues/7738 off the back of this.\r\nFor now, I have hardcoded the deepseek-coder context format, and it seems to work OK across codeqwen2.5 and deepseek-coder, though it's probably not ideal\r\n\r\nWaiting for https://github.com/carlrobertoh/CodeGPT/pull/771"
    },
    {
        "author": {
            "login": "carlrobertoh"
        },
        "body": ""
    },
    {
        "author": {
            "login": "carlrobertoh"
        },
        "body": "It looks like none of the models I previously downloaded support this new logic (except the models you listed). Could we keep the FIM template configuration and make it optional instead?\r\n\r\nWith this, we can also support repository-level completions before they implement it on their end."
    },
    {
        "author": {
            "login": "boswelja"
        },
        "body": "Seems reasonable - it's probably a good idea to also open an issue with ollama for those models, since it sounds like they're not retroactively updating model templates"
    }
]