[
    {
        "title": "Enable vision support in GUI for Azure models (Issue #649)"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "This enables vision support in the GUI as discussed in #649.\r\n\r\nI tested it with a model that supports vision (gpt-4o) as well as with one that does not (gpt-4-32k).\r\n\r\nThe resulting behaviour is attached in screenshots.\r\n\r\n![non-vision-azure-model](https://github.com/user-attachments/assets/900127a7-f037-4344-b57e-ccfc47fa3409)\r\n![vision-azure-model](https://github.com/user-attachments/assets/b6c8f3c5-6214-4e5e-b1df-a4dcd972a72d)\r\n"
    },
    {
        "data": {
            "repository": {
                "issue": {
                    "title": "Vision support across OpenAI-Style-Providers (e.g. Azure, Custon OpenAI endpoint)",
                    "body": "### Describe the need of your request\r\n\r\nModels with vision support are becoming more common but as of now, you can only use vision with OpenAI and Claude in CodeGPT.\r\n\r\nIt would be nice to enable Vision support for other models as well.\r\n\r\n### Proposed solution\r\n\r\nWhen configuring models for other providers, add a checkbox for enabling vision support on the configured model.\r\n\r\nNot all models support vision and therefore it makes sense to configure the support directly with the model.\r\n\r\nAlternative: just enable vision support everywhere, where llm-client would support API-requests that support vision. The REST-Endpoint should respond with a suitable error/warning message.\r\n\r\n### Additional context\r\n\r\nI am willing to work on this issue if it is clear how you want it to be configurable in the settings/UI.",
                    "state": "CLOSED",
                    "comments": {
                        "nodes": [
                            {
                                "author": {
                                    "login": "carlrobertoh"
                                },
                                "body": "If we're just talking about vision support through OpenAI API-compatible providers, then no additional UI changes are required. The image action must be allowed for Azure and Custom OpenAI providers ([ServiceType.java:L68](https://github.com/carlrobertoh/CodeGPT/blob/master/src/main/java/ee/carlrobert/codegpt/settings/service/ServiceType.java#L68)), and then the actual API request must be configured accordingly (this might already come out-of-the-box)."
                            },
                            {
                                "author": {
                                    "login": "moritzfl"
                                },
                                "body": "Good to know - I guess it would have helped to inspect the code.\r\n\r\n~~I tried GPT-4-Turbo before with Azure as well as a custom OpenAI provider (openrouter) and that seems to be the one model that is missing from the list of supported models (\"GPT-4o, GPT-4o mini, and GPT-4 Turbo have vision capabilities\" - see https://platform.openai.com/docs/guides/vision).~~\r\n\r\n~~If I am not mistaken, Azure is only covered by the \"default\" part of the switch-case and thus is not supported for vision at all in CodeGPT.~~\r\n\r\nEDIT: Nevermind - you were just giving hints towards the implementation while I initially thought you meant that a part of this issue is already covered  ... thanks \ud83d\udc4d "
                            },
                            {
                                "author": {
                                    "login": "n0isy"
                                },
                                "body": "@carlrobertoh Can you add an option to force switch ON, switch OFF, or AUTO current code in ([ServiceType.java:L68](https://github.com/carlrobertoh/CodeGPT/blob/master/src/main/java/ee/carlrobert/codegpt/settings/service/ServiceType.java#L68)) ?\r\n\r\nI use custom enterprise proxy (endpoint + auth headers) to openai with image support."
                            },
                            {
                                "author": {
                                    "login": "moritzfl"
                                },
                                "body": "You beat me to it - thanks! My slack day is next week :)\r\n\r\nGiven that you can name models on Azure however you like, do you think it makes sense to just enable image support there globally in a similar fashion?\r\n\r\nAn alternative would be to enforce a naming scheme that is similar to OpenAI but given that Azure will mostly be used in companies, it might be a burden to convince everyone to stick to the naming scheme.\r\n\r\nIf you do not have an Azure Account, I can also test that for you (but then again - I did test llm-client for exactly that when implementing vision support there https://github.com/carlrobertoh/llm-client/pull/18). We also have a Zulip chatbot based on llm-client that is working fine with the Azure account."
                            },
                            {
                                "author": {
                                    "login": "carlrobertoh"
                                },
                                "body": "Yes, I think we should enable image support for all models provided on Azure, since it already comes with an OpenAI-compatible API and the existing functionality should be available out of the box.\r\n\r\n> An alternative would be to enforce a naming scheme that is similar to OpenAI but given that Azure will mostly be used in companies, it might be a burden to convince everyone to stick to the naming scheme.\r\n\r\nI don't believe the naming scheme is worth it. I haven't used Azure myself, but the models aren't global, right? Even if the underlying model might be the same, the name of the model (deployment name) might not be.\r\n\r\nHowever, I'm unsure what will happen if the model doesn't support images. Will it crash or simply ignore the image input? Then again, I didn't test this behaviour with the Custom OpenAI provider either, although this can be different from provider to provider."
                            },
                            {
                                "author": {
                                    "login": "moritzfl"
                                },
                                "body": "Yes, you can basically name models however you like. It seems natural to stick to the model names that OpenAI uses and we do that at our company - but that might not be the case everywhere.\r\n\r\nAnd one use-case for that might even be that you configure a resource once and migrate (i.e. delete the old resource, add the new model with the same name as before in your Azure account) to newer and newer models without any configuration change across the clients that use your API access."
                            }
                        ]
                    }
                }
            }
        }
    }
]