[
    {
        "title": "feat(chat-completions): Add Logprobs for ChatCompletions"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "| Q                 | A\r\n| ----------------- | ----------\r\n| Bug fix?          | no\r\n| New feature?      | yes\r\n| BC breaks?        | no\r\n| Related Issue     | Fix #326 \r\n\r\n## Describe your change\r\n\r\nWanted to be able to get the logprobs in the response from openai. It looks like its a non beta feature exposed in the chat completion object\r\n\r\nhttps://platform.openai.com/docs/api-reference/chat/object\r\n\r\nI've attempted to capture it as specified, and verified that top_logprobs is provided whether we do or do not limit how many are returned as denoted in the test.\r\n\r\n## What problem is this fixing?\r\n\r\nClosing the gap between what openai has exposed and what is supported.\r\n\r\nShould be resolving: https://github.com/aallam/openai-kotlin/issues/326"
    },
    {
        "author": {
            "login": "aallam"
        },
        "body": "Nice! thank you for your contribution!"
    },
    {
        "data": {
            "repository": {
                "issue": {
                    "title": "Logprobs are not exposed in chat completions",
                    "body": "### Feature Description\r\n\r\nLogprobs are not exposed in Chat completions but present in deprecated completions API, please see Open AI API documentation https://platform.openai.com/docs/api-reference/chat\r\n\r\n### Problem it Solves\r\n\r\nI don't see any current workaround, Logprobs solve a lot of problems, see for example https://cookbook.openai.com/examples/using_logprobs\r\n\r\n### Proposed Solution\r\n\r\nWe just need to expose `logprobs` in ChatCompletionRequest and response, similar to how it was done in CompletionRequest",
                    "state": "CLOSED",
                    "comments": {
                        "nodes": []
                    }
                }
            }
        }
    }
]