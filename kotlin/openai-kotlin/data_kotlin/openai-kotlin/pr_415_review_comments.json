[
    {
        "title": "Add reasoning effort, max completion tokens, store options for reasoning model support"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "| Q                 | A\r\n| ----------------- | ----------\r\n| Bug fix?          | no\r\n| New feature?      | yes    <!-- please update the /CHANGELOG.md file -->\r\n| BC breaks?        | no\r\n| Related Issue     | Fix #...  <!-- will close issue automatically, if any -->\r\n\r\n## Describe your change\r\n\r\n`o3-mini` was released yesterday, and there are several changes to the API.\r\n\r\n- Added `reasoning_effort` parameter: This is used to give the model guidance on how many reasoning tokens it should generate before creating a response to the prompt. See [here](https://platform.openai.com/docs/guides/reasoning#reasoning-effort) for more information.\r\n- Deprecated `max_tokens` and add `max_completion_tokens`: This parameter is no longer supported in reasoning models.  See [here](https://platform.openai.com/docs/api-reference/chat/create#chat-create-max_tokens) for more information.\r\n- Add `store` parameter: Option to store the output of chat completion request. See [here](https://platform.openai.com/docs/api-reference/chat/create#chat-create-store)\r\n\r\n## What problem is this fixing?\r\n\r\nThis is to add support to modify options regarding the reasoning models."
    },
    {
        "author": {
            "login": "aallam"
        },
        "body": ""
    },
    {
        "author": {
            "login": "aallam"
        },
        "body": "thank you for your contribution!"
    }
]