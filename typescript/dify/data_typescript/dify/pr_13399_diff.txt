diff --git a/api/core/model_runtime/model_providers/google/llm/_position.yaml b/api/core/model_runtime/model_providers/google/llm/_position.yaml
index 07ede384b0b33c..2b865834e1567a 100644
--- a/api/core/model_runtime/model_providers/google/llm/_position.yaml
+++ b/api/core/model_runtime/model_providers/google/llm/_position.yaml
@@ -1,5 +1,6 @@
 - gemini-2.0-flash-001
 - gemini-2.0-flash-exp
+- gemini-2.0-flash-lite-preview-02-05
 - gemini-2.0-pro-exp-02-05
 - gemini-2.0-flash-thinking-exp-1219
 - gemini-2.0-flash-thinking-exp-01-21
diff --git a/api/core/model_runtime/model_providers/google/llm/gemini-2.0-flash-lite-preview-02-05.yaml b/api/core/model_runtime/model_providers/google/llm/gemini-2.0-flash-lite-preview-02-05.yaml
new file mode 100644
index 00000000000000..9c0a1e0620cb17
--- /dev/null
+++ b/api/core/model_runtime/model_providers/google/llm/gemini-2.0-flash-lite-preview-02-05.yaml
@@ -0,0 +1,41 @@
+model: gemini-2.0-flash-lite-preview-02-05
+label:
+  en_US: Gemini 2.0 Flash Lite Preview 0205
+model_type: llm
+features:
+  - agent-thought
+  - vision
+  - tool-call
+  - stream-tool-call
+  - document
+  - video
+  - audio
+model_properties:
+  mode: chat
+  context_size: 1048576
+parameter_rules:
+  - name: temperature
+    use_template: temperature
+  - name: top_p
+    use_template: top_p
+  - name: top_k
+    label:
+      zh_Hans: 取样数量
+      en_US: Top k
+    type: int
+    help:
+      zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
+      en_US: Only sample from the top K options for each subsequent token.
+    required: false
+  - name: max_output_tokens
+    use_template: max_tokens
+    default: 8192
+    min: 1
+    max: 8192
+  - name: json_schema
+    use_template: json_schema
+pricing:
+  input: '0.00'
+  output: '0.00'
+  unit: '0.000001'
+  currency: USD
