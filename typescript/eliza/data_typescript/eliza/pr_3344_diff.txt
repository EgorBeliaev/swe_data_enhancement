diff --git a/agent/src/index.ts b/agent/src/index.ts
index e68a123de8c..97ee66c2e14 100644
--- a/agent/src/index.ts
+++ b/agent/src/index.ts
@@ -967,7 +967,7 @@ export async function createAgent(
     //     elizaLogger.log("Verifiable inference adapter initialized");
     // }
     // Initialize Opacity adapter if environment variables are present
-    let verifiableInferenceAdapter = null;
+    // let verifiableInferenceAdapter = null;
     // if (
     //     process.env.OPACITY_TEAM_ID &&
     //     process.env.OPACITY_CLOUDFLARE_NAME &&
@@ -1017,7 +1017,7 @@ export async function createAgent(
         providers: [],
         managers: [],
         fetch: logFetch,
-        verifiableInferenceAdapter,
+        // verifiableInferenceAdapter,
     });
 }
 
diff --git a/packages/core/src/generation.ts b/packages/core/src/generation.ts
index 07a45ad0bf3..a46f1ad2076 100644
--- a/packages/core/src/generation.ts
+++ b/packages/core/src/generation.ts
@@ -43,9 +43,9 @@ import {
     ModelProviderName,
     ServiceType,
     type ActionResponse,
-    type IVerifiableInferenceAdapter,
-    type VerifiableInferenceOptions,
-    type VerifiableInferenceResult,
+    // type IVerifiableInferenceAdapter,
+    // type VerifiableInferenceOptions,
+    // type VerifiableInferenceResult,
     //VerifiableInferenceProvider,
     type TelemetrySettings,
     TokenizerType,
@@ -347,8 +347,8 @@ export async function generateText({
     maxSteps = 1,
     stop,
     customSystemPrompt,
-    verifiableInference = process.env.VERIFIABLE_INFERENCE_ENABLED === "true",
-    verifiableInferenceOptions,
+    // verifiableInference = process.env.VERIFIABLE_INFERENCE_ENABLED === "true",
+    // verifiableInferenceOptions,
 }: {
     runtime: IAgentRuntime;
     context: string;
@@ -358,9 +358,9 @@ export async function generateText({
     maxSteps?: number;
     stop?: string[];
     customSystemPrompt?: string;
-    verifiableInference?: boolean;
-    verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
-    verifiableInferenceOptions?: VerifiableInferenceOptions;
+    // verifiableInference?: boolean;
+    // verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
+    // verifiableInferenceOptions?: VerifiableInferenceOptions;
 }): Promise<string> {
     if (!context) {
         console.error("generateText context is empty");
@@ -372,36 +372,36 @@ export async function generateText({
     elizaLogger.info("Generating text with options:", {
         modelProvider: runtime.modelProvider,
         model: modelClass,
-        verifiableInference,
+        // verifiableInference,
     });
     elizaLogger.log("Using provider:", runtime.modelProvider);
     // If verifiable inference is requested and adapter is provided, use it
-    if (verifiableInference && runtime.verifiableInferenceAdapter) {
-        elizaLogger.log(
-            "Using verifiable inference adapter:",
-            runtime.verifiableInferenceAdapter
-        );
-        try {
-            const result: VerifiableInferenceResult =
-                await runtime.verifiableInferenceAdapter.generateText(
-                    context,
-                    modelClass,
-                    verifiableInferenceOptions
-                );
-            elizaLogger.log("Verifiable inference result:", result);
-            // Verify the proof
-            const isValid =
-                await runtime.verifiableInferenceAdapter.verifyProof(result);
-            if (!isValid) {
-                throw new Error("Failed to verify inference proof");
-            }
-
-            return result.text;
-        } catch (error) {
-            elizaLogger.error("Error in verifiable inference:", error);
-            throw error;
-        }
-    }
+    // if (verifiableInference && runtime.verifiableInferenceAdapter) {
+    //     elizaLogger.log(
+    //         "Using verifiable inference adapter:",
+    //         runtime.verifiableInferenceAdapter
+    //     );
+    //     try {
+    //         const result: VerifiableInferenceResult =
+    //             await runtime.verifiableInferenceAdapter.generateText(
+    //                 context,
+    //                 modelClass,
+    //                 verifiableInferenceOptions
+    //             );
+    //         elizaLogger.log("Verifiable inference result:", result);
+    //         // Verify the proof
+    //         const isValid =
+    //             await runtime.verifiableInferenceAdapter.verifyProof(result);
+    //         if (!isValid) {
+    //             throw new Error("Failed to verify inference proof");
+    //         }
+
+    //         return result.text;
+    //     } catch (error) {
+    //         elizaLogger.error("Error in verifiable inference:", error);
+    //         throw error;
+    //     }
+    // }
 
     const provider = runtime.modelProvider;
     elizaLogger.debug("Provider settings:", {
@@ -2050,9 +2050,9 @@ export interface GenerationOptions {
     stop?: string[];
     mode?: "auto" | "json" | "tool";
     experimental_providerMetadata?: Record<string, unknown>;
-    verifiableInference?: boolean;
-    verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
-    verifiableInferenceOptions?: VerifiableInferenceOptions;
+    // verifiableInference?: boolean;
+    // verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
+    // verifiableInferenceOptions?: VerifiableInferenceOptions;
 }
 
 /**
@@ -2084,9 +2084,9 @@ export const generateObject = async ({
     schemaDescription,
     stop,
     mode = "json",
-    verifiableInference = false,
-    verifiableInferenceAdapter,
-    verifiableInferenceOptions,
+    // verifiableInference = false,
+    // verifiableInferenceAdapter,
+    // verifiableInferenceOptions,
 }: GenerationOptions): Promise<GenerateObjectResult<unknown>> => {
     if (!context) {
         const errorMessage = "generateObject context is empty";
@@ -2130,9 +2130,9 @@ export const generateObject = async ({
             runtime,
             context,
             modelClass,
-            verifiableInference,
-            verifiableInferenceAdapter,
-            verifiableInferenceOptions,
+            // verifiableInference,
+            // verifiableInferenceAdapter,
+            // verifiableInferenceOptions,
         });
 
         return response;
@@ -2158,9 +2158,9 @@ interface ProviderOptions {
     modelOptions: ModelSettings;
     modelClass: ModelClass;
     context: string;
-    verifiableInference?: boolean;
-    verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
-    verifiableInferenceOptions?: VerifiableInferenceOptions;
+    // verifiableInference?: boolean;
+    // verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
+    // verifiableInferenceOptions?: VerifiableInferenceOptions;
 }
 
 /**
diff --git a/packages/core/src/runtime.ts b/packages/core/src/runtime.ts
index bddd1b547d3..9ca7e14729a 100644
--- a/packages/core/src/runtime.ts
+++ b/packages/core/src/runtime.ts
@@ -34,7 +34,7 @@ import {
     type IDatabaseAdapter,
     type IMemoryManager,
     type IRAGKnowledgeManager,
-    type IVerifiableInferenceAdapter,
+    // type IVerifiableInferenceAdapter,
     type KnowledgeItem,
     // RAGKnowledgeItem,
     //Media,
@@ -178,7 +178,7 @@ export class AgentRuntime implements IAgentRuntime {
     cacheManager: ICacheManager;
     clients: ClientInstance[] = [];
 
-    verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
+    // verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
 
     registerMemoryManager(manager: IMemoryManager): void {
         if (!manager.tableName) {
@@ -261,7 +261,7 @@ export class AgentRuntime implements IAgentRuntime {
         speechModelPath?: string;
         cacheManager?: ICacheManager;
         logging?: boolean;
-        verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
+        // verifiableInferenceAdapter?: IVerifiableInferenceAdapter;
     }) {
         // use the character id if it exists, otherwise use the agentId if it is passed in, otherwise use the character name
         this.agentId =
@@ -439,7 +439,7 @@ export class AgentRuntime implements IAgentRuntime {
             this.registerEvaluator(evaluator);
         });
 
-        this.verifiableInferenceAdapter = opts.verifiableInferenceAdapter;
+        // this.verifiableInferenceAdapter = opts.verifiableInferenceAdapter;
     }
 
     private async initializeDatabase() {
@@ -1138,7 +1138,7 @@ export class AgentRuntime implements IAgentRuntime {
             runtime: this,
             context,
             modelClass: ModelClass.SMALL,
-            verifiableInferenceAdapter: this.verifiableInferenceAdapter,
+            // verifiableInferenceAdapter: this.verifiableInferenceAdapter,
         });
 
         const evaluators = parseJsonArrayFromText(
@@ -1783,14 +1783,6 @@ Text: ${attachment.text}
             attachments: formattedAttachments,
         } as State;
     }
-
-    getVerifiableInferenceAdapter(): IVerifiableInferenceAdapter | undefined {
-        return this.verifiableInferenceAdapter;
-    }
-
-    setVerifiableInferenceAdapter(adapter: IVerifiableInferenceAdapter): void {
-        this.verifiableInferenceAdapter = adapter;
-    }
 }
 
 const formatKnowledge = (knowledge: KnowledgeItem[]) => {
diff --git a/packages/core/src/types.ts b/packages/core/src/types.ts
index 1c08f714797..37938448bc2 100644
--- a/packages/core/src/types.ts
+++ b/packages/core/src/types.ts
@@ -1297,7 +1297,7 @@ export interface IAgentRuntime {
     services: Map<ServiceType, Service>;
     clients: ClientInstance[];
 
-    verifiableInferenceAdapter?: IVerifiableInferenceAdapter | null;
+    // verifiableInferenceAdapter?: IVerifiableInferenceAdapter | null;
 
     initialize(): Promise<void>;
 
@@ -1569,68 +1569,68 @@ export interface ISlackService extends Service {
     client: any;
 }
 
-/**
- * Available verifiable inference providers
- */
-export enum VerifiableInferenceProvider {
-    RECLAIM = "reclaim",
-    OPACITY = "opacity",
-    PRIMUS = "primus",
-}
-
-/**
- * Options for verifiable inference
- */
-export interface VerifiableInferenceOptions {
-    /** Custom endpoint URL */
-    endpoint?: string;
-    /** Custom headers */
-    headers?: Record<string, string>;
-    /** Provider-specific options */
-    providerOptions?: Record<string, unknown>;
-}
-
-/**
- * Result of a verifiable inference request
- */
-export interface VerifiableInferenceResult {
-    /** Generated text */
-    text: string;
-    /** Proof */
-    proof: any;
-    /** Proof id */
-    id?: string;
-    /** Provider information */
-    provider: VerifiableInferenceProvider;
-    /** Timestamp */
-    timestamp: number;
-}
-
-/**
- * Interface for verifiable inference adapters
- */
-export interface IVerifiableInferenceAdapter {
-    options: any;
-    /**
-     * Generate text with verifiable proof
-     * @param context The input text/prompt
-     * @param modelClass The model class/name to use
-     * @param options Additional provider-specific options
-     * @returns Promise containing the generated text and proof data
-     */
-    generateText(
-        context: string,
-        modelClass: string,
-        options?: VerifiableInferenceOptions,
-    ): Promise<VerifiableInferenceResult>;
-
-    /**
-     * Verify the proof of a generated response
-     * @param result The result containing response and proof to verify
-     * @returns Promise indicating if the proof is valid
-     */
-    verifyProof(result: VerifiableInferenceResult): Promise<boolean>;
-}
+// /**
+//  * Available verifiable inference providers
+//  */
+// export enum VerifiableInferenceProvider {
+//     RECLAIM = "reclaim",
+//     OPACITY = "opacity",
+//     PRIMUS = "primus",
+// }
+
+// /**
+//  * Options for verifiable inference
+//  */
+// export interface VerifiableInferenceOptions {
+//     /** Custom endpoint URL */
+//     endpoint?: string;
+//     /** Custom headers */
+//     headers?: Record<string, string>;
+//     /** Provider-specific options */
+//     providerOptions?: Record<string, unknown>;
+// }
+
+// /**
+//  * Result of a verifiable inference request
+//  */
+// export interface VerifiableInferenceResult {
+//     /** Generated text */
+//     text: string;
+//     /** Proof */
+//     proof: any;
+//     /** Proof id */
+//     id?: string;
+//     /** Provider information */
+//     provider: VerifiableInferenceProvider;
+//     /** Timestamp */
+//     timestamp: number;
+// }
+
+// /**
+//  * Interface for verifiable inference adapters
+//  */
+// export interface IVerifiableInferenceAdapter {
+//     options: any;
+//     /**
+//      * Generate text with verifiable proof
+//      * @param context The input text/prompt
+//      * @param modelClass The model class/name to use
+//      * @param options Additional provider-specific options
+//      * @returns Promise containing the generated text and proof data
+//      */
+//     generateText(
+//         context: string,
+//         modelClass: string,
+//         options?: VerifiableInferenceOptions,
+//     ): Promise<VerifiableInferenceResult>;
+
+//     /**
+//      * Verify the proof of a generated response
+//      * @param result The result containing response and proof to verify
+//      * @returns Promise indicating if the proof is valid
+//      */
+//     verifyProof(result: VerifiableInferenceResult): Promise<boolean>;
+// }
 
 export enum TokenizerType {
     Auto = "auto",
