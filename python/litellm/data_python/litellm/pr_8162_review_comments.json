[
    {
        "title": "fix: support azure o3 model family for fake streaming workaround"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "## Support o3 model family for fake streaming workaround from Azure\r\n`o3-mini` is already available on Azure, but sadly it looks like it doesn't support streaming, just like the `o1` models.\r\n\r\nSo this PR updates the logic for the fake streaming workaround to also support the `o3` family. Note that there's a wider refactor to generalize the name of `AzureOpenAIO1Config` that I'm not making here.\r\n\r\n## Relevant issues\r\nFixes https://github.com/BerriAI/litellm/issues/8158\r\n<!-- e.g. \"Fixes #000\" -->\r\n\r\n## Type\r\n\ud83d\udc1b Bug Fix\r\n\r\n## Changes\r\n* Added `o3*` to the list of models for the Azure fake streaming workaround\r\n<!-- List of changes -->\r\n\r\n## [REQUIRED] Testing - Attach a screenshot of any new tests passing locally\r\nI didn't see any obvious tests in this area, so manually tested the fake streaming is now working with `o3-mini`, `o1-mini`, as well as non-streaming on `o3-mini`. Also validated that real streaming is still working with `gpt-4o`.\r\n\r\n"
    },
    {
        "author": {
            "login": "krrishdholakia"
        },
        "body": ""
    },
    {
        "author": {
            "login": "vercel"
        },
        "body": "[vc]: #3U1MyiqltiO6SfvIbMYjxsSocj3lQwzgJZSo9834HxU=:eyJpc01vbm9yZXBvIjp0cnVlLCJ0eXBlIjoiZ2l0aHViIiwicHJvamVjdHMiOlt7Im5hbWUiOiJsaXRlbGxtIiwicm9vdERpcmVjdG9yeSI6ImRvY3MvbXktd2Vic2l0ZSIsImluc3BlY3RvclVybCI6Imh0dHBzOi8vdmVyY2VsLmNvbS9jbGVya2llYWkvbGl0ZWxsbS9HMU5xNnZjU3lpVTNLVmlKdTdxQ3VDeWFqVnh6IiwicHJldmlld1VybCI6ImxpdGVsbG0tZ2l0LWZvcmstYnlyb25ncm9nYW4tbzMtbWluaS1henVyZS1mYWstOGI4MmRmLWNsZXJraWVhaS52ZXJjZWwuYXBwIiwibmV4dENvbW1pdFN0YXR1cyI6IkRFUExPWUVEIiwibGl2ZUZlZWRiYWNrIjp7InJlc29sdmVkIjowLCJ1bnJlc29sdmVkIjowLCJ0b3RhbCI6MCwibGluayI6ImxpdGVsbG0tZ2l0LWZvcmstYnlyb25ncm9nYW4tbzMtbWluaS1henVyZS1mYWstOGI4MmRmLWNsZXJraWVhaS52ZXJjZWwuYXBwIn19XX0=\n**The latest updates on your projects**. Learn more about [Vercel for Git \u2197\ufe0e](https://vercel.link/github-learn-more)\n\n| Name | Status | Preview | Comments | Updated (UTC) |\n| :--- | :----- | :------ | :------- | :------ |\n| **litellm** | \u2705 Ready ([Inspect](https://vercel.com/clerkieai/litellm/G1Nq6vcSyiU3KViJu7qCuCyajVxz)) | [Visit Preview](https://litellm-git-fork-byrongrogan-o3-mini-azure-fak-8b82df-clerkieai.vercel.app) | \ud83d\udcac [**Add feedback**](https://vercel.live/open-feedback/litellm-git-fork-byrongrogan-o3-mini-azure-fak-8b82df-clerkieai.vercel.app?via=pr-comment-feedback-link) | Feb 1, 2025 4:23pm |\n\n"
    },
    {
        "author": {
            "login": "krrishdholakia"
        },
        "body": "> I didn't see any obvious tests in this area\r\n\r\ntesting here @byrongrogan https://github.com/BerriAI/litellm/blob/d0c5639912581423728ce6bbf99543efc2c372f2/tests/llm_translation/test_azure_o1.py#L21\r\n\r\nthe basellmchattest goes through a series of common scenarios for the model \r\n\r\nit's fine - i can take care of this part, since this will probably require us to have an o3 deployment on azure "
    },
    {
        "data": {
            "repository": {
                "issue": null
            }
        },
        "errors": [
            {
                "type": "NOT_FOUND",
                "path": [
                    "repository",
                    "issue"
                ],
                "locations": [
                    {
                        "line": 4,
                        "column": 9
                    }
                ],
                "message": "Could not resolve to an Issue with the number of 0."
            }
        ]
    }
]