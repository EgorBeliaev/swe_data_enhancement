[
    {
        "title": "Fix Gemini bug when system role is provided"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "Gemini doesn't support role=system.\r\n\r\nWhen `\"SMART_LLM\": \"google_vertexai:gemini-1.5-flash-002\"` for example, the current report generation fails with \"Error in generate_report\".\r\n\r\nThis fix adds a fallback. It first attempts the original chat completion:\r\n```\r\n            messages=[                                                                              \r\n                {\"role\": \"system\", \"content\": f\"{agent_role_prompt}\"},                              \r\n                {\"role\": \"user\", \"content\": content},                                               \r\n            ],\r\n```\r\n\r\nUpon failure, it retries with this new chat completion:\r\n```\r\n                messages=[                                                                          \r\n                    {\"role\": \"user\", \"content\": f\"{agent_role_prompt}\\n\\n{content}\"},               \r\n                ],\r\n```\r\n\r\nThis results in a successful report generation when `\"SMART_LLM\": \"google_vertexai:gemini-1.5-flash-002\"`."
    },
    {
        "author": {
            "login": "assafelovic"
        },
        "body": "Thanks for this!"
    },
    {
        "author": {
            "login": "winsonluk"
        },
        "body": "@assafelovic short fix for when SMART_LLM fails with Gemini, thanks "
    }
]