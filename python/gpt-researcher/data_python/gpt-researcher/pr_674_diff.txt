diff --git a/gpt_researcher/master/agent.py b/gpt_researcher/master/agent.py
index 26a2392f1..a8e1940f0 100644
--- a/gpt_researcher/master/agent.py
+++ b/gpt_researcher/master/agent.py
@@ -19,7 +19,7 @@ def __init__(
         query: str,
         report_type: str = ReportType.ResearchReport.value,
         report_source=ReportSource.Web.value,
-        tone=Tone.Objective.value,
+        tone: Tone = Tone.Objective,
         source_urls=None,
         documents=None,
         config_path=None,
@@ -31,7 +31,7 @@ def __init__(
         visited_urls: set = set(),
         verbose: bool = True,
         context=[],
-        headers: dict = None  # Add headers parameter
+        headers: dict = None,  # Add headers parameter
     ):
         """
         Initialize the GPT Researcher class.
@@ -59,7 +59,9 @@ def __init__(
         self.report_source: str = report_source
         self.research_costs: float = 0.0
         self.cfg = Config(config_path)
-        self.retriever = get_retriever(self.headers.get("retriever")) or get_retriever(self.cfg.retriever)
+        self.retriever = get_retriever(self.headers.get("retriever")) or get_retriever(
+            self.cfg.retriever
+        )
         self.context = context
         self.source_urls = source_urls
         self.documents = documents
@@ -95,11 +97,13 @@ async def conduct_research(self):
         self.source_urls = []
 
         if self.verbose:
-            await stream_output("logs", 
-                                "starting_research", 
-                                f"🔎 Starting the research task for '{self.query}'...", 
-                                self.websocket)
-        
+            await stream_output(
+                "logs",
+                "starting_research",
+                f"🔎 Starting the research task for '{self.query}'...",
+                self.websocket,
+            )
+
         # Generate Agent
         if not (self.agent and self.role):
             self.agent, self.role = await choose_agent(
@@ -107,7 +111,7 @@ async def conduct_research(self):
                 cfg=self.cfg,
                 parent_query=self.parent_query,
                 cost_callback=self.add_costs,
-                headers=self.headers
+                headers=self.headers,
             )
 
         if self.verbose:
@@ -135,10 +139,12 @@ async def conduct_research(self):
 
         time.sleep(2)
         if self.verbose:
-            await stream_output("logs", 
-                                "research_step_finalized", 
-                                f"Finalized research step.\n💸 Total Research Costs: ${self.get_costs()}", 
-                                self.websocket)
+            await stream_output(
+                "logs",
+                "research_step_finalized",
+                f"Finalized research step.\n💸 Total Research Costs: ${self.get_costs()}",
+                self.websocket,
+            )
 
         return self.context
 
@@ -152,11 +158,13 @@ async def write_report(self, existing_headers: list = []):
         report = ""
 
         if self.verbose:
-            await stream_output("logs", 
-                                "task_summary_coming_up", 
-                                f"✍️ Writing summary for research task: {self.query}...", 
-                                self.websocket)
-            
+            await stream_output(
+                "logs",
+                "task_summary_coming_up",
+                f"✍️ Writing summary for research task: {self.query}...",
+                self.websocket,
+            )
+
         if self.report_type == "custom_report":
             self.role = self.cfg.agent_role if self.cfg.agent_role else self.role
             report = await generate_report(
@@ -168,7 +176,7 @@ async def write_report(self, existing_headers: list = []):
                 tone=self.tone,
                 websocket=self.websocket,
                 cfg=self.cfg,
-                headers=self.headers
+                headers=self.headers,
             )
         elif self.report_type == "subtopic_report":
             report = await generate_report(
@@ -183,7 +191,7 @@ async def write_report(self, existing_headers: list = []):
                 main_topic=self.parent_query,
                 existing_headers=existing_headers,
                 cost_callback=self.add_costs,
-                headers=self.headers
+                headers=self.headers,
             )
         else:
             report = await generate_report(
@@ -196,7 +204,7 @@ async def write_report(self, existing_headers: list = []):
                 websocket=self.websocket,
                 cfg=self.cfg,
                 cost_callback=self.add_costs,
-                headers=self.headers
+                headers=self.headers,
             )
 
         return report
@@ -207,10 +215,12 @@ async def __get_context_by_urls(self, urls):
         """
         new_search_urls = await self.__get_new_urls(urls)
         if self.verbose:
-            await stream_output("logs",
-                            "source_urls",
-                            f"🗂️ I will conduct my research based on the following urls: {new_search_urls}...",
-                            self.websocket)
+            await stream_output(
+                "logs",
+                "source_urls",
+                f"🗂️ I will conduct my research based on the following urls: {new_search_urls}...",
+                self.websocket,
+            )
 
         scraped_sites = scrape_urls(new_search_urls, self.cfg)
         return await self.__get_similar_content_by_query(self.query, scraped_sites)
@@ -230,7 +240,7 @@ async def __get_context_by_search(self, query, scraped_data: list = []):
             parent_query=self.parent_query,
             report_type=self.report_type,
             cost_callback=self.add_costs,
-            openai_api_key=self.headers.get("openai_api_key")
+            openai_api_key=self.headers.get("openai_api_key"),
         )
 
         # If this is not part of a sub researcher, add original query to research for better results
@@ -238,12 +248,14 @@ async def __get_context_by_search(self, query, scraped_data: list = []):
             sub_queries.append(query)
 
         if self.verbose:
-            await stream_output("logs",
-                                "subqueries",
-                                f"🗂️ I will conduct my research based on the following queries: {sub_queries}...",
-                                self.websocket,
-                                True,
-                                sub_queries)
+            await stream_output(
+                "logs",
+                "subqueries",
+                f"🗂️ I will conduct my research based on the following queries: {sub_queries}...",
+                self.websocket,
+                True,
+                sub_queries,
+            )
 
         # Using asyncio.gather to process the sub_queries asynchronously
         context = await asyncio.gather(
@@ -265,7 +277,12 @@ async def __process_sub_query(self, sub_query: str, scraped_data: list = []):
             str: The context gathered from search
         """
         if self.verbose:
-            await stream_output("logs", "running_subquery_research", f"\n🔍 Running research for '{sub_query}'...", self.websocket)
+            await stream_output(
+                "logs",
+                "running_subquery_research",
+                f"\n🔍 Running research for '{sub_query}'...",
+                self.websocket,
+            )
 
         if not scraped_data:
             scraped_data = await self.__scrape_data_by_query(sub_query)
@@ -273,9 +290,16 @@ async def __process_sub_query(self, sub_query: str, scraped_data: list = []):
         content = await self.__get_similar_content_by_query(sub_query, scraped_data)
 
         if content and self.verbose:
-            await stream_output("logs", "subquery_context_window", f"📃 {content}", self.websocket)
+            await stream_output(
+                "logs", "subquery_context_window", f"📃 {content}", self.websocket
+            )
         elif self.verbose:
-            await stream_output("logs", "subquery_context_not_found", f"🤷 No content found for '{sub_query}'...", self.websocket)
+            await stream_output(
+                "logs",
+                "subquery_context_not_found",
+                f"🤷 No content found for '{sub_query}'...",
+                self.websocket,
+            )
         return content
 
     async def __get_new_urls(self, url_set_input):
@@ -290,7 +314,14 @@ async def __get_new_urls(self, url_set_input):
                 self.visited_urls.add(url)
                 new_urls.append(url)
                 if self.verbose:
-                    await stream_output("logs", "added_source_url", f"✅ Added source url to research: {url}\n", self.websocket, True, url)
+                    await stream_output(
+                        "logs",
+                        "added_source_url",
+                        f"✅ Added source url to research: {url}\n",
+                        self.websocket,
+                        True,
+                        url,
+                    )
 
         return new_urls
 
@@ -305,8 +336,8 @@ async def __scrape_data_by_query(self, sub_query):
         """
         # Get Urls
         retriever = self.retriever(sub_query, headers=self.headers)
-        search_results = await asyncio.to_thread(retriever.search,
-            max_results=self.cfg.max_search_results_per_query
+        search_results = await asyncio.to_thread(
+            retriever.search, max_results=self.cfg.max_search_results_per_query
         )
         new_search_urls = await self.__get_new_urls(
             [url.get("href") for url in search_results]
@@ -314,15 +345,27 @@ async def __scrape_data_by_query(self, sub_query):
 
         # Scrape Urls
         if self.verbose:
-            await stream_output("logs", "researching", f"🤔 Researching for relevant information...\n", self.websocket)
+            await stream_output(
+                "logs",
+                "researching",
+                f"🤔 Researching for relevant information...\n",
+                self.websocket,
+            )
 
         # Scrape Urls
-        scraped_content_results = await asyncio.to_thread(scrape_urls, new_search_urls, self.cfg)
+        scraped_content_results = await asyncio.to_thread(
+            scrape_urls, new_search_urls, self.cfg
+        )
         return scraped_content_results
 
     async def __get_similar_content_by_query(self, query, pages):
         if self.verbose:
-            await stream_output("logs", "fetching_query_content", f"📚 Getting relevant content based on query: {query}...", self.websocket)
+            await stream_output(
+                "logs",
+                "fetching_query_content",
+                f"📚 Getting relevant content based on query: {query}...",
+                self.websocket,
+            )
 
         # Summarize Raw Data
         context_compressor = ContextCompressor(
@@ -379,7 +422,12 @@ async def get_subtopics(self):
         `construct_subtopics` function.
         """
         if self.verbose:
-            await stream_output("logs", "generating_subtopics", f"🤔 Generating subtopics...", self.websocket)
+            await stream_output(
+                "logs",
+                "generating_subtopics",
+                f"🤔 Generating subtopics...",
+                self.websocket,
+            )
 
         subtopics = await construct_subtopics(
             task=self.query,
@@ -390,6 +438,8 @@ async def get_subtopics(self):
         )
 
         if self.verbose:
-            await stream_output("logs", "subtopics", f"📋Subtopics: {subtopics}", self.websocket)
+            await stream_output(
+                "logs", "subtopics", f"📋Subtopics: {subtopics}", self.websocket
+            )
 
-        return subtopics
\ No newline at end of file
+        return subtopics
diff --git a/gpt_researcher/master/prompts.py b/gpt_researcher/master/prompts.py
index 2db475397..dec1def0a 100644
--- a/gpt_researcher/master/prompts.py
+++ b/gpt_researcher/master/prompts.py
@@ -28,9 +28,11 @@ def generate_search_queries_prompt(
     else:
         task = question
 
-    return f'Write {max_iterations} google search queries to search online that form an objective opinion from the following task: "{task}"' \
-           f'You must respond with a list of strings in the following format: ["query 1", "query 2", "query 3"].\n' \
-           f'The response should contain ONLY the list.'
+    return (
+        f'Write {max_iterations} google search queries to search online that form an objective opinion from the following task: "{task}"'
+        f'You must respond with a list of strings in the following format: ["query 1", "query 2", "query 3"].\n'
+        f"The response should contain ONLY the list."
+    )
 
 
 def generate_report_prompt(
@@ -61,7 +63,7 @@ def generate_report_prompt(
             You MUST write all used source document names at the end of the report as references, and make sure to not add duplicated sources, but only one reference for each."
         """
 
-    tone_prompt = f"Write the report in a {tone} tone." if tone else ""
+    tone_prompt = f"Write the report in a {tone.value} tone." if tone else ""
 
     return f"""
 Information: "{context}"
@@ -236,7 +238,7 @@ def generate_subtopic_report_prompt(
     report_format: str = "apa",
     max_subsections=5,
     total_words=800,
-    tone: Tone = Tone.Objective.value,
+    tone: Tone = Tone.Objective,
 ) -> str:
     return f"""
 "Context":
