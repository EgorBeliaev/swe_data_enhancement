diff --git a/src/codeview/codeview.h b/src/codeview/codeview.h
index e64cba5c1..e7f11d179 100644
--- a/src/codeview/codeview.h
+++ b/src/codeview/codeview.h
@@ -374,79 +374,79 @@ X(MM4,     150, fpr4, 0, 8)\
 X(MM5,     151, fpr5, 0, 8)\
 X(MM6,     152, fpr6, 0, 8)\
 X(MM7,     153, fpr7, 0, 8)\
-X(XMM0,    154, ymm0,  0, 16)\
-X(XMM1,    155, ymm1,  0, 16)\
-X(XMM2,    156, ymm2,  0, 16)\
-X(XMM3,    157, ymm3,  0, 16)\
-X(XMM4,    158, ymm4,  0, 16)\
-X(XMM5,    159, ymm5,  0, 16)\
-X(XMM6,    160, ymm6,  0, 16)\
-X(XMM7,    161, ymm7,  0, 16)\
-X(XMM0_0,  162, ymm0,  0,  4)\
-X(XMM0_1,  163, ymm0,  4,  4)\
-X(XMM0_2,  164, ymm0,  8,  4)\
-X(XMM0_3,  165, ymm0, 12,  4)\
-X(XMM1_0,  166, ymm1,  0,  4)\
-X(XMM1_1,  167, ymm1,  4,  4)\
-X(XMM1_2,  168, ymm1,  8,  4)\
-X(XMM1_3,  169, ymm1, 12,  4)\
-X(XMM2_0,  170, ymm2,  0,  4)\
-X(XMM2_1,  171, ymm2,  4,  4)\
-X(XMM2_2,  172, ymm2,  8,  4)\
-X(XMM2_3,  173, ymm2, 12,  4)\
-X(XMM3_0,  174, ymm3,  0,  4)\
-X(XMM3_1,  175, ymm3,  4,  4)\
-X(XMM3_2,  176, ymm3,  8,  4)\
-X(XMM3_3,  177, ymm3, 12,  4)\
-X(XMM4_0,  178, ymm4,  0,  4)\
-X(XMM4_1,  179, ymm4,  4,  4)\
-X(XMM4_2,  180, ymm4,  8,  4)\
-X(XMM4_3,  181, ymm4, 12,  4)\
-X(XMM5_0,  182, ymm5,  0,  4)\
-X(XMM5_1,  183, ymm5,  4,  4)\
-X(XMM5_2,  184, ymm5,  8,  4)\
-X(XMM5_3,  185, ymm5, 12,  4)\
-X(XMM6_0,  186, ymm6,  0,  4)\
-X(XMM6_1,  187, ymm6,  4,  4)\
-X(XMM6_2,  188, ymm6,  8,  4)\
-X(XMM6_3,  189, ymm6, 12,  4)\
-X(XMM7_0,  190, ymm7,  0,  4)\
-X(XMM7_1,  191, ymm7,  4,  4)\
-X(XMM7_2,  192, ymm7,  8,  4)\
-X(XMM7_3,  193, ymm7, 12,  4)\
-X(XMM0L,   194, ymm0,  0,  8)\
-X(XMM1L,   195, ymm1,  0,  8)\
-X(XMM2L,   196, ymm2,  0,  8)\
-X(XMM3L,   197, ymm3,  0,  8)\
-X(XMM4L,   198, ymm4,  0,  8)\
-X(XMM5L,   199, ymm5,  0,  8)\
-X(XMM6L,   200, ymm6,  0,  8)\
-X(XMM7L,   201, ymm7,  0,  8)\
-X(XMM0H,   202, ymm0,  8,  8)\
-X(XMM1H,   203, ymm1,  8,  8)\
-X(XMM2H,   204, ymm2,  8,  8)\
-X(XMM3H,   205, ymm3,  8,  8)\
-X(XMM4H,   206, ymm4,  8,  8)\
-X(XMM5H,   207, ymm5,  8,  8)\
-X(XMM6H,   208, ymm6,  8,  8)\
-X(XMM7H,   209, ymm7,  8,  8)\
+X(XMM0,    154, zmm0,  0, 16)\
+X(XMM1,    155, zmm1,  0, 16)\
+X(XMM2,    156, zmm2,  0, 16)\
+X(XMM3,    157, zmm3,  0, 16)\
+X(XMM4,    158, zmm4,  0, 16)\
+X(XMM5,    159, zmm5,  0, 16)\
+X(XMM6,    160, zmm6,  0, 16)\
+X(XMM7,    161, zmm7,  0, 16)\
+X(XMM0_0,  162, zmm0,  0,  4)\
+X(XMM0_1,  163, zmm0,  4,  4)\
+X(XMM0_2,  164, zmm0,  8,  4)\
+X(XMM0_3,  165, zmm0, 12,  4)\
+X(XMM1_0,  166, zmm1,  0,  4)\
+X(XMM1_1,  167, zmm1,  4,  4)\
+X(XMM1_2,  168, zmm1,  8,  4)\
+X(XMM1_3,  169, zmm1, 12,  4)\
+X(XMM2_0,  170, zmm2,  0,  4)\
+X(XMM2_1,  171, zmm2,  4,  4)\
+X(XMM2_2,  172, zmm2,  8,  4)\
+X(XMM2_3,  173, zmm2, 12,  4)\
+X(XMM3_0,  174, zmm3,  0,  4)\
+X(XMM3_1,  175, zmm3,  4,  4)\
+X(XMM3_2,  176, zmm3,  8,  4)\
+X(XMM3_3,  177, zmm3, 12,  4)\
+X(XMM4_0,  178, zmm4,  0,  4)\
+X(XMM4_1,  179, zmm4,  4,  4)\
+X(XMM4_2,  180, zmm4,  8,  4)\
+X(XMM4_3,  181, zmm4, 12,  4)\
+X(XMM5_0,  182, zmm5,  0,  4)\
+X(XMM5_1,  183, zmm5,  4,  4)\
+X(XMM5_2,  184, zmm5,  8,  4)\
+X(XMM5_3,  185, zmm5, 12,  4)\
+X(XMM6_0,  186, zmm6,  0,  4)\
+X(XMM6_1,  187, zmm6,  4,  4)\
+X(XMM6_2,  188, zmm6,  8,  4)\
+X(XMM6_3,  189, zmm6, 12,  4)\
+X(XMM7_0,  190, zmm7,  0,  4)\
+X(XMM7_1,  191, zmm7,  4,  4)\
+X(XMM7_2,  192, zmm7,  8,  4)\
+X(XMM7_3,  193, zmm7, 12,  4)\
+X(XMM0L,   194, zmm0,  0,  8)\
+X(XMM1L,   195, zmm1,  0,  8)\
+X(XMM2L,   196, zmm2,  0,  8)\
+X(XMM3L,   197, zmm3,  0,  8)\
+X(XMM4L,   198, zmm4,  0,  8)\
+X(XMM5L,   199, zmm5,  0,  8)\
+X(XMM6L,   200, zmm6,  0,  8)\
+X(XMM7L,   201, zmm7,  0,  8)\
+X(XMM0H,   202, zmm0,  8,  8)\
+X(XMM1H,   203, zmm1,  8,  8)\
+X(XMM2H,   204, zmm2,  8,  8)\
+X(XMM3H,   205, zmm3,  8,  8)\
+X(XMM4H,   206, zmm4,  8,  8)\
+X(XMM5H,   207, zmm5,  8,  8)\
+X(XMM6H,   208, zmm6,  8,  8)\
+X(XMM7H,   209, zmm7,  8,  8)\
 X(MXCSR,   211, mxcsr, 0,  4)\
-X(EMM0L,   220, ymm0,  0,  8)\
-X(EMM1L,   221, ymm1,  0,  8)\
-X(EMM2L,   222, ymm2,  0,  8)\
-X(EMM3L,   223, ymm3,  0,  8)\
-X(EMM4L,   224, ymm4,  0,  8)\
-X(EMM5L,   225, ymm5,  0,  8)\
-X(EMM6L,   226, ymm6,  0,  8)\
-X(EMM7L,   227, ymm7,  0,  8)\
-X(EMM0H,   228, ymm0,  8,  8)\
-X(EMM1H,   229, ymm1,  8,  8)\
-X(EMM2H,   230, ymm2,  8,  8)\
-X(EMM3H,   231, ymm3,  8,  8)\
-X(EMM4H,   232, ymm4,  8,  8)\
-X(EMM5H,   233, ymm5,  8,  8)\
-X(EMM6H,   234, ymm6,  8,  8)\
-X(EMM7H,   235, ymm7,  8,  8)\
+X(EMM0L,   220, zmm0,  0,  8)\
+X(EMM1L,   221, zmm1,  0,  8)\
+X(EMM2L,   222, zmm2,  0,  8)\
+X(EMM3L,   223, zmm3,  0,  8)\
+X(EMM4L,   224, zmm4,  0,  8)\
+X(EMM5L,   225, zmm5,  0,  8)\
+X(EMM6L,   226, zmm6,  0,  8)\
+X(EMM7L,   227, zmm7,  0,  8)\
+X(EMM0H,   228, zmm0,  8,  8)\
+X(EMM1H,   229, zmm1,  8,  8)\
+X(EMM2H,   230, zmm2,  8,  8)\
+X(EMM3H,   231, zmm3,  8,  8)\
+X(EMM4H,   232, zmm4,  8,  8)\
+X(EMM5H,   233, zmm5,  8,  8)\
+X(EMM6H,   234, zmm6,  8,  8)\
+X(EMM7H,   235, zmm7,  8,  8)\
 X(MM00,    236, fpr0,  0,  4)\
 X(MM01,    237, fpr0,  4,  4)\
 X(MM10,    238, fpr1,  0,  4)\
@@ -463,78 +463,78 @@ X(MM60,    248, fpr6,  0,  4)\
 X(MM61,    249, fpr6,  4,  4)\
 X(MM70,    250, fpr7,  0,  4)\
 X(MM71,    251, fpr7,  4,  4)\
-X(XMM8,    252, ymm8,   0, 16)\
-X(XMM9,    253, ymm9,   0, 16)\
-X(XMM10,   254, ymm10,  0, 16)\
-X(XMM11,   255, ymm11,  0, 16)\
-X(XMM12,   256, ymm12,  0, 16)\
-X(XMM13,   257, ymm13,  0, 16)\
-X(XMM14,   258, ymm14,  0, 16)\
-X(XMM15,   259, ymm15,  0, 16)\
-X(XMM8_0,  260, ymm8,   0, 16)\
-X(XMM8_1,  261, ymm8,   4, 16)\
-X(XMM8_2,  262, ymm8,   8, 16)\
-X(XMM8_3,  263, ymm8,  12, 16)\
-X(XMM9_0,  264, ymm9,   0,  4)\
-X(XMM9_1,  265, ymm9,   4,  4)\
-X(XMM9_2,  266, ymm9,   8,  4)\
-X(XMM9_3,  267, ymm9,  12,  4)\
-X(XMM10_0, 268, ymm10,  0,  4)\
-X(XMM10_1, 269, ymm10,  4,  4)\
-X(XMM10_2, 270, ymm10,  8,  4)\
-X(XMM10_3, 271, ymm10, 12,  4)\
-X(XMM11_0, 272, ymm11,  0,  4)\
-X(XMM11_1, 273, ymm11,  4,  4)\
-X(XMM11_2, 274, ymm11,  8,  4)\
-X(XMM11_3, 275, ymm11, 12,  4)\
-X(XMM12_0, 276, ymm12,  0,  4)\
-X(XMM12_1, 277, ymm12,  4,  4)\
-X(XMM12_2, 278, ymm12,  8,  4)\
-X(XMM12_3, 279, ymm12, 12,  4)\
-X(XMM13_0, 280, ymm13,  0,  4)\
-X(XMM13_1, 281, ymm13,  4,  4)\
-X(XMM13_2, 282, ymm13,  8,  4)\
-X(XMM13_3, 283, ymm13, 12,  4)\
-X(XMM14_0, 284, ymm14,  0,  4)\
-X(XMM14_1, 285, ymm14,  4,  4)\
-X(XMM14_2, 286, ymm14,  8,  4)\
-X(XMM14_3, 287, ymm14, 12,  4)\
-X(XMM15_0, 288, ymm15,  0,  4)\
-X(XMM15_1, 289, ymm15,  4,  4)\
-X(XMM15_2, 290, ymm15,  8,  4)\
-X(XMM15_3, 291, ymm15, 12,  4)\
-X(XMM8L,   292, ymm8,   0,  8)\
-X(XMM9L,   293, ymm9,   0,  8)\
-X(XMM10L,  294, ymm10,  0,  8)\
-X(XMM11L,  295, ymm11,  0,  8)\
-X(XMM12L,  296, ymm12,  0,  8)\
-X(XMM13L,  297, ymm13,  0,  8)\
-X(XMM14L,  298, ymm14,  0,  8)\
-X(XMM15L,  299, ymm15,  0,  8)\
-X(XMM8H,   300, ymm8,   8,  8)\
-X(XMM9H,   301, ymm9,   8,  8)\
-X(XMM10H,  302, ymm10,  8,  8)\
-X(XMM11H,  303, ymm11,  8,  8)\
-X(XMM12H,  304, ymm12,  8,  8)\
-X(XMM13H,  305, ymm13,  8,  8)\
-X(XMM14H,  306, ymm14,  8,  8)\
-X(XMM15H,  307, ymm15,  8,  8)\
-X(EMM8L,   308, ymm8,   0,  8)\
-X(EMM9L,   309, ymm9,   0,  8)\
-X(EMM10L,  310, ymm10,  0,  8)\
-X(EMM11L,  311, ymm11,  0,  8)\
-X(EMM12L,  312, ymm12,  0,  8)\
-X(EMM13L,  313, ymm13,  0,  8)\
-X(EMM14L,  314, ymm14,  0,  8)\
-X(EMM15L,  315, ymm15,  0,  8)\
-X(EMM8H,   316, ymm8,   8,  8)\
-X(EMM9H,   317, ymm9,   8,  8)\
-X(EMM10H,  318, ymm10,  8,  8)\
-X(EMM11H,  319, ymm11,  8,  8)\
-X(EMM12H,  320, ymm12,  8,  8)\
-X(EMM13H,  321, ymm13,  8,  8)\
-X(EMM14H,  322, ymm14,  8,  8)\
-X(EMM15H,  323, ymm15,  8,  8)\
+X(XMM8,    252, zmm8,   0, 16)\
+X(XMM9,    253, zmm9,   0, 16)\
+X(XMM10,   254, zmm10,  0, 16)\
+X(XMM11,   255, zmm11,  0, 16)\
+X(XMM12,   256, zmm12,  0, 16)\
+X(XMM13,   257, zmm13,  0, 16)\
+X(XMM14,   258, zmm14,  0, 16)\
+X(XMM15,   259, zmm15,  0, 16)\
+X(XMM8_0,  260, zmm8,   0, 16)\
+X(XMM8_1,  261, zmm8,   4, 16)\
+X(XMM8_2,  262, zmm8,   8, 16)\
+X(XMM8_3,  263, zmm8,  12, 16)\
+X(XMM9_0,  264, zmm9,   0,  4)\
+X(XMM9_1,  265, zmm9,   4,  4)\
+X(XMM9_2,  266, zmm9,   8,  4)\
+X(XMM9_3,  267, zmm9,  12,  4)\
+X(XMM10_0, 268, zmm10,  0,  4)\
+X(XMM10_1, 269, zmm10,  4,  4)\
+X(XMM10_2, 270, zmm10,  8,  4)\
+X(XMM10_3, 271, zmm10, 12,  4)\
+X(XMM11_0, 272, zmm11,  0,  4)\
+X(XMM11_1, 273, zmm11,  4,  4)\
+X(XMM11_2, 274, zmm11,  8,  4)\
+X(XMM11_3, 275, zmm11, 12,  4)\
+X(XMM12_0, 276, zmm12,  0,  4)\
+X(XMM12_1, 277, zmm12,  4,  4)\
+X(XMM12_2, 278, zmm12,  8,  4)\
+X(XMM12_3, 279, zmm12, 12,  4)\
+X(XMM13_0, 280, zmm13,  0,  4)\
+X(XMM13_1, 281, zmm13,  4,  4)\
+X(XMM13_2, 282, zmm13,  8,  4)\
+X(XMM13_3, 283, zmm13, 12,  4)\
+X(XMM14_0, 284, zmm14,  0,  4)\
+X(XMM14_1, 285, zmm14,  4,  4)\
+X(XMM14_2, 286, zmm14,  8,  4)\
+X(XMM14_3, 287, zmm14, 12,  4)\
+X(XMM15_0, 288, zmm15,  0,  4)\
+X(XMM15_1, 289, zmm15,  4,  4)\
+X(XMM15_2, 290, zmm15,  8,  4)\
+X(XMM15_3, 291, zmm15, 12,  4)\
+X(XMM8L,   292, zmm8,   0,  8)\
+X(XMM9L,   293, zmm9,   0,  8)\
+X(XMM10L,  294, zmm10,  0,  8)\
+X(XMM11L,  295, zmm11,  0,  8)\
+X(XMM12L,  296, zmm12,  0,  8)\
+X(XMM13L,  297, zmm13,  0,  8)\
+X(XMM14L,  298, zmm14,  0,  8)\
+X(XMM15L,  299, zmm15,  0,  8)\
+X(XMM8H,   300, zmm8,   8,  8)\
+X(XMM9H,   301, zmm9,   8,  8)\
+X(XMM10H,  302, zmm10,  8,  8)\
+X(XMM11H,  303, zmm11,  8,  8)\
+X(XMM12H,  304, zmm12,  8,  8)\
+X(XMM13H,  305, zmm13,  8,  8)\
+X(XMM14H,  306, zmm14,  8,  8)\
+X(XMM15H,  307, zmm15,  8,  8)\
+X(EMM8L,   308, zmm8,   0,  8)\
+X(EMM9L,   309, zmm9,   0,  8)\
+X(EMM10L,  310, zmm10,  0,  8)\
+X(EMM11L,  311, zmm11,  0,  8)\
+X(EMM12L,  312, zmm12,  0,  8)\
+X(EMM13L,  313, zmm13,  0,  8)\
+X(EMM14L,  314, zmm14,  0,  8)\
+X(EMM15L,  315, zmm15,  0,  8)\
+X(EMM8H,   316, zmm8,   8,  8)\
+X(EMM9H,   317, zmm9,   8,  8)\
+X(EMM10H,  318, zmm10,  8,  8)\
+X(EMM11H,  319, zmm11,  8,  8)\
+X(EMM12H,  320, zmm12,  8,  8)\
+X(EMM13H,  321, zmm13,  8,  8)\
+X(EMM14H,  322, zmm14,  8,  8)\
+X(EMM15H,  323, zmm15,  8,  8)\
 X(SIL,     324, rsi, 0, 1)\
 X(DIL,     325, rdi, 0, 1)\
 X(BPL,     326, rbp, 0, 1)\
@@ -579,326 +579,326 @@ X(R12D,    364, r12, 0, 4)\
 X(R13D,    365, r13, 0, 4)\
 X(R14D,    366, r14, 0, 4)\
 X(R15D,    367, r15, 0, 4)\
-X(YMM0,    368, ymm0,   0, 32)\
-X(YMM1,    369, ymm1,   0, 32)\
-X(YMM2,    370, ymm2,   0, 32)\
-X(YMM3,    371, ymm3,   0, 32)\
-X(YMM4,    372, ymm4,   0, 32)\
-X(YMM5,    373, ymm5,   0, 32)\
-X(YMM6,    374, ymm6,   0, 32)\
-X(YMM7,    375, ymm7,   0, 32)\
-X(YMM8,    376, ymm8,   0, 32)\
-X(YMM9,    377, ymm9,   0, 32)\
-X(YMM10,   378, ymm10,  0, 32)\
-X(YMM11,   379, ymm11,  0, 32)\
-X(YMM12,   380, ymm12,  0, 32)\
-X(YMM13,   381, ymm13,  0, 32)\
-X(YMM14,   382, ymm14,  0, 32)\
-X(YMM15,   383, ymm15,  0, 32)\
-X(YMM0H,   384, ymm0,  16, 32)\
-X(YMM1H,   385, ymm1,  16, 32)\
-X(YMM2H,   386, ymm2,  16, 32)\
-X(YMM3H,   387, ymm3,  16, 32)\
-X(YMM4H,   388, ymm4,  16, 32)\
-X(YMM5H,   389, ymm5,  16, 32)\
-X(YMM6H,   390, ymm6,  16, 32)\
-X(YMM7H,   391, ymm7,  16, 32)\
-X(YMM8H,   392, ymm8,  16, 32)\
-X(YMM9H,   393, ymm9,  16, 32)\
-X(YMM10H,  394, ymm10, 16, 32)\
-X(YMM11H,  395, ymm11, 16, 32)\
-X(YMM12H,  396, ymm12, 16, 32)\
-X(YMM13H,  397, ymm13, 16, 32)\
-X(YMM14H,  398, ymm14, 16, 32)\
-X(YMM15H,  399, ymm15, 16, 32)\
-X(XMM0IL,  400, ymm0,   0,  8)\
-X(XMM1IL,  401, ymm1,   0,  8)\
-X(XMM2IL,  402, ymm2,   0,  8)\
-X(XMM3IL,  403, ymm3,   0,  8)\
-X(XMM4IL,  404, ymm4,   0,  8)\
-X(XMM5IL,  405, ymm5,   0,  8)\
-X(XMM6IL,  406, ymm6,   0,  8)\
-X(XMM7IL,  407, ymm7,   0,  8)\
-X(XMM8IL,  408, ymm8,   0,  8)\
-X(XMM9IL,  409, ymm9,   0,  8)\
-X(XMM10IL, 410, ymm10,  0,  8)\
-X(XMM11IL, 411, ymm11,  0,  8)\
-X(XMM12IL, 412, ymm12,  0,  8)\
-X(XMM13IL, 413, ymm13,  0,  8)\
-X(XMM14IL, 414, ymm14,  0,  8)\
-X(XMM15IL, 415, ymm15,  0,  8)\
-X(XMM0IH,  416, ymm0,   8,  8)\
-X(XMM1IH,  417, ymm1,   8,  8)\
-X(XMM2IH,  418, ymm2,   8,  8)\
-X(XMM3IH,  419, ymm3,   8,  8)\
-X(XMM4IH,  420, ymm4,   8,  8)\
-X(XMM5IH,  421, ymm5,   8,  8)\
-X(XMM6IH,  422, ymm6,   8,  8)\
-X(XMM7IH,  423, ymm7,   8,  8)\
-X(XMM8IH,  424, ymm8,   8,  8)\
-X(XMM9IH,  425, ymm9,   8,  8)\
-X(XMM10IH, 426, ymm10,  8,  8)\
-X(XMM11IH, 427, ymm11,  8,  8)\
-X(XMM12IH, 428, ymm12,  8,  8)\
-X(XMM13IH, 429, ymm13,  8,  8)\
-X(XMM14IH, 430, ymm14,  8,  8)\
-X(XMM15IH, 431, ymm15,  8,  8)\
-X(YMM0I0,  432, ymm0,   0,  8)\
-X(YMM0I1,  433, ymm0,   8,  8)\
-X(YMM0I2,  434, ymm0,  16,  8)\
-X(YMM0I3,  435, ymm0,  24,  8)\
-X(YMM1I0,  436, ymm1,   0,  8)\
-X(YMM1I1,  437, ymm1,   8,  8)\
-X(YMM1I2,  438, ymm1,  16,  8)\
-X(YMM1I3,  439, ymm1,  24,  8)\
-X(YMM2I0,  440, ymm2,   0,  8)\
-X(YMM2I1,  441, ymm2,   8,  8)\
-X(YMM2I2,  442, ymm2,  16,  8)\
-X(YMM2I3,  443, ymm2,  24,  8)\
-X(YMM3I0,  444, ymm3,   0,  8)\
-X(YMM3I1,  445, ymm3,   8,  8)\
-X(YMM3I2,  446, ymm3,  16,  8)\
-X(YMM3I3,  447, ymm3,  24,  8)\
-X(YMM4I0,  448, ymm4,   0,  8)\
-X(YMM4I1,  449, ymm4,   8,  8)\
-X(YMM4I2,  450, ymm4,  16,  8)\
-X(YMM4I3,  451, ymm4,  24,  8)\
-X(YMM5I0,  452, ymm5,   0,  8)\
-X(YMM5I1,  453, ymm5,   8,  8)\
-X(YMM5I2,  454, ymm5,  16,  8)\
-X(YMM5I3,  455, ymm5,  24,  8)\
-X(YMM6I0,  456, ymm6,   0,  8)\
-X(YMM6I1,  457, ymm6,   8,  8)\
-X(YMM6I2,  458, ymm6,  16,  8)\
-X(YMM6I3,  459, ymm6,  24,  8)\
-X(YMM7I0,  460, ymm7,   0,  8)\
-X(YMM7I1,  461, ymm7,   8,  8)\
-X(YMM7I2,  462, ymm7,  16,  8)\
-X(YMM7I3,  463, ymm7,  24,  8)\
-X(YMM8I0,  464, ymm8,   0,  8)\
-X(YMM8I1,  465, ymm8,   8,  8)\
-X(YMM8I2,  466, ymm8,  16,  8)\
-X(YMM8I3,  467, ymm8,  24,  8)\
-X(YMM9I0,  468, ymm9,   0,  8)\
-X(YMM9I1,  469, ymm9,   8,  8)\
-X(YMM9I2,  470, ymm9,  16,  8)\
-X(YMM9I3,  471, ymm9,  24,  8)\
-X(YMM10I0, 472, ymm10,  0,  8)\
-X(YMM10I1, 473, ymm10,  8,  8)\
-X(YMM10I2, 474, ymm10, 16,  8)\
-X(YMM10I3, 475, ymm10, 24,  8)\
-X(YMM11I0, 476, ymm11,  0,  8)\
-X(YMM11I1, 477, ymm11,  8,  8)\
-X(YMM11I2, 478, ymm11, 16,  8)\
-X(YMM11I3, 479, ymm11, 24,  8)\
-X(YMM12I0, 480, ymm12,  0,  8)\
-X(YMM12I1, 481, ymm12,  8,  8)\
-X(YMM12I2, 482, ymm12, 16,  8)\
-X(YMM12I3, 483, ymm12, 24,  8)\
-X(YMM13I0, 484, ymm13,  0,  8)\
-X(YMM13I1, 485, ymm13,  8,  8)\
-X(YMM13I2, 486, ymm13, 16,  8)\
-X(YMM13I3, 487, ymm13, 24,  8)\
-X(YMM14I0, 488, ymm14,  0,  8)\
-X(YMM14I1, 489, ymm14,  8,  8)\
-X(YMM14I2, 490, ymm14, 16,  8)\
-X(YMM14I3, 491, ymm14, 24,  8)\
-X(YMM15I0, 492, ymm15,  0,  8)\
-X(YMM15I1, 493, ymm15,  8,  8)\
-X(YMM15I2, 494, ymm15, 16,  8)\
-X(YMM15I3, 495, ymm15, 24,  8)\
-X(YMM0F0,  496, ymm0,   0,  4)\
-X(YMM0F1,  497, ymm0,   4,  4)\
-X(YMM0F2,  498, ymm0,   8,  4)\
-X(YMM0F3,  499, ymm0,  12,  4)\
-X(YMM0F4,  500, ymm0,  16,  4)\
-X(YMM0F5,  501, ymm0,  20,  4)\
-X(YMM0F6,  502, ymm0,  24,  4)\
-X(YMM0F7,  503, ymm0,  28,  4)\
-X(YMM1F0,  504, ymm1,   0,  4)\
-X(YMM1F1,  505, ymm1,   4,  4)\
-X(YMM1F2,  506, ymm1,   8,  4)\
-X(YMM1F3,  507, ymm1,  12,  4)\
-X(YMM1F4,  508, ymm1,  16,  4)\
-X(YMM1F5,  509, ymm1,  20,  4)\
-X(YMM1F6,  510, ymm1,  24,  4)\
-X(YMM1F7,  511, ymm1,  28,  4)\
-X(YMM2F0,  512, ymm2,   0,  4)\
-X(YMM2F1,  513, ymm2,   4,  4)\
-X(YMM2F2,  514, ymm2,   8,  4)\
-X(YMM2F3,  515, ymm2,  12,  4)\
-X(YMM2F4,  516, ymm2,  16,  4)\
-X(YMM2F5,  517, ymm2,  20,  4)\
-X(YMM2F6,  518, ymm2,  24,  4)\
-X(YMM2F7,  519, ymm2,  28,  4)\
-X(YMM3F0,  520, ymm3,   0,  4)\
-X(YMM3F1,  521, ymm3,   4,  4)\
-X(YMM3F2,  522, ymm3,   8,  4)\
-X(YMM3F3,  523, ymm3,  12,  4)\
-X(YMM3F4,  524, ymm3,  16,  4)\
-X(YMM3F5,  525, ymm3,  20,  4)\
-X(YMM3F6,  526, ymm3,  24,  4)\
-X(YMM3F7,  527, ymm3,  28,  4)\
-X(YMM4F0,  528, ymm4,   0,  4)\
-X(YMM4F1,  529, ymm4,   4,  4)\
-X(YMM4F2,  530, ymm4,   8,  4)\
-X(YMM4F3,  531, ymm4,  12,  4)\
-X(YMM4F4,  532, ymm4,  16,  4)\
-X(YMM4F5,  533, ymm4,  20,  4)\
-X(YMM4F6,  534, ymm4,  24,  4)\
-X(YMM4F7,  535, ymm4,  28,  4)\
-X(YMM5F0,  536, ymm5,   0,  4)\
-X(YMM5F1,  537, ymm5,   4,  4)\
-X(YMM5F2,  538, ymm5,   8,  4)\
-X(YMM5F3,  539, ymm5,  12,  4)\
-X(YMM5F4,  540, ymm5,  16,  4)\
-X(YMM5F5,  541, ymm5,  20,  4)\
-X(YMM5F6,  542, ymm5,  24,  4)\
-X(YMM5F7,  543, ymm5,  28,  4)\
-X(YMM6F0,  544, ymm6,   0,  4)\
-X(YMM6F1,  545, ymm6,   4,  4)\
-X(YMM6F2,  546, ymm6,   8,  4)\
-X(YMM6F3,  547, ymm6,  12,  4)\
-X(YMM6F4,  548, ymm6,  16,  4)\
-X(YMM6F5,  549, ymm6,  20,  4)\
-X(YMM6F6,  550, ymm6,  24,  4)\
-X(YMM6F7,  551, ymm6,  28,  4)\
-X(YMM7F0,  552, ymm7,   0,  4)\
-X(YMM7F1,  553, ymm7,   4,  4)\
-X(YMM7F2,  554, ymm7,   8,  4)\
-X(YMM7F3,  555, ymm7,  12,  4)\
-X(YMM7F4,  556, ymm7,  16,  4)\
-X(YMM7F5,  557, ymm7,  20,  4)\
-X(YMM7F6,  558, ymm7,  24,  4)\
-X(YMM7F7,  559, ymm7,  28,  4)\
-X(YMM8F0,  560, ymm8,   0,  4)\
-X(YMM8F1,  561, ymm8,   4,  4)\
-X(YMM8F2,  562, ymm8,   8,  4)\
-X(YMM8F3,  563, ymm8,  12,  4)\
-X(YMM8F4,  564, ymm8,  16,  4)\
-X(YMM8F5,  565, ymm8,  20,  4)\
-X(YMM8F6,  566, ymm8,  24,  4)\
-X(YMM8F7,  567, ymm8,  28,  4)\
-X(YMM9F0,  568, ymm9,   0,  4)\
-X(YMM9F1,  569, ymm9,   4,  4)\
-X(YMM9F2,  570, ymm9,   8,  4)\
-X(YMM9F3,  571, ymm9,  12,  4)\
-X(YMM9F4,  572, ymm9,  16,  4)\
-X(YMM9F5,  573, ymm9,  20,  4)\
-X(YMM9F6,  574, ymm9,  24,  4)\
-X(YMM9F7,  575, ymm9,  28,  4)\
-X(YMM10F0, 576, ymm10,  0,  4)\
-X(YMM10F1, 577, ymm10,  4,  4)\
-X(YMM10F2, 578, ymm10,  8,  4)\
-X(YMM10F3, 579, ymm10, 12,  4)\
-X(YMM10F4, 580, ymm10, 16,  4)\
-X(YMM10F5, 581, ymm10, 20,  4)\
-X(YMM10F6, 582, ymm10, 24,  4)\
-X(YMM10F7, 583, ymm10, 28,  4)\
-X(YMM11F0, 584, ymm11,  0,  4)\
-X(YMM11F1, 585, ymm11,  4,  4)\
-X(YMM11F2, 586, ymm11,  8,  4)\
-X(YMM11F3, 587, ymm11, 12,  4)\
-X(YMM11F4, 588, ymm11, 16,  4)\
-X(YMM11F5, 589, ymm11, 20,  4)\
-X(YMM11F6, 590, ymm11, 24,  4)\
-X(YMM11F7, 591, ymm11, 28,  4)\
-X(YMM12F0, 592, ymm12,  0,  4)\
-X(YMM12F1, 593, ymm12,  4,  4)\
-X(YMM12F2, 594, ymm12,  8,  4)\
-X(YMM12F3, 595, ymm12, 12,  4)\
-X(YMM12F4, 596, ymm12, 16,  4)\
-X(YMM12F5, 597, ymm12, 20,  4)\
-X(YMM12F6, 598, ymm12, 24,  4)\
-X(YMM12F7, 599, ymm12, 28,  4)\
-X(YMM13F0, 600, ymm13,  0,  4)\
-X(YMM13F1, 601, ymm13,  4,  4)\
-X(YMM13F2, 602, ymm13,  8,  4)\
-X(YMM13F3, 603, ymm13, 12,  4)\
-X(YMM13F4, 604, ymm13, 16,  4)\
-X(YMM13F5, 605, ymm13, 20,  4)\
-X(YMM13F6, 606, ymm13, 24,  4)\
-X(YMM13F7, 607, ymm13, 28,  4)\
-X(YMM14F0, 608, ymm14,  0,  4)\
-X(YMM14F1, 609, ymm14,  4,  4)\
-X(YMM14F2, 610, ymm14,  8,  4)\
-X(YMM14F3, 611, ymm14, 12,  4)\
-X(YMM14F4, 612, ymm14, 16,  4)\
-X(YMM14F5, 613, ymm14, 20,  4)\
-X(YMM14F6, 614, ymm14, 24,  4)\
-X(YMM14F7, 615, ymm14, 28,  4)\
-X(YMM15F0, 616, ymm15,  0,  4)\
-X(YMM15F1, 617, ymm15,  4,  4)\
-X(YMM15F2, 618, ymm15,  8,  4)\
-X(YMM15F3, 619, ymm15, 12,  4)\
-X(YMM15F4, 620, ymm15, 16,  4)\
-X(YMM15F5, 621, ymm15, 20,  4)\
-X(YMM15F6, 622, ymm15, 24,  4)\
-X(YMM15F7, 623, ymm15, 28,  4)\
-X(YMM0D0,  624, ymm0,   0,  8)\
-X(YMM0D1,  625, ymm0,   8,  8)\
-X(YMM0D2,  626, ymm0,  16,  8)\
-X(YMM0D3,  627, ymm0,  24,  8)\
-X(YMM1D0,  628, ymm1,   0,  8)\
-X(YMM1D1,  629, ymm1,   8,  8)\
-X(YMM1D2,  630, ymm1,  16,  8)\
-X(YMM1D3,  631, ymm1,  24,  8)\
-X(YMM2D0,  632, ymm2,   0,  8)\
-X(YMM2D1,  633, ymm2,   8,  8)\
-X(YMM2D2,  634, ymm2,  16,  8)\
-X(YMM2D3,  635, ymm2,  24,  8)\
-X(YMM3D0,  636, ymm3,   0,  8)\
-X(YMM3D1,  637, ymm3,   8,  8)\
-X(YMM3D2,  638, ymm3,  16,  8)\
-X(YMM3D3,  639, ymm3,  24,  8)\
-X(YMM4D0,  640, ymm4,   0,  8)\
-X(YMM4D1,  641, ymm4,   8,  8)\
-X(YMM4D2,  642, ymm4,  16,  8)\
-X(YMM4D3,  643, ymm4,  24,  8)\
-X(YMM5D0,  644, ymm5,   0,  8)\
-X(YMM5D1,  645, ymm5,   8,  8)\
-X(YMM5D2,  646, ymm5,  16,  8)\
-X(YMM5D3,  647, ymm5,  24,  8)\
-X(YMM6D0,  648, ymm6,   0,  8)\
-X(YMM6D1,  649, ymm6,   8,  8)\
-X(YMM6D2,  650, ymm6,  16,  8)\
-X(YMM6D3,  651, ymm6,  24,  8)\
-X(YMM7D0,  652, ymm7,   0,  8)\
-X(YMM7D1,  653, ymm7,   8,  8)\
-X(YMM7D2,  654, ymm7,  16,  8)\
-X(YMM7D3,  655, ymm7,  24,  8)\
-X(YMM8D0,  656, ymm8,   0,  8)\
-X(YMM8D1,  657, ymm8,   8,  8)\
-X(YMM8D2,  658, ymm8,  16,  8)\
-X(YMM8D3,  659, ymm8,  24,  8)\
-X(YMM9D0,  660, ymm9,   0,  8)\
-X(YMM9D1,  661, ymm9,   8,  8)\
-X(YMM9D2,  662, ymm9,  16,  8)\
-X(YMM9D3,  663, ymm9,  24,  8)\
-X(YMM10D0, 664, ymm10,  0,  8)\
-X(YMM10D1, 665, ymm10,  8,  8)\
-X(YMM10D2, 666, ymm10, 16,  8)\
-X(YMM10D3, 667, ymm10, 24,  8)\
-X(YMM11D0, 668, ymm11,  0,  8)\
-X(YMM11D1, 669, ymm11,  8,  8)\
-X(YMM11D2, 670, ymm11, 16,  8)\
-X(YMM11D3, 671, ymm11, 24,  8)\
-X(YMM12D0, 672, ymm12,  0,  8)\
-X(YMM12D1, 673, ymm12,  8,  8)\
-X(YMM12D2, 674, ymm12, 16,  8)\
-X(YMM12D3, 675, ymm12, 24,  8)\
-X(YMM13D0, 676, ymm13,  0,  8)\
-X(YMM13D1, 677, ymm13,  8,  8)\
-X(YMM13D2, 678, ymm13, 16,  8)\
-X(YMM13D3, 679, ymm13, 24,  8)\
-X(YMM14D0, 680, ymm14,  0,  8)\
-X(YMM14D1, 681, ymm14,  8,  8)\
-X(YMM14D2, 682, ymm14, 16,  8)\
-X(YMM14D3, 683, ymm14, 24,  8)\
-X(YMM15D0, 684, ymm15,  0,  8)\
-X(YMM15D1, 685, ymm15,  8,  8)\
-X(YMM15D2, 686, ymm15, 16,  8)\
-X(YMM15D3, 687, ymm15, 24,  8)
+X(YMM0,    368, zmm0,   0, 32)\
+X(YMM1,    369, zmm1,   0, 32)\
+X(YMM2,    370, zmm2,   0, 32)\
+X(YMM3,    371, zmm3,   0, 32)\
+X(YMM4,    372, zmm4,   0, 32)\
+X(YMM5,    373, zmm5,   0, 32)\
+X(YMM6,    374, zmm6,   0, 32)\
+X(YMM7,    375, zmm7,   0, 32)\
+X(YMM8,    376, zmm8,   0, 32)\
+X(YMM9,    377, zmm9,   0, 32)\
+X(YMM10,   378, zmm10,  0, 32)\
+X(YMM11,   379, zmm11,  0, 32)\
+X(YMM12,   380, zmm12,  0, 32)\
+X(YMM13,   381, zmm13,  0, 32)\
+X(YMM14,   382, zmm14,  0, 32)\
+X(YMM15,   383, zmm15,  0, 32)\
+X(YMM0H,   384, zmm0,  16, 32)\
+X(YMM1H,   385, zmm1,  16, 32)\
+X(YMM2H,   386, zmm2,  16, 32)\
+X(YMM3H,   387, zmm3,  16, 32)\
+X(YMM4H,   388, zmm4,  16, 32)\
+X(YMM5H,   389, zmm5,  16, 32)\
+X(YMM6H,   390, zmm6,  16, 32)\
+X(YMM7H,   391, zmm7,  16, 32)\
+X(YMM8H,   392, zmm8,  16, 32)\
+X(YMM9H,   393, zmm9,  16, 32)\
+X(YMM10H,  394, zmm10, 16, 32)\
+X(YMM11H,  395, zmm11, 16, 32)\
+X(YMM12H,  396, zmm12, 16, 32)\
+X(YMM13H,  397, zmm13, 16, 32)\
+X(YMM14H,  398, zmm14, 16, 32)\
+X(YMM15H,  399, zmm15, 16, 32)\
+X(XMM0IL,  400, zmm0,   0,  8)\
+X(XMM1IL,  401, zmm1,   0,  8)\
+X(XMM2IL,  402, zmm2,   0,  8)\
+X(XMM3IL,  403, zmm3,   0,  8)\
+X(XMM4IL,  404, zmm4,   0,  8)\
+X(XMM5IL,  405, zmm5,   0,  8)\
+X(XMM6IL,  406, zmm6,   0,  8)\
+X(XMM7IL,  407, zmm7,   0,  8)\
+X(XMM8IL,  408, zmm8,   0,  8)\
+X(XMM9IL,  409, zmm9,   0,  8)\
+X(XMM10IL, 410, zmm10,  0,  8)\
+X(XMM11IL, 411, zmm11,  0,  8)\
+X(XMM12IL, 412, zmm12,  0,  8)\
+X(XMM13IL, 413, zmm13,  0,  8)\
+X(XMM14IL, 414, zmm14,  0,  8)\
+X(XMM15IL, 415, zmm15,  0,  8)\
+X(XMM0IH,  416, zmm0,   8,  8)\
+X(XMM1IH,  417, zmm1,   8,  8)\
+X(XMM2IH,  418, zmm2,   8,  8)\
+X(XMM3IH,  419, zmm3,   8,  8)\
+X(XMM4IH,  420, zmm4,   8,  8)\
+X(XMM5IH,  421, zmm5,   8,  8)\
+X(XMM6IH,  422, zmm6,   8,  8)\
+X(XMM7IH,  423, zmm7,   8,  8)\
+X(XMM8IH,  424, zmm8,   8,  8)\
+X(XMM9IH,  425, zmm9,   8,  8)\
+X(XMM10IH, 426, zmm10,  8,  8)\
+X(XMM11IH, 427, zmm11,  8,  8)\
+X(XMM12IH, 428, zmm12,  8,  8)\
+X(XMM13IH, 429, zmm13,  8,  8)\
+X(XMM14IH, 430, zmm14,  8,  8)\
+X(XMM15IH, 431, zmm15,  8,  8)\
+X(YMM0I0,  432, zmm0,   0,  8)\
+X(YMM0I1,  433, zmm0,   8,  8)\
+X(YMM0I2,  434, zmm0,  16,  8)\
+X(YMM0I3,  435, zmm0,  24,  8)\
+X(YMM1I0,  436, zmm1,   0,  8)\
+X(YMM1I1,  437, zmm1,   8,  8)\
+X(YMM1I2,  438, zmm1,  16,  8)\
+X(YMM1I3,  439, zmm1,  24,  8)\
+X(YMM2I0,  440, zmm2,   0,  8)\
+X(YMM2I1,  441, zmm2,   8,  8)\
+X(YMM2I2,  442, zmm2,  16,  8)\
+X(YMM2I3,  443, zmm2,  24,  8)\
+X(YMM3I0,  444, zmm3,   0,  8)\
+X(YMM3I1,  445, zmm3,   8,  8)\
+X(YMM3I2,  446, zmm3,  16,  8)\
+X(YMM3I3,  447, zmm3,  24,  8)\
+X(YMM4I0,  448, zmm4,   0,  8)\
+X(YMM4I1,  449, zmm4,   8,  8)\
+X(YMM4I2,  450, zmm4,  16,  8)\
+X(YMM4I3,  451, zmm4,  24,  8)\
+X(YMM5I0,  452, zmm5,   0,  8)\
+X(YMM5I1,  453, zmm5,   8,  8)\
+X(YMM5I2,  454, zmm5,  16,  8)\
+X(YMM5I3,  455, zmm5,  24,  8)\
+X(YMM6I0,  456, zmm6,   0,  8)\
+X(YMM6I1,  457, zmm6,   8,  8)\
+X(YMM6I2,  458, zmm6,  16,  8)\
+X(YMM6I3,  459, zmm6,  24,  8)\
+X(YMM7I0,  460, zmm7,   0,  8)\
+X(YMM7I1,  461, zmm7,   8,  8)\
+X(YMM7I2,  462, zmm7,  16,  8)\
+X(YMM7I3,  463, zmm7,  24,  8)\
+X(YMM8I0,  464, zmm8,   0,  8)\
+X(YMM8I1,  465, zmm8,   8,  8)\
+X(YMM8I2,  466, zmm8,  16,  8)\
+X(YMM8I3,  467, zmm8,  24,  8)\
+X(YMM9I0,  468, zmm9,   0,  8)\
+X(YMM9I1,  469, zmm9,   8,  8)\
+X(YMM9I2,  470, zmm9,  16,  8)\
+X(YMM9I3,  471, zmm9,  24,  8)\
+X(YMM10I0, 472, zmm10,  0,  8)\
+X(YMM10I1, 473, zmm10,  8,  8)\
+X(YMM10I2, 474, zmm10, 16,  8)\
+X(YMM10I3, 475, zmm10, 24,  8)\
+X(YMM11I0, 476, zmm11,  0,  8)\
+X(YMM11I1, 477, zmm11,  8,  8)\
+X(YMM11I2, 478, zmm11, 16,  8)\
+X(YMM11I3, 479, zmm11, 24,  8)\
+X(YMM12I0, 480, zmm12,  0,  8)\
+X(YMM12I1, 481, zmm12,  8,  8)\
+X(YMM12I2, 482, zmm12, 16,  8)\
+X(YMM12I3, 483, zmm12, 24,  8)\
+X(YMM13I0, 484, zmm13,  0,  8)\
+X(YMM13I1, 485, zmm13,  8,  8)\
+X(YMM13I2, 486, zmm13, 16,  8)\
+X(YMM13I3, 487, zmm13, 24,  8)\
+X(YMM14I0, 488, zmm14,  0,  8)\
+X(YMM14I1, 489, zmm14,  8,  8)\
+X(YMM14I2, 490, zmm14, 16,  8)\
+X(YMM14I3, 491, zmm14, 24,  8)\
+X(YMM15I0, 492, zmm15,  0,  8)\
+X(YMM15I1, 493, zmm15,  8,  8)\
+X(YMM15I2, 494, zmm15, 16,  8)\
+X(YMM15I3, 495, zmm15, 24,  8)\
+X(YMM0F0,  496, zmm0,   0,  4)\
+X(YMM0F1,  497, zmm0,   4,  4)\
+X(YMM0F2,  498, zmm0,   8,  4)\
+X(YMM0F3,  499, zmm0,  12,  4)\
+X(YMM0F4,  500, zmm0,  16,  4)\
+X(YMM0F5,  501, zmm0,  20,  4)\
+X(YMM0F6,  502, zmm0,  24,  4)\
+X(YMM0F7,  503, zmm0,  28,  4)\
+X(YMM1F0,  504, zmm1,   0,  4)\
+X(YMM1F1,  505, zmm1,   4,  4)\
+X(YMM1F2,  506, zmm1,   8,  4)\
+X(YMM1F3,  507, zmm1,  12,  4)\
+X(YMM1F4,  508, zmm1,  16,  4)\
+X(YMM1F5,  509, zmm1,  20,  4)\
+X(YMM1F6,  510, zmm1,  24,  4)\
+X(YMM1F7,  511, zmm1,  28,  4)\
+X(YMM2F0,  512, zmm2,   0,  4)\
+X(YMM2F1,  513, zmm2,   4,  4)\
+X(YMM2F2,  514, zmm2,   8,  4)\
+X(YMM2F3,  515, zmm2,  12,  4)\
+X(YMM2F4,  516, zmm2,  16,  4)\
+X(YMM2F5,  517, zmm2,  20,  4)\
+X(YMM2F6,  518, zmm2,  24,  4)\
+X(YMM2F7,  519, zmm2,  28,  4)\
+X(YMM3F0,  520, zmm3,   0,  4)\
+X(YMM3F1,  521, zmm3,   4,  4)\
+X(YMM3F2,  522, zmm3,   8,  4)\
+X(YMM3F3,  523, zmm3,  12,  4)\
+X(YMM3F4,  524, zmm3,  16,  4)\
+X(YMM3F5,  525, zmm3,  20,  4)\
+X(YMM3F6,  526, zmm3,  24,  4)\
+X(YMM3F7,  527, zmm3,  28,  4)\
+X(YMM4F0,  528, zmm4,   0,  4)\
+X(YMM4F1,  529, zmm4,   4,  4)\
+X(YMM4F2,  530, zmm4,   8,  4)\
+X(YMM4F3,  531, zmm4,  12,  4)\
+X(YMM4F4,  532, zmm4,  16,  4)\
+X(YMM4F5,  533, zmm4,  20,  4)\
+X(YMM4F6,  534, zmm4,  24,  4)\
+X(YMM4F7,  535, zmm4,  28,  4)\
+X(YMM5F0,  536, zmm5,   0,  4)\
+X(YMM5F1,  537, zmm5,   4,  4)\
+X(YMM5F2,  538, zmm5,   8,  4)\
+X(YMM5F3,  539, zmm5,  12,  4)\
+X(YMM5F4,  540, zmm5,  16,  4)\
+X(YMM5F5,  541, zmm5,  20,  4)\
+X(YMM5F6,  542, zmm5,  24,  4)\
+X(YMM5F7,  543, zmm5,  28,  4)\
+X(YMM6F0,  544, zmm6,   0,  4)\
+X(YMM6F1,  545, zmm6,   4,  4)\
+X(YMM6F2,  546, zmm6,   8,  4)\
+X(YMM6F3,  547, zmm6,  12,  4)\
+X(YMM6F4,  548, zmm6,  16,  4)\
+X(YMM6F5,  549, zmm6,  20,  4)\
+X(YMM6F6,  550, zmm6,  24,  4)\
+X(YMM6F7,  551, zmm6,  28,  4)\
+X(YMM7F0,  552, zmm7,   0,  4)\
+X(YMM7F1,  553, zmm7,   4,  4)\
+X(YMM7F2,  554, zmm7,   8,  4)\
+X(YMM7F3,  555, zmm7,  12,  4)\
+X(YMM7F4,  556, zmm7,  16,  4)\
+X(YMM7F5,  557, zmm7,  20,  4)\
+X(YMM7F6,  558, zmm7,  24,  4)\
+X(YMM7F7,  559, zmm7,  28,  4)\
+X(YMM8F0,  560, zmm8,   0,  4)\
+X(YMM8F1,  561, zmm8,   4,  4)\
+X(YMM8F2,  562, zmm8,   8,  4)\
+X(YMM8F3,  563, zmm8,  12,  4)\
+X(YMM8F4,  564, zmm8,  16,  4)\
+X(YMM8F5,  565, zmm8,  20,  4)\
+X(YMM8F6,  566, zmm8,  24,  4)\
+X(YMM8F7,  567, zmm8,  28,  4)\
+X(YMM9F0,  568, zmm9,   0,  4)\
+X(YMM9F1,  569, zmm9,   4,  4)\
+X(YMM9F2,  570, zmm9,   8,  4)\
+X(YMM9F3,  571, zmm9,  12,  4)\
+X(YMM9F4,  572, zmm9,  16,  4)\
+X(YMM9F5,  573, zmm9,  20,  4)\
+X(YMM9F6,  574, zmm9,  24,  4)\
+X(YMM9F7,  575, zmm9,  28,  4)\
+X(YMM10F0, 576, zmm10,  0,  4)\
+X(YMM10F1, 577, zmm10,  4,  4)\
+X(YMM10F2, 578, zmm10,  8,  4)\
+X(YMM10F3, 579, zmm10, 12,  4)\
+X(YMM10F4, 580, zmm10, 16,  4)\
+X(YMM10F5, 581, zmm10, 20,  4)\
+X(YMM10F6, 582, zmm10, 24,  4)\
+X(YMM10F7, 583, zmm10, 28,  4)\
+X(YMM11F0, 584, zmm11,  0,  4)\
+X(YMM11F1, 585, zmm11,  4,  4)\
+X(YMM11F2, 586, zmm11,  8,  4)\
+X(YMM11F3, 587, zmm11, 12,  4)\
+X(YMM11F4, 588, zmm11, 16,  4)\
+X(YMM11F5, 589, zmm11, 20,  4)\
+X(YMM11F6, 590, zmm11, 24,  4)\
+X(YMM11F7, 591, zmm11, 28,  4)\
+X(YMM12F0, 592, zmm12,  0,  4)\
+X(YMM12F1, 593, zmm12,  4,  4)\
+X(YMM12F2, 594, zmm12,  8,  4)\
+X(YMM12F3, 595, zmm12, 12,  4)\
+X(YMM12F4, 596, zmm12, 16,  4)\
+X(YMM12F5, 597, zmm12, 20,  4)\
+X(YMM12F6, 598, zmm12, 24,  4)\
+X(YMM12F7, 599, zmm12, 28,  4)\
+X(YMM13F0, 600, zmm13,  0,  4)\
+X(YMM13F1, 601, zmm13,  4,  4)\
+X(YMM13F2, 602, zmm13,  8,  4)\
+X(YMM13F3, 603, zmm13, 12,  4)\
+X(YMM13F4, 604, zmm13, 16,  4)\
+X(YMM13F5, 605, zmm13, 20,  4)\
+X(YMM13F6, 606, zmm13, 24,  4)\
+X(YMM13F7, 607, zmm13, 28,  4)\
+X(YMM14F0, 608, zmm14,  0,  4)\
+X(YMM14F1, 609, zmm14,  4,  4)\
+X(YMM14F2, 610, zmm14,  8,  4)\
+X(YMM14F3, 611, zmm14, 12,  4)\
+X(YMM14F4, 612, zmm14, 16,  4)\
+X(YMM14F5, 613, zmm14, 20,  4)\
+X(YMM14F6, 614, zmm14, 24,  4)\
+X(YMM14F7, 615, zmm14, 28,  4)\
+X(YMM15F0, 616, zmm15,  0,  4)\
+X(YMM15F1, 617, zmm15,  4,  4)\
+X(YMM15F2, 618, zmm15,  8,  4)\
+X(YMM15F3, 619, zmm15, 12,  4)\
+X(YMM15F4, 620, zmm15, 16,  4)\
+X(YMM15F5, 621, zmm15, 20,  4)\
+X(YMM15F6, 622, zmm15, 24,  4)\
+X(YMM15F7, 623, zmm15, 28,  4)\
+X(YMM0D0,  624, zmm0,   0,  8)\
+X(YMM0D1,  625, zmm0,   8,  8)\
+X(YMM0D2,  626, zmm0,  16,  8)\
+X(YMM0D3,  627, zmm0,  24,  8)\
+X(YMM1D0,  628, zmm1,   0,  8)\
+X(YMM1D1,  629, zmm1,   8,  8)\
+X(YMM1D2,  630, zmm1,  16,  8)\
+X(YMM1D3,  631, zmm1,  24,  8)\
+X(YMM2D0,  632, zmm2,   0,  8)\
+X(YMM2D1,  633, zmm2,   8,  8)\
+X(YMM2D2,  634, zmm2,  16,  8)\
+X(YMM2D3,  635, zmm2,  24,  8)\
+X(YMM3D0,  636, zmm3,   0,  8)\
+X(YMM3D1,  637, zmm3,   8,  8)\
+X(YMM3D2,  638, zmm3,  16,  8)\
+X(YMM3D3,  639, zmm3,  24,  8)\
+X(YMM4D0,  640, zmm4,   0,  8)\
+X(YMM4D1,  641, zmm4,   8,  8)\
+X(YMM4D2,  642, zmm4,  16,  8)\
+X(YMM4D3,  643, zmm4,  24,  8)\
+X(YMM5D0,  644, zmm5,   0,  8)\
+X(YMM5D1,  645, zmm5,   8,  8)\
+X(YMM5D2,  646, zmm5,  16,  8)\
+X(YMM5D3,  647, zmm5,  24,  8)\
+X(YMM6D0,  648, zmm6,   0,  8)\
+X(YMM6D1,  649, zmm6,   8,  8)\
+X(YMM6D2,  650, zmm6,  16,  8)\
+X(YMM6D3,  651, zmm6,  24,  8)\
+X(YMM7D0,  652, zmm7,   0,  8)\
+X(YMM7D1,  653, zmm7,   8,  8)\
+X(YMM7D2,  654, zmm7,  16,  8)\
+X(YMM7D3,  655, zmm7,  24,  8)\
+X(YMM8D0,  656, zmm8,   0,  8)\
+X(YMM8D1,  657, zmm8,   8,  8)\
+X(YMM8D2,  658, zmm8,  16,  8)\
+X(YMM8D3,  659, zmm8,  24,  8)\
+X(YMM9D0,  660, zmm9,   0,  8)\
+X(YMM9D1,  661, zmm9,   8,  8)\
+X(YMM9D2,  662, zmm9,  16,  8)\
+X(YMM9D3,  663, zmm9,  24,  8)\
+X(YMM10D0, 664, zmm10,  0,  8)\
+X(YMM10D1, 665, zmm10,  8,  8)\
+X(YMM10D2, 666, zmm10, 16,  8)\
+X(YMM10D3, 667, zmm10, 24,  8)\
+X(YMM11D0, 668, zmm11,  0,  8)\
+X(YMM11D1, 669, zmm11,  8,  8)\
+X(YMM11D2, 670, zmm11, 16,  8)\
+X(YMM11D3, 671, zmm11, 24,  8)\
+X(YMM12D0, 672, zmm12,  0,  8)\
+X(YMM12D1, 673, zmm12,  8,  8)\
+X(YMM12D2, 674, zmm12, 16,  8)\
+X(YMM12D3, 675, zmm12, 24,  8)\
+X(YMM13D0, 676, zmm13,  0,  8)\
+X(YMM13D1, 677, zmm13,  8,  8)\
+X(YMM13D2, 678, zmm13, 16,  8)\
+X(YMM13D3, 679, zmm13, 24,  8)\
+X(YMM14D0, 680, zmm14,  0,  8)\
+X(YMM14D1, 681, zmm14,  8,  8)\
+X(YMM14D2, 682, zmm14, 16,  8)\
+X(YMM14D3, 683, zmm14, 24,  8)\
+X(YMM15D0, 684, zmm15,  0,  8)\
+X(YMM15D1, 685, zmm15,  8,  8)\
+X(YMM15D2, 686, zmm15, 16,  8)\
+X(YMM15D3, 687, zmm15, 24,  8)
 
 typedef U16 CV_Regx64;
 typedef enum CV_Regx64Enum
diff --git a/src/ctrl/ctrl_core.c b/src/ctrl/ctrl_core.c
index bdb956430..78c2ec017 100644
--- a/src/ctrl/ctrl_core.c
+++ b/src/ctrl/ctrl_core.c
@@ -2429,7 +2429,7 @@ ctrl_unwind_step__pe_x64(CTRL_EntityStore *store, CTRL_MachineID machine_id, DMN
               }
               
               // rjf: commit to register
-              void *xmm_reg = (&regs->ymm0) + op_info;
+              void *xmm_reg = (&regs->zmm0) + op_info;
               MemoryCopy(xmm_reg, buf, sizeof(buf));
             }break;
             
@@ -2448,7 +2448,7 @@ ctrl_unwind_step__pe_x64(CTRL_EntityStore *store, CTRL_MachineID machine_id, DMN
               }
               
               // rjf: commit to register
-              void *xmm_reg = (&regs->ymm0) + op_info;
+              void *xmm_reg = (&regs->zmm0) + op_info;
               MemoryCopy(xmm_reg, buf, sizeof(buf));
             }break;
             
diff --git a/src/demon/win32/demon_core_win32.c b/src/demon/win32/demon_core_win32.c
index b8098bff0..e46e8438c 100644
--- a/src/demon/win32/demon_core_win32.c
+++ b/src/demon/win32/demon_core_win32.c
@@ -686,15 +686,11 @@ dmn_w32_thread_read_reg_block(Architecture arch, HANDLE thread, void *reg_block)
       
       //- rjf: unpack info about available features
       U32 feature_mask = GetEnabledXStateFeatures();
-      B32 avx_enabled = !!(feature_mask & XSTATE_MASK_AVX);
+      B32 xstate_enabled = (feature_mask & (XSTATE_MASK_AVX | XSTATE_MASK_AVX512)) != 0;
       
       //- rjf: set up context
       CONTEXT *ctx = 0;
-      U32 ctx_flags = DMN_W32_CTX_X64_ALL;
-      if(avx_enabled)
-      {
-        ctx_flags |= DMN_W32_CTX_INTEL_XSTATE;
-      }
+      U32 ctx_flags = DMN_W32_CTX_X64_ALL | (xstate_enabled ? DMN_W32_CTX_INTEL_XSTATE : 0);
       DWORD size = 0;
       InitializeContext(0, ctx_flags, 0, &size);
       if(GetLastError() == ERROR_INSUFFICIENT_BUFFER)
@@ -707,18 +703,9 @@ dmn_w32_thread_read_reg_block(Architecture arch, HANDLE thread, void *reg_block)
       }
       
       //- rjf: unpack features available on this context
-      B32 avx_available = 0;
-      if(ctx != 0)
+      if (xstate_enabled)
       {
-        if(avx_enabled)
-        {
-          SetXStateFeaturesMask(ctx, XSTATE_MASK_AVX);
-        }
-        DWORD64 xstate_flags = 0;
-        if(GetXStateFeaturesMask(ctx, &xstate_flags))
-        {
-          avx_available = !!(xstate_flags & XSTATE_MASK_AVX);
-        }
+        SetXStateFeaturesMask(ctx, XSTATE_MASK_AVX | XSTATE_MASK_AVX512);
       }
       
       //- rjf: get thread context
@@ -733,6 +720,9 @@ dmn_w32_thread_read_reg_block(Architecture arch, HANDLE thread, void *reg_block)
         break;
       }
       result = 1;
+
+      DWORD64 xstate_mask = 0;
+      GetXStateFeaturesMask(ctx, &xstate_mask);
       
       //- rjf: convert context -> REGS_RegBlockX64
       XSAVE_FORMAT *xsave = &ctx->FltSave;
@@ -786,35 +776,93 @@ dmn_w32_thread_read_reg_block(Architecture arch, HANDLE thread, void *reg_block)
           MemoryCopy(float_d, float_s, sizeof(*float_d));
         }
       }
-      if(!avx_available)
+
+      // SSE registers are always available in x64
       {
         M128A *xmm_s = xsave->XmmRegisters;
-        REGS_Reg256 *xmm_d = &dst->ymm0;
-        for(U32 n = 0; n < 16; n += 1, xmm_s += 1, xmm_d += 1)
+        REGS_Reg512 *zmm_d = &dst->zmm0;
+        for(U32 n = 0; n < 16; n += 1, xmm_s += 1, zmm_d += 1)
         {
-          MemoryCopy(xmm_d, xmm_s, sizeof(*xmm_s));
+          MemoryCopy(zmm_d, xmm_s, sizeof(*xmm_s));
         }
       }
-      if(avx_available)
-      {
-        DWORD part0_length = 0;
-        M128A *part0 = (M128A*)LocateXStateFeature(ctx, XSTATE_LEGACY_SSE, &part0_length);
-        DWORD part1_length = 0;
-        M128A *part1 = (M128A*)LocateXStateFeature(ctx, XSTATE_AVX, &part1_length);
-        Assert(part0_length == part1_length);
-        DWORD count = part0_length/sizeof(part0[0]);
-        count = ClampTop(count, 16);
-        REGS_Reg256 *ymm_d = &dst->ymm0;
-        for (DWORD i = 0; i < count; i += 1, part0 += 1, part1 += 1, ymm_d += 1)
+
+      // AVX
+      if(xstate_mask & XSTATE_MASK_AVX)
+      {
+        DWORD avx_length = 0;
+        U8* avx_s = (U8*)LocateXStateFeature(ctx, XSTATE_AVX, &avx_length);
+        Assert(avx_length == 16 * sizeof(REGS_Reg128));
+
+        REGS_Reg512 *zmm_d = &dst->zmm0;
+        for(U32 n = 0; n < 16; n += 1, avx_s += sizeof(REGS_Reg128), zmm_d += 1)
         {
-          // TODO(rjf): confirm ordering of writes
-          ymm_d->u64[3] = part0->Low;
-          ymm_d->u64[2] = part0->High;
-          ymm_d->u64[1] = part1->Low;
-          ymm_d->u64[0] = part1->High;
+          MemoryCopy(&zmm_d->v[16], avx_s, sizeof(REGS_Reg128));
         }
       }
-      
+      else
+      {
+        REGS_Reg512 *zmm_d = &dst->zmm0;
+        for(U32 n = 0; n < 16; n += 1, zmm_d += 1)
+        {
+          MemoryZero(&zmm_d->v[16], sizeof(REGS_Reg128));
+        }
+      }
+
+      // AVX-512
+      if(xstate_mask & XSTATE_MASK_AVX512)
+      {
+        DWORD kmask_length = 0;
+        U64* kmask_s = (U64*)LocateXStateFeature(ctx, XSTATE_AVX512_KMASK, &kmask_length);
+        Assert(kmask_length == 8 * sizeof(U64));
+
+        REGS_Reg64 *kmask_d = &dst->k0;
+        for(U32 n = 0; n < 8; n += 1, kmask_s += 1, kmask_d += 1)
+        {
+          MemoryCopy(kmask_d, kmask_s, sizeof(*kmask_s));
+        }
+
+        DWORD avx512h_length = 0;
+        U8* avx512h_s = (U8*)LocateXStateFeature(ctx, XSTATE_AVX512_ZMM_H, &avx512h_length);
+        Assert(avx512h_length == 16 * sizeof(REGS_Reg256));
+
+        REGS_Reg512 *zmmh_d = &dst->zmm0;
+        for(U32 n = 0; n < 16; n += 1, avx512h_s += sizeof(REGS_Reg256), zmmh_d += 1)
+        {
+          MemoryCopy(&zmmh_d->v[32], avx512h_s, sizeof(REGS_Reg256));
+        }
+
+        DWORD avx512_length = 0;
+        U8* avx512_s = (U8*)LocateXStateFeature(ctx, XSTATE_AVX512_ZMM, &avx512_length);
+        Assert(avx512_length == 16 * sizeof(REGS_Reg512));
+
+        REGS_Reg512 *zmm_d = &dst->zmm16;
+        for(U32 n = 0; n < 16; n += 1, avx512_s += sizeof(REGS_Reg512), zmm_d += 1)
+        {
+          MemoryCopy(zmm_d, avx512_s, sizeof(REGS_Reg512));
+        }
+      }
+      else
+      {
+        REGS_Reg64 *kmask_d = &dst->k0;
+        for(U32 n = 0; n < 8; n += 1, kmask_d += 1)
+        {
+          MemoryZero(kmask_d, sizeof(*kmask_d));
+        }
+
+        REGS_Reg512 *zmmh_d = &dst->zmm0;
+        for(U32 n = 0; n < 16; n += 1, zmmh_d += 1)
+        {
+          MemoryZero(&zmmh_d->v[32], sizeof(REGS_Reg256));
+        }
+
+        REGS_Reg512 *zmm_d = &dst->zmm16;
+        for(U32 n = 0; n < 16; n += 1, zmm_d += 1)
+        {
+          MemoryZero(zmm_d, sizeof(*zmm_d));
+        }
+      }
+
       scratch_end(scratch);
     }break;
   }
@@ -917,15 +965,11 @@ dmn_w32_thread_write_reg_block(Architecture arch, HANDLE thread, void *reg_block
       
       //- rjf: unpack info about available features
       U32 feature_mask = GetEnabledXStateFeatures();
-      B32 avx_enabled = !!(feature_mask & XSTATE_MASK_AVX);
+      B32 xstate_enabled = (feature_mask & (XSTATE_MASK_AVX | XSTATE_MASK_AVX512)) != 0;
       
       //- rjf: set up context
       CONTEXT *ctx = 0;
-      U32 ctx_flags = DMN_W32_CTX_X64_ALL;
-      if(avx_enabled)
-      {
-        ctx_flags |= DMN_W32_CTX_INTEL_XSTATE;
-      }
+      U32 ctx_flags = DMN_W32_CTX_X64_ALL | (xstate_enabled ? DMN_W32_CTX_INTEL_XSTATE : 0);
       DWORD size = 0;
       InitializeContext(0, ctx_flags, 0, &size);
       if(GetLastError() == ERROR_INSUFFICIENT_BUFFER)
@@ -938,30 +982,14 @@ dmn_w32_thread_write_reg_block(Architecture arch, HANDLE thread, void *reg_block
       }
       
       //- rjf: unpack features available on this context
-      B32 avx_available = 0;
-      if(ctx != 0)
+      if (xstate_enabled)
       {
-        if(avx_enabled)
-        {
-          SetXStateFeaturesMask(ctx, XSTATE_MASK_AVX);
-        }
-        DWORD64 xstate_flags = 0;
-        if(GetXStateFeaturesMask(ctx, &xstate_flags))
-        {
-          avx_available = !!(xstate_flags & XSTATE_MASK_AVX);
-        }
+        SetXStateFeaturesMask(ctx, XSTATE_MASK_AVX | XSTATE_MASK_AVX512);
       }
-      
-      //- rjf: get thread context
-      if(!GetThreadContext(thread, ctx))
-      {
-        ctx = 0;
-      }
-      
+
       //- rjf: bad context -> abort
       if(ctx == 0)
       {
-        DWORD error = GetLastError();
         break;
       }
       
@@ -1015,35 +1043,65 @@ dmn_w32_thread_write_reg_block(Architecture arch, HANDLE thread, void *reg_block
           MemoryCopy(float_d, float_s, 10);
         }
       }
-      if(!avx_available)
+
+      // SSE registers are always available in x64
       {
         M128A *xmm_d = fxsave->XmmRegisters;
-        REGS_Reg256 *xmm_s = &src->ymm0;
-        for(U32 n = 0; n < 8; n += 1, xmm_d += 1, xmm_s += 1)
+        REGS_Reg512 *zmm_s = &src->zmm0;
+        for(U32 n = 0; n < 16; n += 1, xmm_d += 1, zmm_s += 1)
         {
-          MemoryCopy(xmm_d, xmm_s, sizeof(*xmm_d));
+          MemoryCopy(xmm_d, zmm_s, sizeof(*xmm_d));
         }
       }
-      if(avx_available)
-      {
-        DWORD part0_length = 0;
-        M128A *part0 = (M128A*)LocateXStateFeature(ctx, XSTATE_LEGACY_SSE, &part0_length);
-        DWORD part1_length = 0;
-        M128A *part1 = (M128A*)LocateXStateFeature(ctx, XSTATE_AVX, &part1_length);
-        Assert(part0_length == part1_length);
-        DWORD count = part0_length/sizeof(part0[0]);
-        count = ClampTop(count, 16);
-        REGS_Reg256 *ymm_d = &src->ymm0;
-        for(DWORD i = 0; i < count; i += 1, part0 += 1, part1 += 1, ymm_d += 1)
+
+      // AVX
+      if(feature_mask & XSTATE_MASK_AVX)
+      {
+        DWORD avx_length = 0;
+        U8* avx_d = (U8*)LocateXStateFeature(ctx, XSTATE_AVX, &avx_length);
+        Assert(avx_length == 16 * sizeof(REGS_Reg128));
+
+        REGS_Reg512 *zmm_s = &src->zmm0;
+        for(U32 n = 0; n < 16; n += 1, avx_d += sizeof(REGS_Reg128), zmm_s += 1)
         {
-          // TODO(allen): Are we writing these out in the right order? Seems weird right?
-          part0->Low  = ymm_d->u64[3];
-          part0->High = ymm_d->u64[2];
-          part1->Low  = ymm_d->u64[1];
-          part1->High = ymm_d->u64[0];
+          MemoryCopy(avx_d, &zmm_s->v[16], sizeof(REGS_Reg128));
         }
       }
-      
+
+      // AVX-512
+      if(feature_mask & XSTATE_MASK_AVX512)
+      {
+        DWORD kmask_length = 0;
+        U64* kmask_d = (U64*)LocateXStateFeature(ctx, XSTATE_AVX512_KMASK, &kmask_length);
+        Assert(kmask_length == 8 * sizeof(*kmask_d));
+
+        REGS_Reg64 *kmask_s = &src->k0;
+        for(U32 n = 0; n < 8; n += 1, kmask_s += 1, kmask_d += 1)
+        {
+          MemoryCopy(kmask_d, kmask_s, sizeof(*kmask_d));
+        }
+
+        DWORD avx512h_length = 0;
+        U8* avx512h_d = (U8*)LocateXStateFeature(ctx, XSTATE_AVX512_ZMM_H, &avx512h_length);
+        Assert(avx512h_length == 16 * sizeof(REGS_Reg256));
+
+        REGS_Reg512 *zmmh_s = &src->zmm0;
+        for(U32 n = 0; n < 16; n += 1, avx512h_d += sizeof(REGS_Reg256), zmmh_s += 1)
+        {
+          MemoryCopy(avx512h_d, &zmmh_s->v[32], sizeof(REGS_Reg256));
+        }
+
+        DWORD avx512_length = 0;
+        U8* avx512_d = (U8*)LocateXStateFeature(ctx, XSTATE_AVX512_ZMM, &avx512_length);
+        Assert(avx512_length == 16 * sizeof(REGS_Reg512));
+
+        REGS_Reg512 *zmm_s = &src->zmm16;
+        for(U32 n = 0; n < 16; n += 1, avx512_d += sizeof(REGS_Reg512), zmm_s += 1)
+        {
+          MemoryCopy(avx512_d, zmm_s, sizeof(REGS_Reg512));
+        }
+      }
+
       //- rjf: set thread context
       if(SetThreadContext(thread, ctx))
       {
diff --git a/src/lib_rdi_format/rdi_format.h b/src/lib_rdi_format/rdi_format.h
index 6caf4e333..7b13079a6 100644
--- a/src/lib_rdi_format/rdi_format.h
+++ b/src/lib_rdi_format/rdi_format.h
@@ -238,34 +238,58 @@ RDI_RegCodeX64_fpr4       = 45,
 RDI_RegCodeX64_fpr5       = 46,
 RDI_RegCodeX64_fpr6       = 47,
 RDI_RegCodeX64_fpr7       = 48,
-RDI_RegCodeX64_ymm0       = 49,
-RDI_RegCodeX64_ymm1       = 50,
-RDI_RegCodeX64_ymm2       = 51,
-RDI_RegCodeX64_ymm3       = 52,
-RDI_RegCodeX64_ymm4       = 53,
-RDI_RegCodeX64_ymm5       = 54,
-RDI_RegCodeX64_ymm6       = 55,
-RDI_RegCodeX64_ymm7       = 56,
-RDI_RegCodeX64_ymm8       = 57,
-RDI_RegCodeX64_ymm9       = 58,
-RDI_RegCodeX64_ymm10      = 59,
-RDI_RegCodeX64_ymm11      = 60,
-RDI_RegCodeX64_ymm12      = 61,
-RDI_RegCodeX64_ymm13      = 62,
-RDI_RegCodeX64_ymm14      = 63,
-RDI_RegCodeX64_ymm15      = 64,
-RDI_RegCodeX64_mxcsr      = 65,
-RDI_RegCodeX64_fsbase     = 66,
-RDI_RegCodeX64_gsbase     = 67,
-RDI_RegCodeX64_fcw        = 68,
-RDI_RegCodeX64_fsw        = 69,
-RDI_RegCodeX64_ftw        = 70,
-RDI_RegCodeX64_fop        = 71,
-RDI_RegCodeX64_fcs        = 72,
-RDI_RegCodeX64_fds        = 73,
-RDI_RegCodeX64_fip        = 74,
-RDI_RegCodeX64_fdp        = 75,
-RDI_RegCodeX64_mxcsr_mask = 76,
+RDI_RegCodeX64_zmm0       = 49,
+RDI_RegCodeX64_zmm1       = 50,
+RDI_RegCodeX64_zmm2       = 51,
+RDI_RegCodeX64_zmm3       = 52,
+RDI_RegCodeX64_zmm4       = 53,
+RDI_RegCodeX64_zmm5       = 54,
+RDI_RegCodeX64_zmm6       = 55,
+RDI_RegCodeX64_zmm7       = 56,
+RDI_RegCodeX64_zmm8       = 57,
+RDI_RegCodeX64_zmm9       = 58,
+RDI_RegCodeX64_zmm10      = 59,
+RDI_RegCodeX64_zmm11      = 60,
+RDI_RegCodeX64_zmm12      = 61,
+RDI_RegCodeX64_zmm13      = 62,
+RDI_RegCodeX64_zmm14      = 63,
+RDI_RegCodeX64_zmm15      = 64,
+RDI_RegCodeX64_zmm16      = 65,
+RDI_RegCodeX64_zmm17      = 66,
+RDI_RegCodeX64_zmm18      = 67,
+RDI_RegCodeX64_zmm19      = 68,
+RDI_RegCodeX64_zmm20      = 69,
+RDI_RegCodeX64_zmm21      = 70,
+RDI_RegCodeX64_zmm22      = 71,
+RDI_RegCodeX64_zmm23      = 72,
+RDI_RegCodeX64_zmm24      = 73,
+RDI_RegCodeX64_zmm25      = 74,
+RDI_RegCodeX64_zmm26      = 75,
+RDI_RegCodeX64_zmm27      = 76,
+RDI_RegCodeX64_zmm28      = 77,
+RDI_RegCodeX64_zmm29      = 78,
+RDI_RegCodeX64_zmm30      = 79,
+RDI_RegCodeX64_zmm31      = 80,
+RDI_RegCodeX64_k0         = 81,
+RDI_RegCodeX64_k1         = 82,
+RDI_RegCodeX64_k2         = 83,
+RDI_RegCodeX64_k3         = 84,
+RDI_RegCodeX64_k4         = 85,
+RDI_RegCodeX64_k5         = 86,
+RDI_RegCodeX64_k6         = 87,
+RDI_RegCodeX64_k7         = 88,
+RDI_RegCodeX64_mxcsr      = 89,
+RDI_RegCodeX64_fsbase     = 90,
+RDI_RegCodeX64_gsbase     = 91,
+RDI_RegCodeX64_fcw        = 92,
+RDI_RegCodeX64_fsw        = 93,
+RDI_RegCodeX64_ftw        = 94,
+RDI_RegCodeX64_fop        = 95,
+RDI_RegCodeX64_fcs        = 96,
+RDI_RegCodeX64_fds        = 97,
+RDI_RegCodeX64_fip        = 98,
+RDI_RegCodeX64_fdp        = 99,
+RDI_RegCodeX64_mxcsr_mask = 100,
 } RDI_RegCodeX64Enum;
 
 typedef RDI_U32 RDI_BinarySectionFlags;
diff --git a/src/rdi_format/rdi_format.mdesk b/src/rdi_format/rdi_format.mdesk
index e292a5c68..5a02e3402 100644
--- a/src/rdi_format/rdi_format.mdesk
+++ b/src/rdi_format/rdi_format.mdesk
@@ -383,34 +383,58 @@ RDI_RegCodeX64Table:
   {fpr5            46}
   {fpr6            47}
   {fpr7            48}
-  {ymm0            49}
-  {ymm1            50}
-  {ymm2            51}
-  {ymm3            52}
-  {ymm4            53}
-  {ymm5            54}
-  {ymm6            55}
-  {ymm7            56}
-  {ymm8            57}
-  {ymm9            58}
-  {ymm10           59}
-  {ymm11           60}
-  {ymm12           61}
-  {ymm13           62}
-  {ymm14           63}
-  {ymm15           64}
-  {mxcsr           65}
-  {fsbase          66}
-  {gsbase          67}
-  {fcw             68}
-  {fsw             69}
-  {ftw             70}
-  {fop             71}
-  {fcs             72}
-  {fds             73}
-  {fip             74}
-  {fdp             75}
-  {mxcsr_mask      76}
+  {zmm0            49}
+  {zmm1            50}
+  {zmm2            51}
+  {zmm3            52}
+  {zmm4            53}
+  {zmm5            54}
+  {zmm6            55}
+  {zmm7            56}
+  {zmm8            57}
+  {zmm9            58}
+  {zmm10           59}
+  {zmm11           60}
+  {zmm12           61}
+  {zmm13           62}
+  {zmm14           63}
+  {zmm15           64}
+  {zmm16           65}
+  {zmm17           66}
+  {zmm18           67}
+  {zmm19           68}
+  {zmm20           69}
+  {zmm21           70}
+  {zmm22           71}
+  {zmm23           72}
+  {zmm24           73}
+  {zmm25           74}
+  {zmm26           75}
+  {zmm27           76}
+  {zmm28           77}
+  {zmm29           78}
+  {zmm30           79}
+  {zmm31           80}
+  {k0              81}
+  {k1              82}
+  {k2              83}
+  {k3              84}
+  {k4              85}
+  {k5              86}
+  {k6              87}
+  {k7              88}
+  {mxcsr           89}
+  {fsbase          90}
+  {gsbase          91}
+  {fcw             92}
+  {fsw             93}
+  {ftw             94}
+  {fop             95}
+  {fcs             96}
+  {fds             97}
+  {fip             98}
+  {fdp             99}
+  {mxcsr_mask      100}
 }
 
 @enum(RDI_U32) RDI_Arch:
diff --git a/src/regs/generated/regs.meta.c b/src/regs/generated/regs.meta.c
index 7b2286a83..6110bf11a 100644
--- a/src/regs/generated/regs.meta.c
+++ b/src/regs/generated/regs.meta.c
@@ -103,7 +103,7 @@ case Architecture_x86:{result = regs_g_alias_code_x86_usage_kind_table;}break;
 return result;
 }
 C_LINKAGE_BEGIN
-REGS_UsageKind regs_g_reg_code_x64_usage_kind_table[77] =
+REGS_UsageKind regs_g_reg_code_x64_usage_kind_table[101] =
 {
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
@@ -182,9 +182,33 @@ REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
 };
 
-REGS_UsageKind regs_g_alias_code_x64_usage_kind_table[80] =
+REGS_UsageKind regs_g_alias_code_x64_usage_kind_table[96] =
 {
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
@@ -266,9 +290,25 @@ REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
 REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
+REGS_UsageKind_Normal,
 };
 
-String8 regs_g_reg_code_x64_string_table[77] =
+String8 regs_g_reg_code_x64_string_table[101] =
 {
 str8_lit_comp(""),
 str8_lit_comp("rax"),
@@ -331,25 +371,49 @@ str8_lit_comp("ds"),
 str8_lit_comp("es"),
 str8_lit_comp("fs"),
 str8_lit_comp("gs"),
-str8_lit_comp("ymm0"),
-str8_lit_comp("ymm1"),
-str8_lit_comp("ymm2"),
-str8_lit_comp("ymm3"),
-str8_lit_comp("ymm4"),
-str8_lit_comp("ymm5"),
-str8_lit_comp("ymm6"),
-str8_lit_comp("ymm7"),
-str8_lit_comp("ymm8"),
-str8_lit_comp("ymm9"),
-str8_lit_comp("ymm10"),
-str8_lit_comp("ymm11"),
-str8_lit_comp("ymm12"),
-str8_lit_comp("ymm13"),
-str8_lit_comp("ymm14"),
-str8_lit_comp("ymm15"),
+str8_lit_comp("zmm0"),
+str8_lit_comp("zmm1"),
+str8_lit_comp("zmm2"),
+str8_lit_comp("zmm3"),
+str8_lit_comp("zmm4"),
+str8_lit_comp("zmm5"),
+str8_lit_comp("zmm6"),
+str8_lit_comp("zmm7"),
+str8_lit_comp("zmm8"),
+str8_lit_comp("zmm9"),
+str8_lit_comp("zmm10"),
+str8_lit_comp("zmm11"),
+str8_lit_comp("zmm12"),
+str8_lit_comp("zmm13"),
+str8_lit_comp("zmm14"),
+str8_lit_comp("zmm15"),
+str8_lit_comp("zmm16"),
+str8_lit_comp("zmm17"),
+str8_lit_comp("zmm18"),
+str8_lit_comp("zmm19"),
+str8_lit_comp("zmm20"),
+str8_lit_comp("zmm21"),
+str8_lit_comp("zmm22"),
+str8_lit_comp("zmm23"),
+str8_lit_comp("zmm24"),
+str8_lit_comp("zmm25"),
+str8_lit_comp("zmm26"),
+str8_lit_comp("zmm27"),
+str8_lit_comp("zmm28"),
+str8_lit_comp("zmm29"),
+str8_lit_comp("zmm30"),
+str8_lit_comp("zmm31"),
+str8_lit_comp("k0"),
+str8_lit_comp("k1"),
+str8_lit_comp("k2"),
+str8_lit_comp("k3"),
+str8_lit_comp("k4"),
+str8_lit_comp("k5"),
+str8_lit_comp("k6"),
+str8_lit_comp("k7"),
 };
 
-String8 regs_g_alias_code_x64_string_table[80] =
+String8 regs_g_alias_code_x64_string_table[96] =
 {
 str8_lit_comp(""),
 str8_lit_comp("eax"),
@@ -423,6 +487,22 @@ str8_lit_comp("xmm12"),
 str8_lit_comp("xmm13"),
 str8_lit_comp("xmm14"),
 str8_lit_comp("xmm15"),
+str8_lit_comp("ymm0"),
+str8_lit_comp("ymm1"),
+str8_lit_comp("ymm2"),
+str8_lit_comp("ymm3"),
+str8_lit_comp("ymm4"),
+str8_lit_comp("ymm5"),
+str8_lit_comp("ymm6"),
+str8_lit_comp("ymm7"),
+str8_lit_comp("ymm8"),
+str8_lit_comp("ymm9"),
+str8_lit_comp("ymm10"),
+str8_lit_comp("ymm11"),
+str8_lit_comp("ymm12"),
+str8_lit_comp("ymm13"),
+str8_lit_comp("ymm14"),
+str8_lit_comp("ymm15"),
 str8_lit_comp("mm0"),
 str8_lit_comp("mm1"),
 str8_lit_comp("mm2"),
@@ -433,7 +513,7 @@ str8_lit_comp("mm6"),
 str8_lit_comp("mm7"),
 };
 
-REGS_Rng regs_g_reg_code_x64_rng_table[77] =
+REGS_Rng regs_g_reg_code_x64_rng_table[101] =
 {
 {0},
 {(U16)OffsetOf(REGS_RegBlockX64, rax), 8},
@@ -496,25 +576,49 @@ REGS_Rng regs_g_reg_code_x64_rng_table[77] =
 {(U16)OffsetOf(REGS_RegBlockX64, es), 2},
 {(U16)OffsetOf(REGS_RegBlockX64, fs), 2},
 {(U16)OffsetOf(REGS_RegBlockX64, gs), 2},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm0), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm1), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm2), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm3), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm4), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm5), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm6), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm7), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm8), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm9), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm10), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm11), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm12), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm13), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm14), 32},
-{(U16)OffsetOf(REGS_RegBlockX64, ymm15), 32},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm0), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm1), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm2), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm3), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm4), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm5), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm6), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm7), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm8), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm9), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm10), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm11), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm12), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm13), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm14), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm15), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm16), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm17), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm18), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm19), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm20), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm21), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm22), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm23), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm24), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm25), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm26), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm27), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm28), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm29), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm30), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, zmm31), 64},
+{(U16)OffsetOf(REGS_RegBlockX64, k0), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k1), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k2), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k3), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k4), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k5), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k6), 8},
+{(U16)OffsetOf(REGS_RegBlockX64, k7), 8},
 };
 
-REGS_Slice regs_g_alias_code_x64_slice_table[80] =
+REGS_Slice regs_g_alias_code_x64_slice_table[96] =
 {
 {0},
 {REGS_RegCodeX64_rax, 0, 4},
@@ -572,22 +676,38 @@ REGS_Slice regs_g_alias_code_x64_slice_table[80] =
 {REGS_RegCodeX64_rcx, 1, 1},
 {REGS_RegCodeX64_rdx, 1, 1},
 {REGS_RegCodeX64_rbx, 1, 1},
-{REGS_RegCodeX64_ymm0, 0, 16},
-{REGS_RegCodeX64_ymm1, 0, 16},
-{REGS_RegCodeX64_ymm2, 0, 16},
-{REGS_RegCodeX64_ymm3, 0, 16},
-{REGS_RegCodeX64_ymm4, 0, 16},
-{REGS_RegCodeX64_ymm5, 0, 16},
-{REGS_RegCodeX64_ymm6, 0, 16},
-{REGS_RegCodeX64_ymm7, 0, 16},
-{REGS_RegCodeX64_ymm8, 0, 16},
-{REGS_RegCodeX64_ymm9, 0, 16},
-{REGS_RegCodeX64_ymm10, 0, 16},
-{REGS_RegCodeX64_ymm11, 0, 16},
-{REGS_RegCodeX64_ymm12, 0, 16},
-{REGS_RegCodeX64_ymm13, 0, 16},
-{REGS_RegCodeX64_ymm14, 0, 16},
-{REGS_RegCodeX64_ymm15, 0, 16},
+{REGS_RegCodeX64_zmm0, 0, 16},
+{REGS_RegCodeX64_zmm1, 0, 16},
+{REGS_RegCodeX64_zmm2, 0, 16},
+{REGS_RegCodeX64_zmm3, 0, 16},
+{REGS_RegCodeX64_zmm4, 0, 16},
+{REGS_RegCodeX64_zmm5, 0, 16},
+{REGS_RegCodeX64_zmm6, 0, 16},
+{REGS_RegCodeX64_zmm7, 0, 16},
+{REGS_RegCodeX64_zmm8, 0, 16},
+{REGS_RegCodeX64_zmm9, 0, 16},
+{REGS_RegCodeX64_zmm10, 0, 16},
+{REGS_RegCodeX64_zmm11, 0, 16},
+{REGS_RegCodeX64_zmm12, 0, 16},
+{REGS_RegCodeX64_zmm13, 0, 16},
+{REGS_RegCodeX64_zmm14, 0, 16},
+{REGS_RegCodeX64_zmm15, 0, 16},
+{REGS_RegCodeX64_zmm0, 0, 32},
+{REGS_RegCodeX64_zmm1, 0, 32},
+{REGS_RegCodeX64_zmm2, 0, 32},
+{REGS_RegCodeX64_zmm3, 0, 32},
+{REGS_RegCodeX64_zmm4, 0, 32},
+{REGS_RegCodeX64_zmm5, 0, 32},
+{REGS_RegCodeX64_zmm6, 0, 32},
+{REGS_RegCodeX64_zmm7, 0, 32},
+{REGS_RegCodeX64_zmm8, 0, 32},
+{REGS_RegCodeX64_zmm9, 0, 32},
+{REGS_RegCodeX64_zmm10, 0, 32},
+{REGS_RegCodeX64_zmm11, 0, 32},
+{REGS_RegCodeX64_zmm12, 0, 32},
+{REGS_RegCodeX64_zmm13, 0, 32},
+{REGS_RegCodeX64_zmm14, 0, 32},
+{REGS_RegCodeX64_zmm15, 0, 32},
 {REGS_RegCodeX64_fpr0, 0, 8},
 {REGS_RegCodeX64_fpr1, 0, 8},
 {REGS_RegCodeX64_fpr2, 0, 8},
diff --git a/src/regs/generated/regs.meta.h b/src/regs/generated/regs.meta.h
index 55732f1f7..c2abaac98 100644
--- a/src/regs/generated/regs.meta.h
+++ b/src/regs/generated/regs.meta.h
@@ -69,22 +69,46 @@ REGS_RegCodeX64_ds,
 REGS_RegCodeX64_es,
 REGS_RegCodeX64_fs,
 REGS_RegCodeX64_gs,
-REGS_RegCodeX64_ymm0,
-REGS_RegCodeX64_ymm1,
-REGS_RegCodeX64_ymm2,
-REGS_RegCodeX64_ymm3,
-REGS_RegCodeX64_ymm4,
-REGS_RegCodeX64_ymm5,
-REGS_RegCodeX64_ymm6,
-REGS_RegCodeX64_ymm7,
-REGS_RegCodeX64_ymm8,
-REGS_RegCodeX64_ymm9,
-REGS_RegCodeX64_ymm10,
-REGS_RegCodeX64_ymm11,
-REGS_RegCodeX64_ymm12,
-REGS_RegCodeX64_ymm13,
-REGS_RegCodeX64_ymm14,
-REGS_RegCodeX64_ymm15,
+REGS_RegCodeX64_zmm0,
+REGS_RegCodeX64_zmm1,
+REGS_RegCodeX64_zmm2,
+REGS_RegCodeX64_zmm3,
+REGS_RegCodeX64_zmm4,
+REGS_RegCodeX64_zmm5,
+REGS_RegCodeX64_zmm6,
+REGS_RegCodeX64_zmm7,
+REGS_RegCodeX64_zmm8,
+REGS_RegCodeX64_zmm9,
+REGS_RegCodeX64_zmm10,
+REGS_RegCodeX64_zmm11,
+REGS_RegCodeX64_zmm12,
+REGS_RegCodeX64_zmm13,
+REGS_RegCodeX64_zmm14,
+REGS_RegCodeX64_zmm15,
+REGS_RegCodeX64_zmm16,
+REGS_RegCodeX64_zmm17,
+REGS_RegCodeX64_zmm18,
+REGS_RegCodeX64_zmm19,
+REGS_RegCodeX64_zmm20,
+REGS_RegCodeX64_zmm21,
+REGS_RegCodeX64_zmm22,
+REGS_RegCodeX64_zmm23,
+REGS_RegCodeX64_zmm24,
+REGS_RegCodeX64_zmm25,
+REGS_RegCodeX64_zmm26,
+REGS_RegCodeX64_zmm27,
+REGS_RegCodeX64_zmm28,
+REGS_RegCodeX64_zmm29,
+REGS_RegCodeX64_zmm30,
+REGS_RegCodeX64_zmm31,
+REGS_RegCodeX64_k0,
+REGS_RegCodeX64_k1,
+REGS_RegCodeX64_k2,
+REGS_RegCodeX64_k3,
+REGS_RegCodeX64_k4,
+REGS_RegCodeX64_k5,
+REGS_RegCodeX64_k6,
+REGS_RegCodeX64_k7,
 REGS_RegCodeX64_COUNT,
 } REGS_RegCodeX64;
 
@@ -162,6 +186,22 @@ REGS_AliasCodeX64_xmm12,
 REGS_AliasCodeX64_xmm13,
 REGS_AliasCodeX64_xmm14,
 REGS_AliasCodeX64_xmm15,
+REGS_AliasCodeX64_ymm0,
+REGS_AliasCodeX64_ymm1,
+REGS_AliasCodeX64_ymm2,
+REGS_AliasCodeX64_ymm3,
+REGS_AliasCodeX64_ymm4,
+REGS_AliasCodeX64_ymm5,
+REGS_AliasCodeX64_ymm6,
+REGS_AliasCodeX64_ymm7,
+REGS_AliasCodeX64_ymm8,
+REGS_AliasCodeX64_ymm9,
+REGS_AliasCodeX64_ymm10,
+REGS_AliasCodeX64_ymm11,
+REGS_AliasCodeX64_ymm12,
+REGS_AliasCodeX64_ymm13,
+REGS_AliasCodeX64_ymm14,
+REGS_AliasCodeX64_ymm15,
 REGS_AliasCodeX64_mm0,
 REGS_AliasCodeX64_mm1,
 REGS_AliasCodeX64_mm2,
@@ -343,22 +383,46 @@ REGS_Reg16 ds;
 REGS_Reg16 es;
 REGS_Reg16 fs;
 REGS_Reg16 gs;
-REGS_Reg256 ymm0;
-REGS_Reg256 ymm1;
-REGS_Reg256 ymm2;
-REGS_Reg256 ymm3;
-REGS_Reg256 ymm4;
-REGS_Reg256 ymm5;
-REGS_Reg256 ymm6;
-REGS_Reg256 ymm7;
-REGS_Reg256 ymm8;
-REGS_Reg256 ymm9;
-REGS_Reg256 ymm10;
-REGS_Reg256 ymm11;
-REGS_Reg256 ymm12;
-REGS_Reg256 ymm13;
-REGS_Reg256 ymm14;
-REGS_Reg256 ymm15;
+REGS_Reg512 zmm0;
+REGS_Reg512 zmm1;
+REGS_Reg512 zmm2;
+REGS_Reg512 zmm3;
+REGS_Reg512 zmm4;
+REGS_Reg512 zmm5;
+REGS_Reg512 zmm6;
+REGS_Reg512 zmm7;
+REGS_Reg512 zmm8;
+REGS_Reg512 zmm9;
+REGS_Reg512 zmm10;
+REGS_Reg512 zmm11;
+REGS_Reg512 zmm12;
+REGS_Reg512 zmm13;
+REGS_Reg512 zmm14;
+REGS_Reg512 zmm15;
+REGS_Reg512 zmm16;
+REGS_Reg512 zmm17;
+REGS_Reg512 zmm18;
+REGS_Reg512 zmm19;
+REGS_Reg512 zmm20;
+REGS_Reg512 zmm21;
+REGS_Reg512 zmm22;
+REGS_Reg512 zmm23;
+REGS_Reg512 zmm24;
+REGS_Reg512 zmm25;
+REGS_Reg512 zmm26;
+REGS_Reg512 zmm27;
+REGS_Reg512 zmm28;
+REGS_Reg512 zmm29;
+REGS_Reg512 zmm30;
+REGS_Reg512 zmm31;
+REGS_Reg64 k0;
+REGS_Reg64 k1;
+REGS_Reg64 k2;
+REGS_Reg64 k3;
+REGS_Reg64 k4;
+REGS_Reg64 k5;
+REGS_Reg64 k6;
+REGS_Reg64 k7;
 };
 
 typedef struct REGS_RegBlockX86 REGS_RegBlockX86;
@@ -427,12 +491,12 @@ REGS_Reg256 ymm7;
 };
 
 C_LINKAGE_BEGIN
-extern REGS_UsageKind regs_g_reg_code_x64_usage_kind_table[77];
-extern REGS_UsageKind regs_g_alias_code_x64_usage_kind_table[80];
-extern String8 regs_g_reg_code_x64_string_table[77];
-extern String8 regs_g_alias_code_x64_string_table[80];
-extern REGS_Rng regs_g_reg_code_x64_rng_table[77];
-extern REGS_Slice regs_g_alias_code_x64_slice_table[80];
+extern REGS_UsageKind regs_g_reg_code_x64_usage_kind_table[101];
+extern REGS_UsageKind regs_g_alias_code_x64_usage_kind_table[96];
+extern String8 regs_g_reg_code_x64_string_table[101];
+extern String8 regs_g_alias_code_x64_string_table[96];
+extern REGS_Rng regs_g_reg_code_x64_rng_table[101];
+extern REGS_Slice regs_g_alias_code_x64_slice_table[96];
 extern REGS_UsageKind regs_g_reg_code_x86_usage_kind_table[61];
 extern REGS_UsageKind regs_g_alias_code_x86_usage_kind_table[36];
 extern String8 regs_g_reg_code_x86_string_table[61];
diff --git a/src/regs/rdi/generated/regs_rdi.meta.c b/src/regs/rdi/generated/regs_rdi.meta.c
index ad975b7d5..4d4b7fe5e 100644
--- a/src/regs/rdi/generated/regs_rdi.meta.c
+++ b/src/regs/rdi/generated/regs_rdi.meta.c
@@ -74,22 +74,46 @@ case REGS_RegCodeX64_ds:{result = RDI_RegCodeX64_ds;}break;
 case REGS_RegCodeX64_es:{result = RDI_RegCodeX64_es;}break;
 case REGS_RegCodeX64_fs:{result = RDI_RegCodeX64_fs;}break;
 case REGS_RegCodeX64_gs:{result = RDI_RegCodeX64_gs;}break;
-case REGS_RegCodeX64_ymm0:{result = RDI_RegCodeX64_ymm0;}break;
-case REGS_RegCodeX64_ymm1:{result = RDI_RegCodeX64_ymm1;}break;
-case REGS_RegCodeX64_ymm2:{result = RDI_RegCodeX64_ymm2;}break;
-case REGS_RegCodeX64_ymm3:{result = RDI_RegCodeX64_ymm3;}break;
-case REGS_RegCodeX64_ymm4:{result = RDI_RegCodeX64_ymm4;}break;
-case REGS_RegCodeX64_ymm5:{result = RDI_RegCodeX64_ymm5;}break;
-case REGS_RegCodeX64_ymm6:{result = RDI_RegCodeX64_ymm6;}break;
-case REGS_RegCodeX64_ymm7:{result = RDI_RegCodeX64_ymm7;}break;
-case REGS_RegCodeX64_ymm8:{result = RDI_RegCodeX64_ymm8;}break;
-case REGS_RegCodeX64_ymm9:{result = RDI_RegCodeX64_ymm9;}break;
-case REGS_RegCodeX64_ymm10:{result = RDI_RegCodeX64_ymm10;}break;
-case REGS_RegCodeX64_ymm11:{result = RDI_RegCodeX64_ymm11;}break;
-case REGS_RegCodeX64_ymm12:{result = RDI_RegCodeX64_ymm12;}break;
-case REGS_RegCodeX64_ymm13:{result = RDI_RegCodeX64_ymm13;}break;
-case REGS_RegCodeX64_ymm14:{result = RDI_RegCodeX64_ymm14;}break;
-case REGS_RegCodeX64_ymm15:{result = RDI_RegCodeX64_ymm15;}break;
+case REGS_RegCodeX64_zmm0:{result = RDI_RegCodeX64_zmm0;}break;
+case REGS_RegCodeX64_zmm1:{result = RDI_RegCodeX64_zmm1;}break;
+case REGS_RegCodeX64_zmm2:{result = RDI_RegCodeX64_zmm2;}break;
+case REGS_RegCodeX64_zmm3:{result = RDI_RegCodeX64_zmm3;}break;
+case REGS_RegCodeX64_zmm4:{result = RDI_RegCodeX64_zmm4;}break;
+case REGS_RegCodeX64_zmm5:{result = RDI_RegCodeX64_zmm5;}break;
+case REGS_RegCodeX64_zmm6:{result = RDI_RegCodeX64_zmm6;}break;
+case REGS_RegCodeX64_zmm7:{result = RDI_RegCodeX64_zmm7;}break;
+case REGS_RegCodeX64_zmm8:{result = RDI_RegCodeX64_zmm8;}break;
+case REGS_RegCodeX64_zmm9:{result = RDI_RegCodeX64_zmm9;}break;
+case REGS_RegCodeX64_zmm10:{result = RDI_RegCodeX64_zmm10;}break;
+case REGS_RegCodeX64_zmm11:{result = RDI_RegCodeX64_zmm11;}break;
+case REGS_RegCodeX64_zmm12:{result = RDI_RegCodeX64_zmm12;}break;
+case REGS_RegCodeX64_zmm13:{result = RDI_RegCodeX64_zmm13;}break;
+case REGS_RegCodeX64_zmm14:{result = RDI_RegCodeX64_zmm14;}break;
+case REGS_RegCodeX64_zmm15:{result = RDI_RegCodeX64_zmm15;}break;
+case REGS_RegCodeX64_zmm16:{result = RDI_RegCodeX64_zmm16;}break;
+case REGS_RegCodeX64_zmm17:{result = RDI_RegCodeX64_zmm17;}break;
+case REGS_RegCodeX64_zmm18:{result = RDI_RegCodeX64_zmm18;}break;
+case REGS_RegCodeX64_zmm19:{result = RDI_RegCodeX64_zmm19;}break;
+case REGS_RegCodeX64_zmm20:{result = RDI_RegCodeX64_zmm20;}break;
+case REGS_RegCodeX64_zmm21:{result = RDI_RegCodeX64_zmm21;}break;
+case REGS_RegCodeX64_zmm22:{result = RDI_RegCodeX64_zmm22;}break;
+case REGS_RegCodeX64_zmm23:{result = RDI_RegCodeX64_zmm23;}break;
+case REGS_RegCodeX64_zmm24:{result = RDI_RegCodeX64_zmm24;}break;
+case REGS_RegCodeX64_zmm25:{result = RDI_RegCodeX64_zmm25;}break;
+case REGS_RegCodeX64_zmm26:{result = RDI_RegCodeX64_zmm26;}break;
+case REGS_RegCodeX64_zmm27:{result = RDI_RegCodeX64_zmm27;}break;
+case REGS_RegCodeX64_zmm28:{result = RDI_RegCodeX64_zmm28;}break;
+case REGS_RegCodeX64_zmm29:{result = RDI_RegCodeX64_zmm29;}break;
+case REGS_RegCodeX64_zmm30:{result = RDI_RegCodeX64_zmm30;}break;
+case REGS_RegCodeX64_zmm31:{result = RDI_RegCodeX64_zmm31;}break;
+case REGS_RegCodeX64_k0:{result = RDI_RegCodeX64_k0;}break;
+case REGS_RegCodeX64_k1:{result = RDI_RegCodeX64_k1;}break;
+case REGS_RegCodeX64_k2:{result = RDI_RegCodeX64_k2;}break;
+case REGS_RegCodeX64_k3:{result = RDI_RegCodeX64_k3;}break;
+case REGS_RegCodeX64_k4:{result = RDI_RegCodeX64_k4;}break;
+case REGS_RegCodeX64_k5:{result = RDI_RegCodeX64_k5;}break;
+case REGS_RegCodeX64_k6:{result = RDI_RegCodeX64_k6;}break;
+case REGS_RegCodeX64_k7:{result = RDI_RegCodeX64_k7;}break;
 }
 }break;
 case Architecture_x86:
@@ -233,22 +257,46 @@ case RDI_RegCodeX64_ds:{result = REGS_RegCodeX64_ds;}break;
 case RDI_RegCodeX64_es:{result = REGS_RegCodeX64_es;}break;
 case RDI_RegCodeX64_fs:{result = REGS_RegCodeX64_fs;}break;
 case RDI_RegCodeX64_gs:{result = REGS_RegCodeX64_gs;}break;
-case RDI_RegCodeX64_ymm0:{result = REGS_RegCodeX64_ymm0;}break;
-case RDI_RegCodeX64_ymm1:{result = REGS_RegCodeX64_ymm1;}break;
-case RDI_RegCodeX64_ymm2:{result = REGS_RegCodeX64_ymm2;}break;
-case RDI_RegCodeX64_ymm3:{result = REGS_RegCodeX64_ymm3;}break;
-case RDI_RegCodeX64_ymm4:{result = REGS_RegCodeX64_ymm4;}break;
-case RDI_RegCodeX64_ymm5:{result = REGS_RegCodeX64_ymm5;}break;
-case RDI_RegCodeX64_ymm6:{result = REGS_RegCodeX64_ymm6;}break;
-case RDI_RegCodeX64_ymm7:{result = REGS_RegCodeX64_ymm7;}break;
-case RDI_RegCodeX64_ymm8:{result = REGS_RegCodeX64_ymm8;}break;
-case RDI_RegCodeX64_ymm9:{result = REGS_RegCodeX64_ymm9;}break;
-case RDI_RegCodeX64_ymm10:{result = REGS_RegCodeX64_ymm10;}break;
-case RDI_RegCodeX64_ymm11:{result = REGS_RegCodeX64_ymm11;}break;
-case RDI_RegCodeX64_ymm12:{result = REGS_RegCodeX64_ymm12;}break;
-case RDI_RegCodeX64_ymm13:{result = REGS_RegCodeX64_ymm13;}break;
-case RDI_RegCodeX64_ymm14:{result = REGS_RegCodeX64_ymm14;}break;
-case RDI_RegCodeX64_ymm15:{result = REGS_RegCodeX64_ymm15;}break;
+case RDI_RegCodeX64_zmm0:{result = REGS_RegCodeX64_zmm0;}break;
+case RDI_RegCodeX64_zmm1:{result = REGS_RegCodeX64_zmm1;}break;
+case RDI_RegCodeX64_zmm2:{result = REGS_RegCodeX64_zmm2;}break;
+case RDI_RegCodeX64_zmm3:{result = REGS_RegCodeX64_zmm3;}break;
+case RDI_RegCodeX64_zmm4:{result = REGS_RegCodeX64_zmm4;}break;
+case RDI_RegCodeX64_zmm5:{result = REGS_RegCodeX64_zmm5;}break;
+case RDI_RegCodeX64_zmm6:{result = REGS_RegCodeX64_zmm6;}break;
+case RDI_RegCodeX64_zmm7:{result = REGS_RegCodeX64_zmm7;}break;
+case RDI_RegCodeX64_zmm8:{result = REGS_RegCodeX64_zmm8;}break;
+case RDI_RegCodeX64_zmm9:{result = REGS_RegCodeX64_zmm9;}break;
+case RDI_RegCodeX64_zmm10:{result = REGS_RegCodeX64_zmm10;}break;
+case RDI_RegCodeX64_zmm11:{result = REGS_RegCodeX64_zmm11;}break;
+case RDI_RegCodeX64_zmm12:{result = REGS_RegCodeX64_zmm12;}break;
+case RDI_RegCodeX64_zmm13:{result = REGS_RegCodeX64_zmm13;}break;
+case RDI_RegCodeX64_zmm14:{result = REGS_RegCodeX64_zmm14;}break;
+case RDI_RegCodeX64_zmm15:{result = REGS_RegCodeX64_zmm15;}break;
+case RDI_RegCodeX64_zmm16:{result = REGS_RegCodeX64_zmm16;}break;
+case RDI_RegCodeX64_zmm17:{result = REGS_RegCodeX64_zmm17;}break;
+case RDI_RegCodeX64_zmm18:{result = REGS_RegCodeX64_zmm18;}break;
+case RDI_RegCodeX64_zmm19:{result = REGS_RegCodeX64_zmm19;}break;
+case RDI_RegCodeX64_zmm20:{result = REGS_RegCodeX64_zmm20;}break;
+case RDI_RegCodeX64_zmm21:{result = REGS_RegCodeX64_zmm21;}break;
+case RDI_RegCodeX64_zmm22:{result = REGS_RegCodeX64_zmm22;}break;
+case RDI_RegCodeX64_zmm23:{result = REGS_RegCodeX64_zmm23;}break;
+case RDI_RegCodeX64_zmm24:{result = REGS_RegCodeX64_zmm24;}break;
+case RDI_RegCodeX64_zmm25:{result = REGS_RegCodeX64_zmm25;}break;
+case RDI_RegCodeX64_zmm26:{result = REGS_RegCodeX64_zmm26;}break;
+case RDI_RegCodeX64_zmm27:{result = REGS_RegCodeX64_zmm27;}break;
+case RDI_RegCodeX64_zmm28:{result = REGS_RegCodeX64_zmm28;}break;
+case RDI_RegCodeX64_zmm29:{result = REGS_RegCodeX64_zmm29;}break;
+case RDI_RegCodeX64_zmm30:{result = REGS_RegCodeX64_zmm30;}break;
+case RDI_RegCodeX64_zmm31:{result = REGS_RegCodeX64_zmm31;}break;
+case RDI_RegCodeX64_k0:{result = REGS_RegCodeX64_k0;}break;
+case RDI_RegCodeX64_k1:{result = REGS_RegCodeX64_k1;}break;
+case RDI_RegCodeX64_k2:{result = REGS_RegCodeX64_k2;}break;
+case RDI_RegCodeX64_k3:{result = REGS_RegCodeX64_k3;}break;
+case RDI_RegCodeX64_k4:{result = REGS_RegCodeX64_k4;}break;
+case RDI_RegCodeX64_k5:{result = REGS_RegCodeX64_k5;}break;
+case RDI_RegCodeX64_k6:{result = REGS_RegCodeX64_k6;}break;
+case RDI_RegCodeX64_k7:{result = REGS_RegCodeX64_k7;}break;
 }
 }break;
 case Architecture_x86:
diff --git a/src/regs/regs.h b/src/regs/regs.h
index 9875ad2a8..bc929d776 100644
--- a/src/regs/regs.h
+++ b/src/regs/regs.h
@@ -72,6 +72,16 @@ union REGS_Reg256
   F64 f64[4];
 };
 
+typedef union REGS_Reg512 REGS_Reg512;
+union REGS_Reg512
+{
+  U8 v[64];
+  U32 u32[16];
+  F32 f32[16];
+  U64 u64[8];
+  F64 f64[8];
+};
+
 ////////////////////////////////
 //~ rjf: Register Slicing Types
 
diff --git a/src/regs/regs.mdesk b/src/regs/regs.mdesk
index cfebf067f..a4fcd10e7 100644
--- a/src/regs/regs.mdesk
+++ b/src/regs/regs.mdesk
@@ -67,22 +67,46 @@ REGS_RegTableX64:
   {es                             16   Normal}
   {fs                             16   Normal}
   {gs                             16   Normal}
-  {ymm0                           256  Normal}
-  {ymm1                           256  Normal}
-  {ymm2                           256  Normal}
-  {ymm3                           256  Normal}
-  {ymm4                           256  Normal}
-  {ymm5                           256  Normal}
-  {ymm6                           256  Normal}
-  {ymm7                           256  Normal}
-  {ymm8                           256  Normal}
-  {ymm9                           256  Normal}
-  {ymm10                          256  Normal}
-  {ymm11                          256  Normal}
-  {ymm12                          256  Normal}
-  {ymm13                          256  Normal}
-  {ymm14                          256  Normal}
-  {ymm15                          256  Normal}
+  {zmm0                           512  Normal}
+  {zmm1                           512  Normal}
+  {zmm2                           512  Normal}
+  {zmm3                           512  Normal}
+  {zmm4                           512  Normal}
+  {zmm5                           512  Normal}
+  {zmm6                           512  Normal}
+  {zmm7                           512  Normal}
+  {zmm8                           512  Normal}
+  {zmm9                           512  Normal}
+  {zmm10                          512  Normal}
+  {zmm11                          512  Normal}
+  {zmm12                          512  Normal}
+  {zmm13                          512  Normal}
+  {zmm14                          512  Normal}
+  {zmm15                          512  Normal}
+  {zmm16                          512  Normal}
+  {zmm17                          512  Normal}
+  {zmm18                          512  Normal}
+  {zmm19                          512  Normal}
+  {zmm20                          512  Normal}
+  {zmm21                          512  Normal}
+  {zmm22                          512  Normal}
+  {zmm23                          512  Normal}
+  {zmm24                          512  Normal}
+  {zmm25                          512  Normal}
+  {zmm26                          512  Normal}
+  {zmm27                          512  Normal}
+  {zmm28                          512  Normal}
+  {zmm29                          512  Normal}
+  {zmm30                          512  Normal}
+  {zmm31                          512  Normal}
+  {k0                             64   Normal}
+  {k1                             64   Normal}
+  {k2                             64   Normal}
+  {k3                             64   Normal}
+  {k4                             64   Normal}
+  {k5                             64   Normal}
+  {k6                             64   Normal}
+  {k7                             64   Normal}
 }
 
 @table(name base off size usage)
@@ -146,22 +170,38 @@ REGS_AliasTableX64:
   {ch              rcx    8      8      Normal}
   {dh              rdx    8      8      Normal}
   {bh              rbx    8      8      Normal}
-  {xmm0            ymm0   0      128    Normal}
-  {xmm1            ymm1   0      128    Normal}
-  {xmm2            ymm2   0      128    Normal}
-  {xmm3            ymm3   0      128    Normal}
-  {xmm4            ymm4   0      128    Normal}
-  {xmm5            ymm5   0      128    Normal}
-  {xmm6            ymm6   0      128    Normal}
-  {xmm7            ymm7   0      128    Normal}
-  {xmm8            ymm8   0      128    Normal}
-  {xmm9            ymm9   0      128    Normal}
-  {xmm10           ymm10  0      128    Normal}
-  {xmm11           ymm11  0      128    Normal}
-  {xmm12           ymm12  0      128    Normal}
-  {xmm13           ymm13  0      128    Normal}
-  {xmm14           ymm14  0      128    Normal}
-  {xmm15           ymm15  0      128    Normal}
+  {xmm0            zmm0   0      128    Normal}
+  {xmm1            zmm1   0      128    Normal}
+  {xmm2            zmm2   0      128    Normal}
+  {xmm3            zmm3   0      128    Normal}
+  {xmm4            zmm4   0      128    Normal}
+  {xmm5            zmm5   0      128    Normal}
+  {xmm6            zmm6   0      128    Normal}
+  {xmm7            zmm7   0      128    Normal}
+  {xmm8            zmm8   0      128    Normal}
+  {xmm9            zmm9   0      128    Normal}
+  {xmm10           zmm10  0      128    Normal}
+  {xmm11           zmm11  0      128    Normal}
+  {xmm12           zmm12  0      128    Normal}
+  {xmm13           zmm13  0      128    Normal}
+  {xmm14           zmm14  0      128    Normal}
+  {xmm15           zmm15  0      128    Normal}
+  {ymm0            zmm0   0      256    Normal}
+  {ymm1            zmm1   0      256    Normal}
+  {ymm2            zmm2   0      256    Normal}
+  {ymm3            zmm3   0      256    Normal}
+  {ymm4            zmm4   0      256    Normal}
+  {ymm5            zmm5   0      256    Normal}
+  {ymm6            zmm6   0      256    Normal}
+  {ymm7            zmm7   0      256    Normal}
+  {ymm8            zmm8   0      256    Normal}
+  {ymm9            zmm9   0      256    Normal}
+  {ymm10           zmm10  0      256    Normal}
+  {ymm11           zmm11  0      256    Normal}
+  {ymm12           zmm12  0      256    Normal}
+  {ymm13           zmm13  0      256    Normal}
+  {ymm14           zmm14  0      256    Normal}
+  {ymm15           zmm15  0      256    Normal}
   {mm0             fpr0   0      64     Normal}
   {mm1             fpr1   0      64     Normal}
   {mm2             fpr2   0      64     Normal}
