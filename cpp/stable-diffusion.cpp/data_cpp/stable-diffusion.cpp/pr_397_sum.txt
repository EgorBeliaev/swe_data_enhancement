**Issue Description:**

The GitHub pull request (PR) aims to address a bug where the Clip-L model does not function properly with Flux models. The results from the model were identical to alternative models, hinting that Clip-L was not contributing as expected.

**Instructions for Changes:**

1. **Clip Backend Adjustment:**
   - Modify the clip backend to skip the final text projection if the `text_projection` tensor does not exist. This should behave like replacing the `text_projection` with an identity matrix (`torch.eye()`).
   - When `text_projection` is present, replace matrix multiplication with a biasless linear layer.

2. **Patch Implementation:**
   - Hard-code the Clip prompt to always be `"Painting, in the style of starry night by Van Gogh"`.
   - Ensure that the T5 example prompt remains as `"a lovely cat holding a sign says 'flux.cpp'"`.

3. **Adjust and Encode Text:**
   - In `conditioner.hpp`, change the encoding using `clip_l_tokenizer.encode()` to utilize the hardcoded Clip prompt.

4. **Testing and Validation:**
   - Run tests using the Schnell and SD3 models to verify that the fix modifies the output as expected, ensuring improved differentiation between the models.

These changes focus on fixing the core issue of Clip-L's non-functional behavior in Flux models by altering the backend logic and testing the effectiveness post-change.