[
    {
        "title": "Improve memory consumption on large Kubernetes clusters when NodePort listeners are used"
    },
    {
        "author": {
            "login": "PR Description"
        },
        "body": "### Type of change\r\n\r\n- Bugfix\r\n\r\n### Description\r\n\r\nWhen using node port listeners, the cluster operator needs to figure out the bootstrap address for the node port listener in order to add it to the status section of the Kafka CR.\r\n\r\nRight now, we do it the following way:\r\n1. We list all worker nodes\r\n2. We list all Kafka pods\r\n3. We match the pods to the nodes and collect the addresses of the nodes they are running on\r\n\r\nBut this approach can cause the operator to run out of memory on large Kubernetes clusters because:\r\n* We keep the list of the nodes in memory\r\n* A single node resource can be pretty big because its status contains lists of container images etc.\r\n\r\nSo this can easily lead to running out of memory, even with a small Kafka cluster. Reports from users suggest problems with 250 worker node OpenShift cluster with one Kafka cluster. I was able to reproduce it on a cluster with ~160 worker nodes with the help of 3 small Kafka clusters.\r\n\r\nThis PR updates the way how we collect the addresses for the status. It:\r\n* Gets the list of broker pods\r\n* From the pods, it gets a list of nodes they are running on\r\n* Gets the nodes from Kubernetes one-by-one with GET instead of LIST API\r\n* Extracts the addresses from the nodes\r\n\r\nThis has the trade-off of making more Kubernetes API calls and spending more CPU while being more carefull with the used memory.\r\n\r\nIt should help with the most common use case where the Kube cluster is large with many nodes, but the Kafka cluster is much smaller. For situations where the Kafka cluster is large as well, we will still need the memory to store many nodes. So users might need to increase the operator memory, but that is not unexpected for large Kafka cluster. For a large Kafka cluster, it might also make a large number of GET calls for the individual nodes instead of one LIST command. But I think overall this is a reasonable trade-off.\r\n\r\n### Checklist\r\n\r\n- [x] Write tests\r\n- [x] Make sure all tests pass\r\n- [x] Try your changes from Pod inside your Kubernetes and OpenShift cluster, not just locally"
    },
    {
        "author": {
            "login": "Frawless"
        },
        "body": ""
    },
    {
        "author": {
            "login": "ppatierno"
        },
        "body": "LGTM. Just a nit and a question for you."
    },
    {
        "author": {
            "login": "see-quick"
        },
        "body": ""
    },
    {
        "author": {
            "login": "scholzj"
        },
        "body": ""
    },
    {
        "author": {
            "login": "ppatierno"
        },
        "body": ""
    },
    {
        "author": {
            "login": "scholzj"
        },
        "body": "/azp run regression"
    },
    {
        "author": {
            "login": "azure-pipelines"
        },
        "body": "<samp>\nAzure Pipelines successfully started running 1 pipeline(s).<br>\r\n\n</samp>"
    }
]