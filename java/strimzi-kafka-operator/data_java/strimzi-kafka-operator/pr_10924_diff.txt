diff --git a/CHANGELOG.md b/CHANGELOG.md
index fe26371922e..3bfb2674068 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -4,6 +4,8 @@
 
 ### Major changes, deprecations and removals
 
+* Support for MirrorMaker 1 has been removed.
+  Please make sure to migrate to MirrorMaker 2 before upgrading to Strimzi 0.46 or newer.
 * [Strimzi EnvVar Configuration Provider](https://github.com/strimzi/kafka-env-var-config-provider) (deprecated in Strimzi 0.38.0) and [Strimzi MirrorMaker 2 Extensions](https://github.com/strimzi/mirror-maker-2-extensions) (deprecated in Strimzi 0.28.0) plugins were removed from Strimzi container images.
   Please use the Apache Kafka [EnvVarConfigProvider](https://github.com/strimzi/kafka-env-var-config-provider?tab=readme-ov-file#deprecation-notice) and [Identity Replication Policy](https://github.com/strimzi/mirror-maker-2-extensions?tab=readme-ov-file#identity-replication-policy) instead.
 
diff --git a/Makefile b/Makefile
index 497e749b5f1..170626c39e0 100644
--- a/Makefile
+++ b/Makefile
@@ -14,7 +14,7 @@ ifneq ($(RELEASE_VERSION),latest)
   GITHUB_VERSION = $(RELEASE_VERSION)
 endif
 
-SUBDIRS=kafka-agent mirror-maker-agent tracing-agent crd-annotations test crd-generator api mockkube certificate-manager operator-common config-model config-model-generator cluster-operator topic-operator user-operator kafka-init systemtest docker-images/artifacts packaging/helm-charts/helm3 packaging/install packaging/examples
+SUBDIRS=kafka-agent tracing-agent crd-annotations test crd-generator api mockkube certificate-manager operator-common config-model config-model-generator cluster-operator topic-operator user-operator kafka-init systemtest docker-images/artifacts packaging/helm-charts/helm3 packaging/install packaging/examples
 DOCKERDIRS=docker-images/base docker-images/operator docker-images/kafka-based docker-images/maven-builder docker-images/kaniko-executor
 DOCKER_TARGETS=docker_build docker_push docker_tag docker_load docker_save docker_amend_manifest docker_push_manifest docker_sign_manifest docker_delete_manifest docker_delete_archive docker_sbom docker_push_sbom
 JAVA_TARGETS=java_build java_install java_clean
diff --git a/api/pom.xml b/api/pom.xml
index d64de90a9b1..6dcf99e36d0 100644
--- a/api/pom.xml
+++ b/api/pom.xml
@@ -172,7 +172,6 @@
                                 <argument>--yaml</argument>
                                 <argument>io.strimzi.api.kafka.model.kafka.Kafka=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}040-Crd-kafka.yaml</argument>
                                 <argument>io.strimzi.api.kafka.model.connect.KafkaConnect=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}041-Crd-kafkaconnect.yaml</argument>
-                                <argument>io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}045-Crd-kafkamirrormaker.yaml</argument>
                                 <argument>io.strimzi.api.kafka.model.bridge.KafkaBridge=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}046-Crd-kafkabridge.yaml</argument>
                                 <argument>io.strimzi.api.kafka.model.connector.KafkaConnector=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}047-Crd-kafkaconnector.yaml</argument>
                                 <argument>io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2=${project.basedir}${file.separator}..${file.separator}packaging${file.separator}install${file.separator}cluster-operator${file.separator}048-Crd-kafkamirrormaker2.yaml</argument>
@@ -231,7 +230,6 @@
                                 <argument>io.strimzi.api.kafka.model.connect.KafkaConnect</argument>
                                 <argument>io.strimzi.api.kafka.model.topic.KafkaTopic</argument>
                                 <argument>io.strimzi.api.kafka.model.user.KafkaUser</argument>
-                                <argument>io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker</argument>
                                 <argument>io.strimzi.api.kafka.model.bridge.KafkaBridge</argument>
                                 <argument>io.strimzi.api.kafka.model.connector.KafkaConnector</argument>
                                 <argument>io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2</argument>
diff --git a/api/src/main/java/io/strimzi/api/ResourceLabels.java b/api/src/main/java/io/strimzi/api/ResourceLabels.java
index 8fb4c069e83..095e8d89d34 100644
--- a/api/src/main/java/io/strimzi/api/ResourceLabels.java
+++ b/api/src/main/java/io/strimzi/api/ResourceLabels.java
@@ -20,7 +20,7 @@ public class ResourceLabels {
      * <ul>
      *   <li>Kafka</li>
      *   <li>KafkaConnect</li>
-     *   <li>KafkaMirrorMaker</li>
+     *   <li>KafkaMirrorMaker2</li>
      *   <li>KafkaBridge</li>
      *   <li>KafkaUser</li>
      *   <li>KafkaTopic</li>
diff --git a/api/src/main/java/io/strimzi/api/kafka/Crds.java b/api/src/main/java/io/strimzi/api/kafka/Crds.java
index bae32f3f2a8..d8b978f1df2 100644
--- a/api/src/main/java/io/strimzi/api/kafka/Crds.java
+++ b/api/src/main/java/io/strimzi/api/kafka/Crds.java
@@ -22,8 +22,6 @@
 import io.strimzi.api.kafka.model.connector.KafkaConnectorList;
 import io.strimzi.api.kafka.model.kafka.Kafka;
 import io.strimzi.api.kafka.model.kafka.KafkaList;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2List;
 import io.strimzi.api.kafka.model.nodepool.KafkaNodePool;
@@ -46,7 +44,6 @@
 /**
  * "Static" information about the CRDs defined in this package
  */
-@SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
 public class Crds {
     @SuppressWarnings("unchecked")
     private static final Class<? extends CustomResource>[] CRDS = new Class[] {
@@ -54,7 +51,6 @@ public class Crds {
         KafkaConnect.class,
         KafkaTopic.class,
         KafkaUser.class,
-        KafkaMirrorMaker.class,
         KafkaBridge.class,
         KafkaConnector.class,
         KafkaMirrorMaker2.class,
@@ -108,15 +104,6 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls)
             listKind = KafkaUser.RESOURCE_LIST_KIND;
             versions = KafkaUser.VERSIONS;
             status = new CustomResourceSubresourceStatus();
-        } else if (cls.equals(KafkaMirrorMaker.class)) {
-            scope = KafkaMirrorMaker.SCOPE;
-            plural = KafkaMirrorMaker.RESOURCE_PLURAL;
-            singular = KafkaMirrorMaker.RESOURCE_SINGULAR;
-            group = KafkaMirrorMaker.RESOURCE_GROUP;
-            kind = KafkaMirrorMaker.RESOURCE_KIND;
-            listKind = KafkaMirrorMaker.RESOURCE_LIST_KIND;
-            versions = KafkaMirrorMaker.VERSIONS;
-            status = new CustomResourceSubresourceStatus();
         } else if (cls.equals(KafkaBridge.class)) {
             scope = KafkaBridge.SCOPE;
             plural = KafkaBridge.RESOURCE_PLURAL;
@@ -251,14 +238,6 @@ public static MixedOperation<KafkaUser, KafkaUserList, Resource<KafkaUser>> kafk
         return client.resources(KafkaUser.class, KafkaUserList.class);
     }
 
-    public static CustomResourceDefinition kafkaMirrorMaker() {
-        return crd(KafkaMirrorMaker.class);
-    }
-
-    public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>> mirrorMakerOperation(KubernetesClient client) {
-        return client.resources(KafkaMirrorMaker.class, KafkaMirrorMakerList.class);
-    }
-
     public static CustomResourceDefinition kafkaBridge() {
         return crd(KafkaBridge.class);
     }
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/common/ClientTls.java b/api/src/main/java/io/strimzi/api/kafka/model/common/ClientTls.java
index 6c833db39a4..582f7c52445 100644
--- a/api/src/main/java/io/strimzi/api/kafka/model/common/ClientTls.java
+++ b/api/src/main/java/io/strimzi/api/kafka/model/common/ClientTls.java
@@ -17,7 +17,7 @@
 import java.util.Map;
 
 /**
- * Represent the TLS configuration for all the Clients(KafkaConnect, KafkaBridge, KafkaMirrorMaker, KafkaMirrorMaker2).
+ * Represent the TLS configuration for all the Clients(KafkaConnect, KafkaBridge, KafkaMirrorMaker2).
  */
 @DescriptionFile
 @Buildable(
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.java
deleted file mode 100644
index 10d119fe639..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.java
+++ /dev/null
@@ -1,153 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
-import io.fabric8.kubernetes.api.model.Namespaced;
-import io.fabric8.kubernetes.client.CustomResource;
-import io.fabric8.kubernetes.model.annotation.Group;
-import io.fabric8.kubernetes.model.annotation.Version;
-import io.strimzi.api.annotations.DeprecatedType;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.api.kafka.model.common.UnknownPropertyPreserving;
-import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
-import io.strimzi.crdgenerator.annotations.Crd;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.sundr.builder.annotations.Buildable;
-import io.sundr.builder.annotations.BuildableReference;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-@JsonDeserialize
-@Crd(
-    spec = @Crd.Spec(
-        names = @Crd.Spec.Names(
-            kind = KafkaMirrorMaker.RESOURCE_KIND,
-            plural = KafkaMirrorMaker.RESOURCE_PLURAL,
-            shortNames = {KafkaMirrorMaker.SHORT_NAME},
-            categories = {Constants.STRIMZI_CATEGORY}
-        ),
-        group = KafkaMirrorMaker.RESOURCE_GROUP,
-        scope = KafkaMirrorMaker.SCOPE,
-        versions = {
-            @Crd.Spec.Version(name = KafkaMirrorMaker.V1BETA2, served = true, storage = false),
-            @Crd.Spec.Version(name = KafkaMirrorMaker.V1BETA1, served = true, storage = true),
-            @Crd.Spec.Version(name = KafkaMirrorMaker.V1ALPHA1, served = true, storage = false)
-        },
-        subresources = @Crd.Spec.Subresources(
-            status = @Crd.Spec.Subresources.Status(),
-            scale = @Crd.Spec.Subresources.Scale(
-                specReplicasPath = KafkaMirrorMaker.SPEC_REPLICAS_PATH,
-                statusReplicasPath = KafkaMirrorMaker.STATUS_REPLICAS_PATH,
-                labelSelectorPath = KafkaMirrorMaker.LABEL_SELECTOR_PATH
-            )
-        ),
-        additionalPrinterColumns = {
-            @Crd.Spec.AdditionalPrinterColumn(
-                name = "Desired replicas",
-                description = "The desired number of Kafka MirrorMaker replicas",
-                jsonPath = ".spec.replicas",
-                type = "integer"),
-            @Crd.Spec.AdditionalPrinterColumn(
-                name = "Consumer Bootstrap Servers",
-                description = "The boostrap servers for the consumer",
-                jsonPath = ".spec.consumer.bootstrapServers",
-                type = "string",
-                priority = 1),
-            @Crd.Spec.AdditionalPrinterColumn(
-                name = "Producer Bootstrap Servers",
-                description = "The boostrap servers for the producer",
-                jsonPath = ".spec.producer.bootstrapServers",
-                type = "string",
-                priority = 1),
-            @Crd.Spec.AdditionalPrinterColumn(
-                name = "Ready",
-                description = "The state of the custom resource",
-                jsonPath = ".status.conditions[?(@.type==\"Ready\")].status",
-                type = "string")
-        }
-    )
-)
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API,
-        refs = {@BuildableReference(CustomResource.class)}
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
-@EqualsAndHashCode(callSuper = true)
-@ToString(callSuper = true)
-@Version(Constants.V1BETA2)
-@Group(Constants.RESOURCE_GROUP_NAME)
-@Deprecated
-@DeprecatedType(replacedWithType = KafkaMirrorMaker2.class)
-public class KafkaMirrorMaker extends CustomResource<KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> implements Namespaced, UnknownPropertyPreserving {
-    private static final long serialVersionUID = 1L;
-
-    public static final String SCOPE = "Namespaced";
-    public static final String V1ALPHA1 = Constants.V1ALPHA1;
-    public static final String V1BETA1 = Constants.V1BETA1;
-    public static final String V1BETA2 = Constants.V1BETA2;
-    public static final String CONSUMED_VERSION = V1BETA2;
-    public static final List<String> VERSIONS = List.of(V1BETA2, V1BETA1, V1ALPHA1);
-    public static final String RESOURCE_KIND = "KafkaMirrorMaker";
-    public static final String RESOURCE_LIST_KIND = RESOURCE_KIND + "List";
-    public static final String RESOURCE_GROUP = Constants.RESOURCE_GROUP_NAME;
-    public static final String RESOURCE_PLURAL = "kafkamirrormakers";
-    public static final String RESOURCE_SINGULAR = "kafkamirrormaker";
-    public static final String CRD_NAME = RESOURCE_PLURAL + "." + RESOURCE_GROUP;
-    public static final String SHORT_NAME = "kmm";
-    public static final List<String> RESOURCE_SHORTNAMES = List.of(SHORT_NAME);
-    public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
-    public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
-
-    private Map<String, Object> additionalProperties;
-
-    // Added to avoid duplication during Json serialization
-    private String apiVersion;
-    private String kind;
-
-    public KafkaMirrorMaker() {
-        super();
-    }
-
-    public KafkaMirrorMaker(KafkaMirrorMakerSpec spec, KafkaMirrorMakerStatus status) {
-        super();
-        this.spec = spec;
-        this.status = status;
-    }
-
-    @Override
-    @Description("The specification of Kafka MirrorMaker.")
-    public KafkaMirrorMakerSpec getSpec() {
-        return super.getSpec();
-    }
-
-    @Override
-    @Description("The status of Kafka MirrorMaker.")
-    public KafkaMirrorMakerStatus getStatus() {
-        return super.getStatus();
-    }
-
-    @Override
-    public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties != null ? this.additionalProperties : Map.of();
-    }
-
-    @Override
-    public void setAdditionalProperty(String name, Object value) {
-        if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(2);
-        }
-        this.additionalProperties.put(name, value);
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerClientSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerClientSpec.java
deleted file mode 100644
index 7dc8a577780..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerClientSpec.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.strimzi.api.kafka.model.common.ClientTls;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.api.kafka.model.common.UnknownPropertyPreserving;
-import io.strimzi.api.kafka.model.common.authentication.KafkaClientAuthentication;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-import java.util.HashMap;
-import java.util.Map;
-
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@EqualsAndHashCode
-@ToString
-public class KafkaMirrorMakerClientSpec implements UnknownPropertyPreserving {
-    private String bootstrapServers;
-    protected Map<String, Object> config = new HashMap<>(0);
-    private ClientTls tls;
-    private KafkaClientAuthentication authentication;
-    private Map<String, Object> additionalProperties;
-
-    @Description("Authentication configuration for connecting to the cluster.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public KafkaClientAuthentication getAuthentication() {
-        return authentication;
-    }
-
-    public void setAuthentication(KafkaClientAuthentication authentication) {
-        this.authentication = authentication;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public Map<String, Object> getConfig() {
-        return config;
-    }
-
-    public void setConfig(Map<String, Object> config) {
-        this.config = config;
-    }
-
-    @Description("TLS configuration for connecting MirrorMaker to the cluster.")
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    public ClientTls getTls() {
-        return tls;
-    }
-
-    public void setTls(ClientTls tls) {
-        this.tls = tls;
-    }
-
-    @Description("A list of host:port pairs for establishing the initial connection to the Kafka cluster.")
-    @JsonProperty(required = true)
-    public String getBootstrapServers() {
-        return bootstrapServers;
-    }
-
-    public void setBootstrapServers(String bootstrapServers) {
-        this.bootstrapServers = bootstrapServers;
-    }
-
-    @Override
-    public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties != null ? this.additionalProperties : Map.of();
-    }
-
-    @Override
-    public void setAdditionalProperty(String name, Object value) {
-        if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(2);
-        }
-        this.additionalProperties.put(name, value);
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerConsumerSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerConsumerSpec.java
deleted file mode 100644
index 6d81b310475..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerConsumerSpec.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.strimzi.crdgenerator.annotations.DescriptionFile;
-import io.strimzi.crdgenerator.annotations.Minimum;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-import java.util.Map;
-
-@DescriptionFile
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"numStreams", "offsetCommitInterval", "bootstrapServers", "groupId", "authentication", "tls", "config"})
-@EqualsAndHashCode(callSuper = true)
-@ToString(callSuper = true)
-public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
-
-    private Integer numStreams;
-    private String groupId;
-    private Integer offsetCommitInterval;
-
-    @Override
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    @Description("The MirrorMaker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
-    public Map<String, Object> getConfig() {
-        return config;
-    }
-
-    @Description("Specifies the number of consumer stream threads to create.")
-    @Minimum(1)
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    public Integer getNumStreams() {
-        return numStreams;
-    }
-
-    public void setNumStreams(Integer numStreams) {
-        this.numStreams = numStreams;
-    }
-
-    @Description("A unique string that identifies the consumer group this consumer belongs to.")
-    @JsonProperty(required = true)
-    public String getGroupId() {
-        return groupId;
-    }
-
-    public void setGroupId(String groupId) {
-        this.groupId = groupId;
-    }
-
-    @Description("Specifies the offset auto-commit interval in ms. Default value is 60000.")
-    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
-    public Integer getOffsetCommitInterval() {
-        return offsetCommitInterval;
-    }
-
-    public void setOffsetCommitInterval(Integer offsetCommitInterval) {
-        this.offsetCommitInterval = offsetCommitInterval;
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerList.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerList.java
deleted file mode 100644
index 785e405f975..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerList.java
+++ /dev/null
@@ -1,17 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import io.fabric8.kubernetes.api.model.DefaultKubernetesResourceList;
-import lombok.ToString;
-
-/**
- * A {@code DefaultKubernetesResourceList<KafkaMirrorMaker>} required for using Fabric8 CRD support.
- */
-@SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
-@ToString(callSuper = true)
-public class KafkaMirrorMakerList extends DefaultKubernetesResourceList<KafkaMirrorMaker> {
-    private static final long serialVersionUID = 1L;
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerProducerSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerProducerSpec.java
deleted file mode 100644
index e0b37bbbb89..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerProducerSpec.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.strimzi.crdgenerator.annotations.DescriptionFile;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-import java.util.Map;
-
-@DescriptionFile
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "bootstrapServers", "abortOnSendFailure", "authentication", "config", "tls"})
-@EqualsAndHashCode(callSuper = true)
-@ToString(callSuper = true)
-public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
-    private Boolean abortOnSendFailure;
-
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security., interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
-
-    @Description("Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.")
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    public Boolean getAbortOnSendFailure() {
-        return abortOnSendFailure;
-    }
-
-    public void setAbortOnSendFailure(Boolean abortOnSendFailure) {
-        this.abortOnSendFailure = abortOnSendFailure;
-    }
-
-    @Override
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    @Description("The MirrorMaker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
-    public Map<String, Object> getConfig() {
-        return config;
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerResources.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerResources.java
deleted file mode 100644
index 8d75b904488..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerResources.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-/**
- * Encapsulates the naming scheme used for the resources which the Cluster Operator manages for a
- * {@code KafkaMirrorMaker} cluster.
- */
-public class KafkaMirrorMakerResources {
-    protected KafkaMirrorMakerResources() { }
-
-    /**
-     * Returns the name of the Kafka MirrorMaker {@code Deployment} for a {@code KafkaMirrorMaker} cluster of the given name.
-     * @param clusterName  The {@code metadata.name} of the {@code KafkaMirrorMaker} resource.
-     * @return The name of the corresponding Kafka MirrorMaker {@code Deployment}.
-     */
-    public static String componentName(String clusterName) {
-        return clusterName + "-mirror-maker";
-    }
-
-    /**
-     * Returns the name of the Kafka MirrorMaker {@code ServiceAccount} for a {@code KafkaMirrorMaker} cluster of the given name.
-     * @param clusterName  The {@code metadata.name} of the {@code KafkaMirrorMaker} resource.
-     * @return The name of the corresponding Kafka MirrorMaker {@code ServiceAccount}.
-     */
-    public static String serviceAccountName(String clusterName) {
-        return componentName(clusterName);
-    }
-
-    /**
-     * Returns the name of the Prometheus {@code Service} for a {@code KafkaMirrorMaker} cluster of the given name.
-     * @param clusterName  The {@code metadata.name} of the {@code KafkaMirrorMaker} resource.
-     * @return The name of the corresponding {@code Service}.
-     */
-    public static String serviceName(String clusterName) {
-        return clusterName + "-mirror-maker";
-    }
-
-    /**
-     * Returns the name of the Kafka MirrorMaker metrics and log {@code ConfigMap} for a {@code KafkaMirrorMaker} cluster of the given name.
-     * @param clusterName  The {@code metadata.name} of the {@code KafkaMirrorMaker} resource.
-     * @return The name of the corresponding Kafka MirrorMaker metrics and log {@code ConfigMap}.
-     */
-    public static String metricsAndLogConfigMapName(String clusterName) {
-        return clusterName + "-mirror-maker-config";
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerSpec.java
deleted file mode 100644
index 85abdb215dd..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerSpec.java
+++ /dev/null
@@ -1,227 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.fabric8.kubernetes.api.model.ResourceRequirements;
-import io.strimzi.api.annotations.DeprecatedProperty;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.api.kafka.model.common.HasConfigurableLogging;
-import io.strimzi.api.kafka.model.common.HasConfigurableMetrics;
-import io.strimzi.api.kafka.model.common.HasLivenessProbe;
-import io.strimzi.api.kafka.model.common.HasReadinessProbe;
-import io.strimzi.api.kafka.model.common.JvmOptions;
-import io.strimzi.api.kafka.model.common.Logging;
-import io.strimzi.api.kafka.model.common.Probe;
-import io.strimzi.api.kafka.model.common.Spec;
-import io.strimzi.api.kafka.model.common.metrics.MetricsConfig;
-import io.strimzi.api.kafka.model.common.tracing.Tracing;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.strimzi.crdgenerator.annotations.DescriptionFile;
-import io.strimzi.crdgenerator.annotations.KubeLink;
-import io.strimzi.crdgenerator.annotations.Minimum;
-import io.strimzi.crdgenerator.annotations.OneOf;
-import io.strimzi.crdgenerator.annotations.PresentInVersions;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-@DescriptionFile
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({
-    "version", "replicas", "image", "consumer", "producer", "resources", "whitelist", "include", "jvmOptions",
-    "logging", "metricsConfig", "tracing", "template", "livenessProbe", "readinessProbe"})
-@OneOf({@OneOf.Alternative(@OneOf.Alternative.Property("include")), @OneOf.Alternative(@OneOf.Alternative.Property("whitelist"))})
-@EqualsAndHashCode(callSuper = true)
-@ToString(callSuper = true)
-public class KafkaMirrorMakerSpec extends Spec implements HasConfigurableMetrics, HasConfigurableLogging, HasLivenessProbe, HasReadinessProbe {
-    private static final int DEFAULT_REPLICAS = 3;
-
-    private int replicas = DEFAULT_REPLICAS;
-
-    private String version;
-    private String image;
-    private String whitelist;
-    private String include;
-    private KafkaMirrorMakerConsumerSpec consumer;
-    private KafkaMirrorMakerProducerSpec producer;
-    private ResourceRequirements resources;
-    private Probe livenessProbe;
-    private Probe readinessProbe;
-    private JvmOptions jvmOptions;
-    private Logging logging;
-    private MetricsConfig metricsConfig;
-    private Tracing tracing;
-    private KafkaMirrorMakerTemplate template;
-
-    @Description("The number of pods in the `Deployment`.")
-    @Minimum(0)
-    @JsonProperty(required = true)
-    public int getReplicas() {
-        return replicas;
-    }
-
-    public void setReplicas(int replicas) {
-        this.replicas = replicas;
-    }
-
-    @Description("The Kafka MirrorMaker version. Defaults to the latest version. " +
-            "Consult the documentation to understand the process required to upgrade or downgrade the version.")
-    public String getVersion() {
-        return version;
-    }
-
-    public void setVersion(String version) {
-        this.version = version;
-    }
-
-    @Description("The container image used for Kafka MirrorMaker pods. "
-        + "If no image name is explicitly specified, it is determined based on the `spec.version` configuration. "
-        + "The image names are specifically mapped to corresponding versions in the Cluster Operator configuration.")
-    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
-    public String getImage() {
-        return image;
-    }
-
-    public void setImage(String image) {
-        this.image = image;
-    }
-
-    @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. " +
-            "Mirroring two topics named A and B is achieved by using the expression `A|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. " +
-            "You can also specify multiple regular expressions separated by commas.")
-    @DeprecatedProperty(movedToPath = "spec.include")
-    @PresentInVersions("v1alpha1-v1beta2")
-    @Deprecated
-    public String getWhitelist() {
-        return whitelist;
-    }
-
-    public void setWhitelist(String whitelist) {
-        this.whitelist = whitelist;
-    }
-
-    @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. " +
-            "Mirroring two topics named A and B is achieved by using the expression `A|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. " +
-            "You can also specify multiple regular expressions separated by commas.")
-    public String getInclude() {
-        return include;
-    }
-
-    public void setInclude(String include) {
-        this.include = include;
-    }
-
-    @Description("Configuration of source cluster.")
-    @JsonProperty(required = true)
-    public KafkaMirrorMakerConsumerSpec getConsumer() {
-        return consumer;
-    }
-
-    public void setConsumer(KafkaMirrorMakerConsumerSpec consumer) {
-        this.consumer = consumer;
-    }
-
-    @Description("Configuration of target cluster.")
-    @JsonProperty(required = true)
-    public KafkaMirrorMakerProducerSpec getProducer() {
-        return producer;
-    }
-
-    public void setProducer(KafkaMirrorMakerProducerSpec producer) {
-        this.producer = producer;
-    }
-
-    @Description("Metrics configuration.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    @Override
-    public MetricsConfig getMetricsConfig() {
-        return metricsConfig;
-    }
-
-    @Override
-    public void setMetricsConfig(MetricsConfig metricsConfig) {
-        this.metricsConfig = metricsConfig;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("The configuration of tracing in Kafka MirrorMaker.")
-    public Tracing getTracing() {
-        return tracing;
-    }
-
-    public void setTracing(Tracing tracing) {
-        this.tracing = tracing;
-    }
-
-    @Description("Logging configuration for MirrorMaker.")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
-    @Override
-    public Logging getLogging() {
-        return logging;
-    }
-
-    @Override
-    public void setLogging(Logging logging) {
-        this.logging = logging;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    @Description("JVM Options for pods")
-    public JvmOptions getJvmOptions() {
-        return jvmOptions;
-    }
-
-    public void setJvmOptions(JvmOptions jvmOptions) {
-        this.jvmOptions = jvmOptions;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
-    @Description("CPU and memory resources to reserve.")
-    public ResourceRequirements getResources() {
-        return resources;
-    }
-
-    public void setResources(ResourceRequirements resources) {
-        this.resources = resources;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    @Description("Pod liveness checking.")
-    public Probe getLivenessProbe() {
-        return livenessProbe;
-    }
-
-    public void setLivenessProbe(Probe livenessProbe) {
-        this.livenessProbe = livenessProbe;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
-    @Description("Pod readiness checking.")
-    public Probe getReadinessProbe() {
-        return readinessProbe;
-    }
-
-    public void setReadinessProbe(Probe readinessProbe) {
-        this.readinessProbe = readinessProbe;
-    }
-
-    @Description("Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public KafkaMirrorMakerTemplate getTemplate() {
-        return template;
-    }
-
-    public void setTemplate(KafkaMirrorMakerTemplate template) {
-        this.template = template;
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerStatus.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerStatus.java
deleted file mode 100644
index 781e48e33bc..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerStatus.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.api.kafka.model.kafka.Status;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-/**
- * Represents a status of the Kafka MirrorMaker resource
- */
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"conditions", "observedGeneration", "labelSelector", "replicas"})
-@EqualsAndHashCode(callSuper = true)
-@ToString(callSuper = true)
-public class KafkaMirrorMakerStatus extends Status {
-    private int replicas;
-    private String labelSelector;
-
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("The current number of pods being used to provide this resource.")
-    public int getReplicas() {
-        return replicas;
-    }
-
-    public void setReplicas(int replicas) {
-        this.replicas = replicas;
-    }
-
-    @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Label selector for pods providing this resource.")
-    public String getLabelSelector() {
-        return labelSelector;
-    }
-
-    public void setLabelSelector(String labelSelector) {
-        this.labelSelector = labelSelector;
-    }
-}
diff --git a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTemplate.java b/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTemplate.java
deleted file mode 100644
index 578c82c9ca4..00000000000
--- a/api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTemplate.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.strimzi.api.kafka.model.common.Constants;
-import io.strimzi.api.kafka.model.common.UnknownPropertyPreserving;
-import io.strimzi.api.kafka.model.common.template.ContainerTemplate;
-import io.strimzi.api.kafka.model.common.template.DeploymentTemplate;
-import io.strimzi.api.kafka.model.common.template.PodDisruptionBudgetTemplate;
-import io.strimzi.api.kafka.model.common.template.PodTemplate;
-import io.strimzi.api.kafka.model.common.template.ResourceTemplate;
-import io.strimzi.crdgenerator.annotations.Description;
-import io.sundr.builder.annotations.Buildable;
-import lombok.EqualsAndHashCode;
-import lombok.ToString;
-
-import java.util.HashMap;
-import java.util.Map;
-
-/**
- * Representation of a template for Kafka MirrorMaker resources.
- */
-@Buildable(
-        editableEnabled = false,
-        builderPackage = Constants.FABRIC8_KUBERNETES_API
-)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"deployment", "pod", "podDisruptionBudget", "mirrorMakerContainer", "serviceAccount"})
-@EqualsAndHashCode
-@ToString
-public class KafkaMirrorMakerTemplate implements UnknownPropertyPreserving {
-    private DeploymentTemplate deployment;
-    private PodTemplate pod;
-    private PodDisruptionBudgetTemplate podDisruptionBudget;
-    private ContainerTemplate mirrorMakerContainer;
-    private ResourceTemplate serviceAccount;
-    private Map<String, Object> additionalProperties;
-
-    @Description("Template for Kafka MirrorMaker `Deployment`.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public DeploymentTemplate getDeployment() {
-        return deployment;
-    }
-
-    public void setDeployment(DeploymentTemplate deployment) {
-        this.deployment = deployment;
-    }
-
-    @Description("Template for Kafka MirrorMaker `Pods`.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public PodTemplate getPod() {
-        return pod;
-    }
-
-    public void setPod(PodTemplate pod) {
-        this.pod = pod;
-    }
-
-    @Description("Template for Kafka MirrorMaker `PodDisruptionBudget`.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public PodDisruptionBudgetTemplate getPodDisruptionBudget() {
-        return podDisruptionBudget;
-    }
-
-    public void setPodDisruptionBudget(PodDisruptionBudgetTemplate podDisruptionBudget) {
-        this.podDisruptionBudget = podDisruptionBudget;
-    }
-
-    @Description("Template for Kafka MirrorMaker container")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ContainerTemplate getMirrorMakerContainer() {
-        return mirrorMakerContainer;
-    }
-
-    public void setMirrorMakerContainer(ContainerTemplate mirrorMakerContainer) {
-        this.mirrorMakerContainer = mirrorMakerContainer;
-    }
-
-    @Description("Template for the Kafka MirrorMaker service account.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getServiceAccount() {
-        return serviceAccount;
-    }
-
-    public void setServiceAccount(ResourceTemplate serviceAccount) {
-        this.serviceAccount = serviceAccount;
-    }
-
-    @Override
-    public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties != null ? this.additionalProperties : Map.of();
-    }
-
-    @Override
-    public void setAdditionalProperty(String name, Object value) {
-        if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(2);
-        }
-        this.additionalProperties.put(name, value);
-    }
-}
diff --git a/api/src/main/java/io/strimzi/plugin/security/profiles/PodSecurityProvider.java b/api/src/main/java/io/strimzi/plugin/security/profiles/PodSecurityProvider.java
index c8234cdaf8a..5014b98ce42 100644
--- a/api/src/main/java/io/strimzi/plugin/security/profiles/PodSecurityProvider.java
+++ b/api/src/main/java/io/strimzi/plugin/security/profiles/PodSecurityProvider.java
@@ -130,7 +130,7 @@ default SecurityContext entityUserOperatorContainerSecurityContext(ContainerSecu
     @Deprecated
     @SuppressWarnings("unused")
     default SecurityContext entityOperatorTlsSidecarContainerSecurityContext(ContainerSecurityProviderContext context) {
-        return securityContextOrNull(context);
+        throw new UnsupportedOperationException("TLS Sidecar container in Entity Operator pods is not supported anymore");
     }
 
     /**
@@ -192,7 +192,7 @@ default SecurityContext cruiseControlContainerSecurityContext(ContainerSecurityP
     @Deprecated
     @SuppressWarnings("unused")
     default PodSecurityContext jmxTransPodSecurityContext(PodSecurityProviderContext context) {
-        return null;
+        throw new UnsupportedOperationException("JMX Trans is not supported anymore");
     }
 
     /**
@@ -206,7 +206,7 @@ default PodSecurityContext jmxTransPodSecurityContext(PodSecurityProviderContext
     @Deprecated
     @SuppressWarnings("unused")
     default SecurityContext jmxTransContainerSecurityContext(ContainerSecurityProviderContext context) {
-        return null;
+        throw new UnsupportedOperationException("JMX Trans is not supported anymore");
     }
 
     /**
@@ -271,27 +271,31 @@ default SecurityContext kafkaConnectBuildContainerSecurityContext(ContainerSecur
     }
 
     /**
-     * Provides the Pod security context for the Kafka Mirror Maker 1 pods. The default implementation just returns the
-     * security context configured by the user in the template section or null (no Pod security context).
+     * Previously, this method provided the Pod security context for the Kafka Mirror Maker 1 pods. As Mirror Maker 1 is
+     * not supported anymore, this method is deprecated and always returns null.
      *
      * @param context   Provides the context which can be used to generate the Pod security context
      *
      * @return  Pod security context which will be set for the Kafka Mirror Maker 1 pods
      */
+    @Deprecated
+    @SuppressWarnings("unused")
     default PodSecurityContext kafkaMirrorMakerPodSecurityContext(PodSecurityProviderContext context) {
-        return podSecurityContextOrNull(context);
+        throw new UnsupportedOperationException("Mirror Maker 1 is not supported anymore");
     }
 
     /**
-     * Provides the (container) security context for the Kafka Mirror Maker 1 containers. The default implementation just
-     * returns the security context configured by the user in the template section or null (no security context).
+     * Previously, this method provided the security context for the Kafka Mirror Maker 1 containers. As Mirror Maker 1
+     * is not supported anymore, this method is deprecated and always returns null.
      *
      * @param context   Provides the context which can be used to generate the security context
      *
      * @return  Security context which will be set for the Kafka Mirror Maker 1 containers
      */
+    @Deprecated
+    @SuppressWarnings("unused")
     default SecurityContext kafkaMirrorMakerContainerSecurityContext(ContainerSecurityProviderContext context) {
-        return securityContextOrNull(context);
+        throw new UnsupportedOperationException("Mirror Maker 1 is not supported anymore");
     }
 
     /**
diff --git a/api/src/main/java/io/strimzi/plugin/security/profiles/impl/RestrictedPodSecurityProvider.java b/api/src/main/java/io/strimzi/plugin/security/profiles/impl/RestrictedPodSecurityProvider.java
index 5afda86adef..a68d37efbbb 100644
--- a/api/src/main/java/io/strimzi/plugin/security/profiles/impl/RestrictedPodSecurityProvider.java
+++ b/api/src/main/java/io/strimzi/plugin/security/profiles/impl/RestrictedPodSecurityProvider.java
@@ -97,11 +97,6 @@ public SecurityContext kafkaConnectBuildContainerSecurityContext(ContainerSecuri
         }
     }
 
-    @Override
-    public SecurityContext kafkaMirrorMakerContainerSecurityContext(ContainerSecurityProviderContext context) {
-        return createRestrictedContainerSecurityContext(context);
-    }
-
     @Override
     public SecurityContext bridgeContainerSecurityContext(ContainerSecurityProviderContext context) {
         return createRestrictedContainerSecurityContext(context);
diff --git a/api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
index 6942aecaf42..298b1d6dc48 100644
--- a/api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
+++ b/api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
@@ -33,7 +33,6 @@ public class StructuralCrdIT extends AbstractCrdIT {
             "kafkaconnects.kafka.strimzi.io", "041-Crd-kafkaconnect.yaml",
             "kafkatopics.kafka.strimzi.io", "043-Crd-kafkatopic.yaml",
             "kafkausers.kafka.strimzi.io", "044-Crd-kafkauser.yaml",
-            "kafkamirrormakers.kafka.strimzi.io", "045-Crd-kafkamirrormaker.yaml",
             "kafkabridges.kafka.strimzi.io", "046-Crd-kafkabridge.yaml",
             "kafkaconnectors.kafka.strimzi.io", "047-Crd-kafkaconnector.yaml",
             "kafkamirrormaker2s.kafka.strimzi.io", "048-Crd-kafkamirrormaker2.yaml",
diff --git a/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerCrdIT.java
deleted file mode 100644
index 0618972ae79..00000000000
--- a/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerCrdIT.java
+++ /dev/null
@@ -1,100 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import io.fabric8.kubernetes.client.ConfigBuilder;
-import io.fabric8.kubernetes.client.KubernetesClientBuilder;
-import io.fabric8.kubernetes.client.KubernetesClientException;
-import io.strimzi.api.kafka.model.AbstractCrdIT;
-import io.strimzi.test.CrdUtils;
-import io.strimzi.test.TestUtils;
-import org.junit.jupiter.api.AfterAll;
-import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
-
-import static org.junit.jupiter.api.Assertions.assertThrows;
-
-/**
- * The purpose of this test is to confirm that we can create a
- * resource from the POJOs, serialize it and create the resource in K8S.
- * I.e. that such instance resources obtained from POJOs are valid according to the schema
- * validation done by K8S.
- */
-public class KafkaMirrorMakerCrdIT extends AbstractCrdIT {
-    public static final String NAMESPACE = "kafkamirrormaker-crd-it";
-
-    @SuppressWarnings("deprecation")
-    @Test
-    void testKafkaMirrorMakerScaling() {
-        createScaleDelete(KafkaMirrorMaker.class, "KafkaMirrorMaker.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerMinimal() {
-        createDeleteCustomResource("KafkaMirrorMaker-minimal.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithMissingRequired() {
-        Throwable exception = assertThrows(
-                KubernetesClientException.class,
-                () -> createDeleteCustomResource("KafkaMirrorMaker-with-missing-required-property.yaml"));
-
-        assertMissingRequiredPropertiesMessage(exception.getMessage(), "bootstrapServers", "producer");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithTls() {
-        createDeleteCustomResource("KafkaMirrorMaker-with-tls.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithTlsAuth() {
-        createDeleteCustomResource("KafkaMirrorMaker-with-tls-auth.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithTlsAuthWithMissingRequired() {
-        Throwable exception = assertThrows(
-                KubernetesClientException.class,
-                () -> createDeleteCustomResource("KafkaMirrorMaker-with-tls-auth-with-missing-required.yaml"));
-
-        assertMissingRequiredPropertiesMessage(exception.getMessage(),
-                "spec.producer.authentication.certificateAndKey.certificate",
-                "spec.producer.authentication.certificateAndKey.key");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithScramSha512Auth() {
-        createDeleteCustomResource("KafkaMirrorMaker-with-scram-sha-512-auth.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithTemplate() {
-        createDeleteCustomResource("KafkaMirrorMaker-with-template.yaml");
-    }
-
-    @Test
-    void testKafkaMirrorMakerWithCommitAndAbort() {
-        createDeleteCustomResource("KafkaMirrorMaker-with-commit-and-abort.yaml");
-    }
-
-    @SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
-    @BeforeAll
-    void setupEnvironment() {
-        client = new KubernetesClientBuilder().withConfig(new ConfigBuilder().withNamespace(NAMESPACE).build()).build();
-        CrdUtils.createCrd(client, KafkaMirrorMaker.CRD_NAME, CrdUtils.CRD_KAFKA_MIRROR_MAKER);
-        TestUtils.createNamespace(client, NAMESPACE);
-    }
-
-    @SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
-    @AfterAll
-    void teardownEnvironment() {
-        CrdUtils.deleteCrd(client, KafkaMirrorMaker.CRD_NAME);
-        TestUtils.deleteNamespace(client, NAMESPACE);
-        client.close();
-    }
-}
-
diff --git a/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTest.java b/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTest.java
deleted file mode 100644
index 6c18224c7ae..00000000000
--- a/api/src/test/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerTest.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.api.kafka.model.mirrormaker;
-
-import io.strimzi.api.kafka.model.AbstractCrdTest;
-
-/**
- * The purpose of this test is to ensure:
- *
- * 1. we get a correct tree of POJOs when reading a JSON/YAML `KafkaMirrorMaker` resource.
- */
-@SuppressWarnings("deprecation")
-public class KafkaMirrorMakerTest extends AbstractCrdTest<KafkaMirrorMaker> {
-
-    public KafkaMirrorMakerTest() {
-        super(KafkaMirrorMaker.class);
-    }
-}
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-minimal.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-minimal.yaml
deleted file mode 100644
index df6e89d0818..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-minimal.yaml
+++ /dev/null
@@ -1,12 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  include: "*"
-  consumer:
-    bootstrapServers: my-source-kafka:9092
-    groupId: my-source-group-id
-  producer:
-    bootstrapServers: my-target-kafka:9092
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-commit-and-abort.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-commit-and-abort.yaml
deleted file mode 100644
index f22534df5cc..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-commit-and-abort.yaml
+++ /dev/null
@@ -1,20 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  image: foo
-  replicas: 1
-  include: "*"
-  consumer:
-    numStreams: 2
-    groupId: my-source-group-id
-    bootstrapServers: my-source-kafka:9092
-    offsetCommitInterval: 50000
-    config:
-      foo: bar
-  producer:
-    abortOnSendFailure: false
-    bootstrapServers: my-target-kafka:9092
-    config:
-      foo: buz
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-missing-required-property.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-missing-required-property.yaml
deleted file mode 100644
index 4a34ab2d86b..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-missing-required-property.yaml
+++ /dev/null
@@ -1,10 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  consumer:
-    # required bootstrapServers is missing
-    groupId: my-source-group-id
-  # required producer is missing
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-scram-sha-512-auth.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-scram-sha-512-auth.yaml
deleted file mode 100644
index aedbe6bae34..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-scram-sha-512-auth.yaml
+++ /dev/null
@@ -1,24 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  include: "*"
-  consumer:
-    bootstrapServers: my-source-kafka:9092
-    groupId: my-source-group-id
-    authentication:
-      type: scram-sha-512
-      username: johndoe
-      passwordSecret:
-        secretName: my-user-secret
-        password: password
-  producer:
-    bootstrapServers: my-target-kafka:9092
-    authentication:
-      type: scram-sha-512
-      username: johndoe
-      passwordSecret:
-        secretName: my-user-secret
-        password: password
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-template.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-template.yaml
deleted file mode 100644
index c25ff475be3..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-template.yaml
+++ /dev/null
@@ -1,52 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  image: foo
-  replicas: 1
-  include: "*"
-  consumer:
-    numStreams: 2
-    groupId: my-source-group-id
-    bootstrapServers: my-source-kafka:9092
-    config:
-      foo: bar
-  producer:
-    bootstrapServers: my-target-kafka:9092
-    config:
-      foo: buz
-  template:
-    deployment:
-      metadata:
-        labels:
-          key1: label1
-          key2: label2
-        annotations:
-          key1: label1
-          key2: label2
-    pod:
-      metadata:
-        labels:
-          key1: label1
-          key2: label2
-        annotations:
-          key1: label1
-          key2: label2
-      imagePullSecrets:
-        - name: some-secret
-        - name: some-other-secret
-      securityContext:
-        runAsUser: 1000001
-        runAsGroup: 1000001
-        fsGroup: 0
-      terminationGracePeriodSeconds: 30
-    podDisruptionBudget:
-      metadata:
-        labels:
-          key1: label1
-          key2: label2
-        annotations:
-          key1: label1
-          key2: label2
-      maxUnavailable: 1
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth-with-missing-required.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth-with-missing-required.yaml
deleted file mode 100644
index 2a46614ef42..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth-with-missing-required.yaml
+++ /dev/null
@@ -1,34 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  consumer:
-    bootstrapServers: my-source-kafka:9093
-    groupId: my-source-group-id
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
-    authentication:
-      type: tls
-      certificateAndKey:
-        secretName: my-user-secret
-        key: user.key
-        certificate: user.crt
-  producer:
-    bootstrapServers: my-target-kafka:9093
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
-    authentication:
-      type: tls
-      certificateAndKey:
-        secretName: my-user-secret
-        # required key and certificate are missing
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth.yaml
deleted file mode 100644
index f38a432e514..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls-auth.yaml
+++ /dev/null
@@ -1,36 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  include: "*"
-  consumer:
-    bootstrapServers: my-source-kafka:9093
-    groupId: my-source-group-id
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
-    authentication:
-      type: tls
-      certificateAndKey:
-        secretName: my-user-secret
-        key: user.key
-        certificate: user.crt
-  producer:
-    bootstrapServers: my-target-kafka:9093
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
-    authentication:
-      type: tls
-      certificateAndKey:
-        secretName: my-user-secret
-        key: user.key
-        certificate: user.crt
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls.yaml
deleted file mode 100644
index 61cfbe7ffff..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker-with-tls.yaml
+++ /dev/null
@@ -1,24 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  replicas: 1
-  include: "*"
-  consumer:
-    bootstrapServers: my-source-kafka:9093
-    groupId: my-source-group-id
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
-  producer:
-    bootstrapServers: my-target-kafka:9093
-    tls:
-      trustedCertificates:
-        - secretName: my-secret
-          certificate: ca.crt
-        - secretName: my-another-secret
-          certificate: another-ca.crt
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.out.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.out.yaml
deleted file mode 100644
index 0234e3681c9..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.out.yaml
+++ /dev/null
@@ -1,19 +0,0 @@
----
-apiVersion: "kafka.strimzi.io/v1beta2"
-kind: "KafkaMirrorMaker"
-metadata:
-  name: "test-kafka-mirror-maker"
-spec:
-  replicas: 1
-  image: "foo"
-  consumer:
-    numStreams: 2
-    bootstrapServers: "my-source-kafka:9092"
-    groupId: "my-source-group-id"
-    config:
-      foo: "bar"
-  producer:
-    bootstrapServers: "my-target-kafka:9092"
-    config:
-      foo: "buz"
-  include: "*"
\ No newline at end of file
diff --git a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.yaml b/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.yaml
deleted file mode 100644
index d3776ff661a..00000000000
--- a/api/src/test/resources/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMaker.yaml
+++ /dev/null
@@ -1,18 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: test-kafka-mirror-maker
-spec:
-  image: foo
-  replicas: 1
-  include: "*"
-  consumer:
-    numStreams: 2
-    groupId: my-source-group-id
-    bootstrapServers: my-source-kafka:9092
-    config:
-      foo: bar
-  producer:
-    bootstrapServers: my-target-kafka:9092
-    config:
-      foo: buz
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
index 1bb094b0449..142fb551874 100644
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
+++ b/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
@@ -11,7 +11,6 @@
 import io.strimzi.operator.cluster.operator.assembly.KafkaBridgeAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaConnectAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaMirrorMaker2AssemblyOperator;
-import io.strimzi.operator.cluster.operator.assembly.KafkaMirrorMakerAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaRebalanceAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.ReconnectingWatcher;
 import io.strimzi.operator.cluster.operator.assembly.StrimziPodSetController;
@@ -49,7 +48,6 @@ public class ClusterOperator extends AbstractVerticle {
     private long reconcileTimer;
     private final KafkaAssemblyOperator kafkaAssemblyOperator;
     private final KafkaConnectAssemblyOperator kafkaConnectAssemblyOperator;
-    private final KafkaMirrorMakerAssemblyOperator kafkaMirrorMakerAssemblyOperator;
     private final KafkaMirrorMaker2AssemblyOperator kafkaMirrorMaker2AssemblyOperator;
     private final KafkaBridgeAssemblyOperator kafkaBridgeAssemblyOperator;
     private final KafkaRebalanceAssemblyOperator kafkaRebalanceAssemblyOperator;
@@ -68,7 +66,6 @@ public class ClusterOperator extends AbstractVerticle {
      * @param config                            Cluster Operator configuration
      * @param kafkaAssemblyOperator             Kafka operator
      * @param kafkaConnectAssemblyOperator      KafkaConnect operator
-     * @param kafkaMirrorMakerAssemblyOperator  KafkaMirrorMaker operator
      * @param kafkaMirrorMaker2AssemblyOperator KafkaMirrorMaker2 operator
      * @param kafkaBridgeAssemblyOperator       KafkaBridge operator
      * @param kafkaRebalanceAssemblyOperator    KafkaRebalance operator
@@ -78,7 +75,6 @@ public ClusterOperator(String namespace,
                            ClusterOperatorConfig config,
                            KafkaAssemblyOperator kafkaAssemblyOperator,
                            KafkaConnectAssemblyOperator kafkaConnectAssemblyOperator,
-                           KafkaMirrorMakerAssemblyOperator kafkaMirrorMakerAssemblyOperator,
                            KafkaMirrorMaker2AssemblyOperator kafkaMirrorMaker2AssemblyOperator,
                            KafkaBridgeAssemblyOperator kafkaBridgeAssemblyOperator,
                            KafkaRebalanceAssemblyOperator kafkaRebalanceAssemblyOperator,
@@ -88,7 +84,6 @@ public ClusterOperator(String namespace,
         this.config = config;
         this.kafkaAssemblyOperator = kafkaAssemblyOperator;
         this.kafkaConnectAssemblyOperator = kafkaConnectAssemblyOperator;
-        this.kafkaMirrorMakerAssemblyOperator = kafkaMirrorMakerAssemblyOperator;
         this.kafkaMirrorMaker2AssemblyOperator = kafkaMirrorMaker2AssemblyOperator;
         this.kafkaBridgeAssemblyOperator = kafkaBridgeAssemblyOperator;
         this.kafkaRebalanceAssemblyOperator = kafkaRebalanceAssemblyOperator;
@@ -107,8 +102,8 @@ public void start(Promise<Void> start) {
 
         if (!config.isPodSetReconciliationOnly()) {
             List<AbstractOperator<?, ?, ?, ?>> operators = new ArrayList<>(asList(
-                    kafkaAssemblyOperator, kafkaMirrorMakerAssemblyOperator, kafkaConnectAssemblyOperator,
-                    kafkaBridgeAssemblyOperator, kafkaMirrorMaker2AssemblyOperator, kafkaRebalanceAssemblyOperator));
+                    kafkaAssemblyOperator, kafkaConnectAssemblyOperator, kafkaBridgeAssemblyOperator,
+                    kafkaMirrorMaker2AssemblyOperator, kafkaRebalanceAssemblyOperator));
             for (AbstractOperator<?, ?, ?, ?> operator : operators) {
                 startFutures.add(operator.createWatch(namespace).compose(w -> {
                     LOGGER.info("Opened watch for {} operator", operator.kind());
@@ -192,7 +187,6 @@ private void reconcileAll(String trigger) {
             Handler<AsyncResult<Void>> ignore = ignored -> {
             };
             kafkaAssemblyOperator.reconcileAll(trigger, namespace, ignore);
-            kafkaMirrorMakerAssemblyOperator.reconcileAll(trigger, namespace, ignore);
             kafkaConnectAssemblyOperator.reconcileAll(trigger, namespace, ignore);
             kafkaMirrorMaker2AssemblyOperator.reconcileAll(trigger, namespace, ignore);
             kafkaBridgeAssemblyOperator.reconcileAll(trigger, namespace, ignore);
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
index df00e87294c..553a7047853 100644
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
+++ b/cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
@@ -55,11 +55,6 @@ public class ClusterOperatorConfig {
      */
     public static final String STRIMZI_KAFKA_CONNECT_IMAGES = "STRIMZI_KAFKA_CONNECT_IMAGES";
 
-    /**
-     * Configures the Kafka Mirror Maker container images
-     */
-    public static final String STRIMZI_KAFKA_MIRROR_MAKER_IMAGES = "STRIMZI_KAFKA_MIRROR_MAKER_IMAGES";
-
     /**
      * Configures the Kafka Mirror Maker 2 container images
      */
@@ -288,7 +283,7 @@ private static void warningsForRemovedEndVars(Map<String, String> map) {
 
     public static ClusterOperatorConfig buildFromMap(Map<String, String> map) {
         warningsForRemovedEndVars(map);
-        KafkaVersion.Lookup lookup = parseKafkaVersions(map.get(STRIMZI_KAFKA_IMAGES), map.get(STRIMZI_KAFKA_CONNECT_IMAGES), map.get(STRIMZI_KAFKA_MIRROR_MAKER_IMAGES), map.get(STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES));
+        KafkaVersion.Lookup lookup = parseKafkaVersions(map.get(STRIMZI_KAFKA_IMAGES), map.get(STRIMZI_KAFKA_CONNECT_IMAGES), map.get(STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES));
         return buildFromMap(map, lookup);
 
     }
@@ -342,11 +337,10 @@ public <T> T get(ConfigParameter<T> value) {
         return (T) this.map.get(value.key());
     }
 
-    private static KafkaVersion.Lookup parseKafkaVersions(String kafkaImages, String connectImages, String mirrorMakerImages, String mirrorMaker2Images) {
+    private static KafkaVersion.Lookup parseKafkaVersions(String kafkaImages, String connectImages, String mirrorMaker2Images) {
         KafkaVersion.Lookup lookup = new KafkaVersion.Lookup(
                 Util.parseMap(kafkaImages),
                 Util.parseMap(connectImages),
-                Util.parseMap(mirrorMakerImages),
                 Util.parseMap(mirrorMaker2Images));
 
         String image = "";
@@ -361,10 +355,6 @@ private static KafkaVersion.Lookup parseKafkaVersions(String kafkaImages, String
             envVar = STRIMZI_KAFKA_CONNECT_IMAGES;
             lookup.validateKafkaConnectImages(lookup.supportedVersions());
 
-            image = "Kafka Mirror Maker";
-            envVar = STRIMZI_KAFKA_MIRROR_MAKER_IMAGES;
-            lookup.validateKafkaMirrorMakerImages(lookup.supportedVersions());
-
             image = "Kafka Mirror Maker 2";
             envVar = STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES;
             lookup.validateKafkaMirrorMaker2Images(lookup.supportedVersionsForFeature("kafkaMirrorMaker2"));
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
index b01d8f308a9..a01d4eddda7 100644
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
+++ b/cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
@@ -14,7 +14,6 @@
 import io.strimzi.operator.cluster.operator.assembly.KafkaBridgeAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaConnectAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaMirrorMaker2AssemblyOperator;
-import io.strimzi.operator.cluster.operator.assembly.KafkaMirrorMakerAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaRebalanceAssemblyOperator;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.MetricsProvider;
@@ -148,7 +147,6 @@ static CompositeFuture deployClusterOperatorVerticles(Vertx vertx, KubernetesCli
         KafkaAssemblyOperator kafkaClusterOperations = null;
         KafkaConnectAssemblyOperator kafkaConnectClusterOperations = null;
         KafkaMirrorMaker2AssemblyOperator kafkaMirrorMaker2AssemblyOperator = null;
-        KafkaMirrorMakerAssemblyOperator kafkaMirrorMakerAssemblyOperator = null;
         KafkaBridgeAssemblyOperator kafkaBridgeAssemblyOperator = null;
         KafkaRebalanceAssemblyOperator kafkaRebalanceAssemblyOperator = null;
 
@@ -164,7 +162,6 @@ static CompositeFuture deployClusterOperatorVerticles(Vertx vertx, KubernetesCli
             kafkaClusterOperations = new KafkaAssemblyOperator(vertx, pfa, certManager, passwordGenerator, resourceOperatorSupplier, config);
             kafkaConnectClusterOperations = new KafkaConnectAssemblyOperator(vertx, pfa, resourceOperatorSupplier, config);
             kafkaMirrorMaker2AssemblyOperator = new KafkaMirrorMaker2AssemblyOperator(vertx, pfa, resourceOperatorSupplier, config);
-            kafkaMirrorMakerAssemblyOperator = new KafkaMirrorMakerAssemblyOperator(vertx, pfa, certManager, passwordGenerator, resourceOperatorSupplier, config);
             kafkaBridgeAssemblyOperator = new KafkaBridgeAssemblyOperator(vertx, pfa, certManager, passwordGenerator, resourceOperatorSupplier, config);
             kafkaRebalanceAssemblyOperator = new KafkaRebalanceAssemblyOperator(vertx, resourceOperatorSupplier, config);
         }
@@ -177,7 +174,6 @@ static CompositeFuture deployClusterOperatorVerticles(Vertx vertx, KubernetesCli
                     config,
                     kafkaClusterOperations,
                     kafkaConnectClusterOperations,
-                    kafkaMirrorMakerAssemblyOperator,
                     kafkaMirrorMaker2AssemblyOperator,
                     kafkaBridgeAssemblyOperator,
                     kafkaRebalanceAssemblyOperator,
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
deleted file mode 100644
index e965edfb035..00000000000
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
+++ /dev/null
@@ -1,488 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.operator.cluster.model;
-
-import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.Container;
-import io.fabric8.kubernetes.api.model.ContainerPort;
-import io.fabric8.kubernetes.api.model.EnvVar;
-import io.fabric8.kubernetes.api.model.HasMetadata;
-import io.fabric8.kubernetes.api.model.LocalObjectReference;
-import io.fabric8.kubernetes.api.model.Volume;
-import io.fabric8.kubernetes.api.model.VolumeMount;
-import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudget;
-import io.strimzi.api.kafka.model.common.JvmOptions;
-import io.strimzi.api.kafka.model.common.Probe;
-import io.strimzi.api.kafka.model.common.ProbeBuilder;
-import io.strimzi.api.kafka.model.common.template.DeploymentTemplate;
-import io.strimzi.api.kafka.model.common.template.PodDisruptionBudgetTemplate;
-import io.strimzi.api.kafka.model.common.template.PodTemplate;
-import io.strimzi.api.kafka.model.common.tracing.JaegerTracing;
-import io.strimzi.api.kafka.model.common.tracing.OpenTelemetryTracing;
-import io.strimzi.api.kafka.model.common.tracing.Tracing;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerTemplate;
-import io.strimzi.operator.cluster.model.logging.LoggingModel;
-import io.strimzi.operator.cluster.model.logging.SupportsLogging;
-import io.strimzi.operator.cluster.model.metrics.MetricsModel;
-import io.strimzi.operator.cluster.model.metrics.SupportsMetrics;
-import io.strimzi.operator.cluster.model.securityprofiles.ContainerSecurityProviderContextImpl;
-import io.strimzi.operator.cluster.model.securityprofiles.PodSecurityProviderContextImpl;
-import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.Util;
-import io.strimzi.operator.common.model.InvalidResourceException;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import static io.strimzi.api.kafka.model.common.template.DeploymentStrategy.ROLLING_UPDATE;
-
-/**
- * Kafka Mirror Maker 1 model
- */
-@SuppressWarnings({"checkstyle:CyclomaticComplexity", "checkstyle:NPathComplexity"})
-public class KafkaMirrorMakerCluster extends AbstractModel implements SupportsMetrics, SupportsLogging {
-    protected static final String COMPONENT_TYPE = "kafka-mirror-maker";
-
-    protected static final String TLS_CERTS_VOLUME_MOUNT_CONSUMER = "/opt/kafka/consumer-certs/";
-    protected static final String PASSWORD_VOLUME_MOUNT_CONSUMER = "/opt/kafka/consumer-password/";
-    protected static final String TLS_CERTS_VOLUME_MOUNT_PRODUCER = "/opt/kafka/producer-certs/";
-    protected static final String PASSWORD_VOLUME_MOUNT_PRODUCER = "/opt/kafka/producer-password/";
-    protected static final String OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER = "/opt/kafka/consumer-oauth-certs/";
-    protected static final String OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER = "/opt/kafka/producer-oauth-certs/";
-    private static final String LOG_AND_METRICS_CONFIG_VOLUME_NAME = "kafka-metrics-and-logging";
-    private static final String LOG_AND_METRICS_CONFIG_VOLUME_MOUNT = "/opt/kafka/custom-config/";
-
-    // Configuration defaults
-    private static final int DEFAULT_HEALTHCHECK_PERIOD = 10; // This is used inside the Mirror Maker agent
-    private static final Probe DEFAULT_HEALTHCHECK_OPTIONS = new ProbeBuilder().withTimeoutSeconds(5).withInitialDelaySeconds(60).build();
-
-    // Kafka Mirror Maker configuration keys (EnvVariables)
-    protected static final String ENV_VAR_PREFIX = "KAFKA_MIRRORMAKER_";
-
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_METRICS_ENABLED = "KAFKA_MIRRORMAKER_METRICS_ENABLED";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER = "KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_CONSUMER = "KAFKA_MIRRORMAKER_TLS_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER = "KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_CERT_CONSUMER = "KAFKA_MIRRORMAKER_TLS_AUTH_CERT_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_KEY_CONSUMER = "KAFKA_MIRRORMAKER_TLS_AUTH_KEY_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER = "KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER = "KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER = "KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_GROUPID_CONSUMER = "KAFKA_MIRRORMAKER_GROUPID_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER = "KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER = "KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER";
-
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_PRODUCER = "KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_PRODUCER = "KAFKA_MIRRORMAKER_TLS_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER = "KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_CERT_PRODUCER = "KAFKA_MIRRORMAKER_TLS_AUTH_CERT_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_KEY_PRODUCER = "KAFKA_MIRRORMAKER_TLS_AUTH_KEY_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER = "KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER = "KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER = "KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER = "KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER = "KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER";
-
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_INCLUDE = "KAFKA_MIRRORMAKER_INCLUDE";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS = "KAFKA_MIRRORMAKER_NUMSTREAMS";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL = "KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL";
-    protected static final String ENV_VAR_KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE = "KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE";
-
-    protected static final String ENV_VAR_STRIMZI_READINESS_PERIOD = "STRIMZI_READINESS_PERIOD";
-    protected static final String ENV_VAR_STRIMZI_LIVENESS_PERIOD = "STRIMZI_LIVENESS_PERIOD";
-    protected static final String ENV_VAR_STRIMZI_TRACING = "STRIMZI_TRACING";
-
-    protected static final String CO_ENV_VAR_CUSTOM_MIRROR_MAKER_POD_LABELS = "STRIMZI_CUSTOM_KAFKA_MIRROR_MAKER_LABELS";
-
-    private int replicas;
-    protected String include;
-    protected Tracing tracing;
-    private MetricsModel metrics;
-    private LoggingModel logging;
-
-    protected KafkaMirrorMakerProducerSpec producer;
-    protected KafkaMirrorMakerConsumerSpec consumer;
-
-    // Templates
-    private PodDisruptionBudgetTemplate templatePodDisruptionBudget;
-    private DeploymentTemplate templateDeployment;
-    private PodTemplate templatePod;
-
-    private static final Map<String, String> DEFAULT_POD_LABELS = new HashMap<>();
-    static {
-        String value = System.getenv(CO_ENV_VAR_CUSTOM_MIRROR_MAKER_POD_LABELS);
-        if (value != null) {
-            DEFAULT_POD_LABELS.putAll(Util.parseMap(value));
-        }
-    }
-
-    /**
-     * Constructor
-     *
-     * @param reconciliation The reconciliation
-     * @param resource Kubernetes resource with metadata containing the namespace and cluster name
-     * @param sharedEnvironmentProvider Shared environment provider
-     */
-    protected KafkaMirrorMakerCluster(Reconciliation reconciliation, HasMetadata resource, SharedEnvironmentProvider sharedEnvironmentProvider) {
-        super(reconciliation, resource, KafkaMirrorMakerResources.componentName(resource.getMetadata().getName()), COMPONENT_TYPE, sharedEnvironmentProvider);
-    }
-
-    /**
-     * Creates the Kafka Mirror Maker 1 model from the KafkaMirrorMaker CR
-     *
-     * @param reconciliation        Reconciliation marker
-     * @param kafkaMirrorMaker      KafkaMirrorMaker custom resource
-     * @param versions              Supported Kafka versions
-     * @param sharedEnvironmentProvider Shared environment provider.
-     *
-     * @return  Kafka Mirror Maker model instance
-     */
-    @SuppressWarnings("deprecation")
-    public static KafkaMirrorMakerCluster fromCrd(Reconciliation reconciliation,
-                                                  KafkaMirrorMaker kafkaMirrorMaker,
-                                                  KafkaVersion.Lookup versions,
-                                                  SharedEnvironmentProvider sharedEnvironmentProvider) {
-        KafkaMirrorMakerCluster result = new KafkaMirrorMakerCluster(reconciliation, kafkaMirrorMaker, sharedEnvironmentProvider);
-
-        KafkaMirrorMakerSpec spec = kafkaMirrorMaker.getSpec();
-        if (spec != null) {
-            result.replicas = spec.getReplicas();
-            result.resources = spec.getResources();
-            result.readinessProbeOptions = ProbeUtils.extractReadinessProbeOptionsOrDefault(spec, DEFAULT_HEALTHCHECK_OPTIONS);
-            result.livenessProbeOptions = ProbeUtils.extractLivenessProbeOptionsOrDefault(spec, DEFAULT_HEALTHCHECK_OPTIONS);
-
-            String whitelist = spec.getWhitelist();
-            String include = spec.getInclude();
-
-            if (include == null && whitelist == null)   {
-                throw new InvalidResourceException("One of the fields include or whitelist needs to be specified.");
-            } else if (whitelist != null && include != null) {
-                LOGGER.warnCr(reconciliation, "Both include and whitelist fields are present. Whitelist is deprecated and will be ignored.");
-            }
-
-            result.include = include != null ? include : whitelist;
-
-            String warnMsg = AuthenticationUtils.validateClientAuthentication(spec.getProducer().getAuthentication(), spec.getProducer().getTls() != null);
-            if (!warnMsg.isEmpty()) {
-                LOGGER.warnCr(reconciliation, warnMsg);
-            }
-
-            result.producer = spec.getProducer();
-
-            warnMsg = AuthenticationUtils.validateClientAuthentication(spec.getConsumer().getAuthentication(), spec.getConsumer().getTls() != null);
-            if (!warnMsg.isEmpty()) {
-                LOGGER.warnCr(reconciliation, warnMsg);
-            }
-
-            result.consumer = spec.getConsumer();
-
-            result.image = versions.kafkaMirrorMakerImage(spec.getImage(), spec.getVersion());
-
-            result.gcLoggingEnabled = spec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
-            result.jvmOptions = spec.getJvmOptions();
-            result.metrics = new MetricsModel(spec);
-            result.logging = new LoggingModel(spec, result.getClass().getSimpleName(), false, true);
-
-            if (spec.getTemplate() != null) {
-                KafkaMirrorMakerTemplate template = spec.getTemplate();
-
-                result.templatePodDisruptionBudget = template.getPodDisruptionBudget();
-                result.templateDeployment = template.getDeployment();
-                result.templatePod = template.getPod();
-                result.templateServiceAccount = template.getServiceAccount();
-                result.templateContainer = template.getMirrorMakerContainer();
-            }
-
-            result.tracing = spec.getTracing();
-        }
-
-        return result;
-    }
-
-    protected List<ContainerPort> getContainerPortList() {
-        List<ContainerPort> portList = new ArrayList<>(1);
-        if (metrics.isEnabled()) {
-            portList.add(ContainerUtils.createContainerPort(MetricsModel.METRICS_PORT_NAME, MetricsModel.METRICS_PORT));
-        }
-
-        return portList;
-    }
-
-    protected List<Volume> getVolumes(boolean isOpenShift) {
-        List<Volume> volumeList = new ArrayList<>(2);
-
-        volumeList.add(VolumeUtils.createTempDirVolume(templatePod));
-        volumeList.add(VolumeUtils.createConfigMapVolume(LOG_AND_METRICS_CONFIG_VOLUME_NAME, KafkaMirrorMakerResources.metricsAndLogConfigMapName(cluster)));
-
-        if (producer.getTls() != null) {
-            CertUtils.createTrustedCertificatesVolumes(volumeList, producer.getTls().getTrustedCertificates(), isOpenShift);
-        }
-        AuthenticationUtils.configureClientAuthenticationVolumes(producer.getAuthentication(), volumeList, "producer-oauth-certs", isOpenShift);
-
-        if (consumer.getTls() != null) {
-            CertUtils.createTrustedCertificatesVolumes(volumeList, consumer.getTls().getTrustedCertificates(), isOpenShift);
-        }
-        AuthenticationUtils.configureClientAuthenticationVolumes(consumer.getAuthentication(), volumeList, "consumer-oauth-certs", isOpenShift);
-
-        return volumeList;
-    }
-
-    protected List<VolumeMount> getVolumeMounts() {
-        List<VolumeMount> volumeMountList = new ArrayList<>(2);
-
-        volumeMountList.add(VolumeUtils.createTempDirVolumeMount());
-        volumeMountList.add(VolumeUtils.createVolumeMount(LOG_AND_METRICS_CONFIG_VOLUME_NAME, LOG_AND_METRICS_CONFIG_VOLUME_MOUNT));
-        /* producer auth*/
-        if (producer.getTls() != null) {
-            CertUtils.createTrustedCertificatesVolumeMounts(volumeMountList, producer.getTls().getTrustedCertificates(), TLS_CERTS_VOLUME_MOUNT_PRODUCER);
-        }
-        AuthenticationUtils.configureClientAuthenticationVolumeMounts(producer.getAuthentication(), volumeMountList, TLS_CERTS_VOLUME_MOUNT_PRODUCER, PASSWORD_VOLUME_MOUNT_PRODUCER, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER, "producer-oauth-certs");
-
-        /* consumer auth*/
-        if (consumer.getTls() != null) {
-            CertUtils.createTrustedCertificatesVolumeMounts(volumeMountList, consumer.getTls().getTrustedCertificates(), TLS_CERTS_VOLUME_MOUNT_CONSUMER);
-        }
-        AuthenticationUtils.configureClientAuthenticationVolumeMounts(consumer.getAuthentication(), volumeMountList, TLS_CERTS_VOLUME_MOUNT_CONSUMER, PASSWORD_VOLUME_MOUNT_CONSUMER, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER, "consumer-oauth-certs");
-
-        return volumeMountList;
-    }
-
-    /**
-     * Generates Kafka Mirror Maker Deployment
-     *
-     * @param annotations       Map with annotations
-     * @param isOpenShift       Flag indicating if we are on OpenShift
-     * @param imagePullPolicy   Image pull policy
-     * @param imagePullSecrets  List with image pull secrets
-     *
-     * @return  Generated Deployment
-     */
-    public Deployment generateDeployment(Map<String, String> annotations, boolean isOpenShift, ImagePullPolicy imagePullPolicy, List<LocalObjectReference> imagePullSecrets) {
-        return WorkloadUtils.createDeployment(
-                componentName,
-                namespace,
-                labels,
-                ownerReference,
-                templateDeployment,
-                replicas,
-                null,
-                WorkloadUtils.deploymentStrategy(TemplateUtils.deploymentStrategy(templateDeployment, ROLLING_UPDATE)),
-                WorkloadUtils.createPodTemplateSpec(
-                        componentName,
-                        labels,
-                        templatePod,
-                        DEFAULT_POD_LABELS,
-                        annotations,
-                        templatePod != null ? templatePod.getAffinity() : null,
-                        null,
-                        List.of(createContainer(imagePullPolicy)),
-                        getVolumes(isOpenShift),
-                        imagePullSecrets,
-                        securityProvider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(templatePod))
-                )
-        );
-    }
-
-    /* test */ Container createContainer(ImagePullPolicy imagePullPolicy) {
-        return ContainerUtils.createContainer(
-                componentName,
-                image,
-                List.of("/opt/kafka/kafka_mirror_maker_run.sh"),
-                securityProvider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(templateContainer)),
-                resources,
-                getEnvVars(),
-                getContainerPortList(),
-                getVolumeMounts(),
-                ProbeUtils.defaultBuilder(livenessProbeOptions).withNewExec().withCommand("/opt/kafka/kafka_mirror_maker_liveness.sh").endExec().build(),
-                // The mirror-maker-agent will create /tmp/mirror-maker-ready in the container
-                ProbeUtils.defaultBuilder(readinessProbeOptions).withNewExec().withCommand("test", "-f", "/tmp/mirror-maker-ready").endExec().build(),
-                imagePullPolicy
-        );
-    }
-
-    @SuppressWarnings("deprecation")
-    private KafkaMirrorMakerConsumerConfiguration getConsumerConfiguration() {
-        KafkaMirrorMakerConsumerConfiguration config = new KafkaMirrorMakerConsumerConfiguration(reconciliation, consumer.getConfig().entrySet());
-
-        if (tracing != null) {
-            if (JaegerTracing.TYPE_JAEGER.equals(tracing.getType())) {
-                LOGGER.warnCr(reconciliation, "Tracing type \"{}\" is not supported anymore and will be ignored", JaegerTracing.TYPE_JAEGER);
-            } else if (OpenTelemetryTracing.TYPE_OPENTELEMETRY.equals(tracing.getType())) {
-                config.setConfigOption("interceptor.classes", OpenTelemetryTracing.CONSUMER_INTERCEPTOR_CLASS_NAME);
-            }
-        }
-
-        return config;
-    }
-
-    @SuppressWarnings("deprecation")
-    private KafkaMirrorMakerProducerConfiguration getProducerConfiguration()    {
-        KafkaMirrorMakerProducerConfiguration config = new KafkaMirrorMakerProducerConfiguration(reconciliation, producer.getConfig().entrySet());
-
-        if (tracing != null) {
-            if (JaegerTracing.TYPE_JAEGER.equals(tracing.getType())) {
-                LOGGER.warnCr(reconciliation, "Tracing type \"{}\" is not supported anymore and will be ignored", JaegerTracing.TYPE_JAEGER);
-            } else if (OpenTelemetryTracing.TYPE_OPENTELEMETRY.equals(tracing.getType())) {
-                config.setConfigOption("interceptor.classes", OpenTelemetryTracing.PRODUCER_INTERCEPTOR_CLASS_NAME);
-            }
-        }
-
-        return config;
-    }
-
-    protected List<EnvVar> getEnvVars() {
-        List<EnvVar> varList = new ArrayList<>();
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER,
-                getConsumerConfiguration().getConfiguration()));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER,
-                getProducerConfiguration().getConfiguration()));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_METRICS_ENABLED, String.valueOf(metrics.isEnabled())));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER, consumer.getBootstrapServers()));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_PRODUCER, producer.getBootstrapServers()));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_INCLUDE, include));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_GROUPID_CONSUMER, consumer.getGroupId()));
-        if (consumer.getNumStreams() != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS, Integer.toString(consumer.getNumStreams())));
-        }
-        if (consumer.getOffsetCommitInterval() != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL, Integer.toString(consumer.getOffsetCommitInterval())));
-        }
-        if (producer.getAbortOnSendFailure() != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE, Boolean.toString(producer.getAbortOnSendFailure())));
-        }
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
-
-        if (tracing != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_TRACING, tracing.getType()));
-        }
-
-        JvmOptionUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
-        JvmOptionUtils.jvmPerformanceOptions(varList, jvmOptions);
-        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
-
-        /* consumer */
-        addConsumerEnvVars(varList);
-
-        /* producer */
-        addProducerEnvVars(varList);
-
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_LIVENESS_PERIOD,
-                String.valueOf(livenessProbeOptions.getPeriodSeconds() != null ? livenessProbeOptions.getPeriodSeconds() : DEFAULT_HEALTHCHECK_PERIOD)));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_READINESS_PERIOD,
-                String.valueOf(readinessProbeOptions.getPeriodSeconds() != null ? readinessProbeOptions.getPeriodSeconds() : DEFAULT_HEALTHCHECK_PERIOD)));
-
-        // Add shared environment variables used for all containers
-        varList.addAll(sharedEnvironmentProvider.variables());
-
-        ContainerUtils.addContainerEnvsToExistingEnvs(reconciliation, varList, templateContainer);
-
-        return varList;
-    }
-
-    /**
-     * Sets the consumer related environment variables in the provided List.
-     *
-     * @param varList   List with environment variables
-     */
-    private void addConsumerEnvVars(List<EnvVar> varList) {
-        if (consumer.getTls() != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_TLS_CONSUMER, "true"));
-
-            if (consumer.getTls().getTrustedCertificates() != null && !consumer.getTls().getTrustedCertificates().isEmpty()) {
-                varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER, CertUtils.trustedCertsEnvVar(consumer.getTls().getTrustedCertificates())));
-            }
-        }
-
-        AuthenticationUtils.configureClientAuthenticationEnvVars(consumer.getAuthentication(), varList, name -> ENV_VAR_PREFIX + name + "_CONSUMER");
-    }
-
-    /**
-     * Sets the producer related environment variables in the provided List.
-     *
-     * @param varList   List with environment variables
-     */
-    private void addProducerEnvVars(List<EnvVar> varList) {
-        if (producer.getTls() != null) {
-            varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_TLS_PRODUCER, "true"));
-
-            if (producer.getTls().getTrustedCertificates() != null && !producer.getTls().getTrustedCertificates().isEmpty()) {
-                varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER, CertUtils.trustedCertsEnvVar(producer.getTls().getTrustedCertificates())));
-            }
-        }
-
-        AuthenticationUtils.configureClientAuthenticationEnvVars(producer.getAuthentication(), varList, name -> ENV_VAR_PREFIX + name + "_PRODUCER");
-    }
-
-    /**
-     * Generates the PodDisruptionBudget
-     *
-     * @return The pod disruption budget.
-     */
-    public PodDisruptionBudget generatePodDisruptionBudget() {
-        return PodDisruptionBudgetUtils.createPodDisruptionBudget(componentName, namespace, labels, ownerReference, templatePodDisruptionBudget);
-    }
-
-    protected String getInclude() {
-        return include;
-    }
-
-    /**
-     * Generates a metrics and logging ConfigMap according to the configuration. If this operand doesn't support logging
-     * or metrics, they will nto be set.
-     *
-     * @param metricsAndLogging     The external CMs with logging and metrics configuration
-     *
-     * @return The generated ConfigMap
-     */
-    public ConfigMap generateMetricsAndLogConfigMap(MetricsAndLogging metricsAndLogging) {
-        return ConfigMapUtils
-                .createConfigMap(
-                        KafkaMirrorMakerResources.metricsAndLogConfigMapName(cluster),
-                        namespace,
-                        labels,
-                        ownerReference,
-                        ConfigMapUtils.generateMetricsAndLogConfigMapData(reconciliation, this, metricsAndLogging)
-                );
-    }
-
-    /**
-     * @return The number of replicas
-     */
-    public int getReplicas() {
-        return replicas;
-    }
-
-    /**
-     * @return  Metrics Model instance for configuring Prometheus metrics
-     */
-    public MetricsModel metrics()   {
-        return metrics;
-    }
-
-    /**
-     * @return  Logging Model instance for configuring logging
-     */
-    public LoggingModel logging()   {
-        return logging;
-    }
-}
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java
deleted file mode 100644
index 03339cc2d6f..00000000000
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-
-package io.strimzi.operator.cluster.model;
-
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec;
-import io.strimzi.operator.common.Reconciliation;
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-/**
- * Class for handling Kafka Mirror Maker consumer configuration passed by the user
- */
-public class KafkaMirrorMakerConsumerConfiguration extends AbstractConfiguration {
-    private static final List<String> FORBIDDEN_PREFIXES;
-    private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS;
-    private static final Map<String, String> DEFAULTS;
-
-    static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
-        DEFAULTS = new HashMap<>(0);
-    }
-
-    /**
-     * Constructor used to instantiate this class from JsonObject. Should be used to create configuration from
-     * ConfigMap / CRD.
-     *
-     * @param reconciliation  The reconciliation
-     * @param jsonOptions     Json object with configuration options as key ad value pairs.
-     */
-    public KafkaMirrorMakerConsumerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
-    }
-}
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java
deleted file mode 100644
index c13e92b7096..00000000000
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-
-package io.strimzi.operator.cluster.model;
-
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec;
-import io.strimzi.operator.common.Reconciliation;
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-/**
- * Class for handling Kafka Mirror Maker producer configuration passed by the user
- */
-public class KafkaMirrorMakerProducerConfiguration extends AbstractConfiguration {
-    private static final List<String> FORBIDDEN_PREFIXES;
-    private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS;
-    private static final Map<String, String> DEFAULTS;
-
-    static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
-        DEFAULTS = new HashMap<>(0);
-    }
-
-    /**
-     * Constructor used to instantiate this class from JsonObject. Should be used to create configuration from
-     * ConfigMap / CRD.
-     *
-     * @param reconciliation  The reconciliation
-     * @param jsonOptions     Json object with configuration options as key ad value pairs.
-     */
-    public KafkaMirrorMakerProducerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
-    }
-}
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
index 6f03a75cd00..bf6aa262b3d 100644
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
+++ b/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
@@ -82,7 +82,6 @@ public static class Lookup {
         private final KafkaVersion defaultVersion;
         private final Map<String, String> kafkaImages;
         private final Map<String, String> kafkaConnectImages;
-        private final Map<String, String> kafkaMirrorMakerImages;
         private final Map<String, String> kafkaMirrorMaker2Images;
 
         /**
@@ -90,23 +89,20 @@ public static class Lookup {
          *
          * @param kafkaImages               Map with container images for various Kafka versions to be used for Kafka brokers and ZooKeeper
          * @param kafkaConnectImages        Map with container images for various Kafka versions to be used for Kafka Connect
-         * @param kafkaMirrorMakerImages    Map with container images for various Kafka versions to be used for Kafka Mirror Maker
          * @param kafkaMirrorMaker2Images   Map with container images for various Kafka versions to be used for Kafka Mirror Maker 2
          */
         public Lookup(Map<String, String> kafkaImages,
                       Map<String, String> kafkaConnectImages,
-                      Map<String, String> kafkaMirrorMakerImages,
                       Map<String, String> kafkaMirrorMaker2Images) {
             this(new InputStreamReader(
                     KafkaVersion.class.getResourceAsStream("/" + KAFKA_VERSIONS_RESOURCE),
                     StandardCharsets.UTF_8),
-                    kafkaImages, kafkaConnectImages, kafkaMirrorMakerImages, kafkaMirrorMaker2Images);
+                    kafkaImages, kafkaConnectImages, kafkaMirrorMaker2Images);
         }
 
         protected Lookup(Reader reader,
                          Map<String, String> kafkaImages,
                          Map<String, String> kafkaConnectImages,
-                         Map<String, String> kafkaMirrorMakerImages,
                          Map<String, String> kafkaMirrorMaker2Images) {
             map = new HashMap<>();
             try {
@@ -116,7 +112,6 @@ protected Lookup(Reader reader,
             }
             this.kafkaImages = kafkaImages;
             this.kafkaConnectImages = kafkaConnectImages;
-            this.kafkaMirrorMakerImages = kafkaMirrorMakerImages;
             this.kafkaMirrorMaker2Images = kafkaMirrorMaker2Images;
         }
 
@@ -302,40 +297,12 @@ public void validateKafkaConnectImages(Set<String> versions) throws NoImageExcep
             validateImages(versions, kafkaConnectImages);
         }
 
-        /**
-         * The Kafka Connect image to use for a Kafka Mirror Maker cluster.
-         * @param image The image given in the CR.
-         * @param version The version given in the CR.
-         * @return The image to use.
-         * @throws InvalidResourceException If no image was given in the CR and the version given
-         * was not present in {@link ClusterOperatorConfig#STRIMZI_KAFKA_MIRROR_MAKER_IMAGES}.
-         */
-        public String kafkaMirrorMakerImage(String image, String version) {
-            try {
-                return image(image,
-                        version,
-                        kafkaMirrorMakerImages);
-            } catch (NoImageException e) {
-                throw asInvalidResourceException(version, e);
-            }
-        }
-
         InvalidResourceException asInvalidResourceException(String version, NoImageException e) {
             return new InvalidResourceException("Kafka version " + version + " is not supported. " +
                     "Supported versions are: " + String.join(", ", supportedVersions()) + ".",
                     e);
         }
 
-        /**
-         * Validate that the given versions have images present in {@link ClusterOperatorConfig#STRIMZI_KAFKA_MIRROR_MAKER_IMAGES}.
-         * @param versions The versions to validate.
-         * @throws NoImageException If one of the versions lacks an image.
-         * @throws UnsupportedVersionException If any version with configured image is not supported
-         */
-        public void validateKafkaMirrorMakerImages(Set<String> versions) throws NoImageException, UnsupportedVersionException {
-            validateImages(versions, kafkaMirrorMakerImages);
-        }
-
         /**
          * The Kafka MirrorMaker 2 image to use for a Kafka MirrorMaker 2 cluster.
          * @param image The image given in the CR.
@@ -379,7 +346,6 @@ public String toString() {
                         .append(" msg: ").append(version.messageVersion)
                         .append(" kafka-image: ").append(kafkaImages.get(v))
                         .append(" connect-image: ").append(kafkaConnectImages.get(v))
-                        .append(" mirrormaker-image: ").append(kafkaMirrorMakerImages.get(v))
                         .append(" mirrormaker2-image: ").append(kafkaMirrorMaker2Images.get(v))
                         .append("}");
 
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
deleted file mode 100644
index 2934b2aabf7..00000000000
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
+++ /dev/null
@@ -1,157 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.operator.cluster.operator.assembly;
-
-import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.ServiceAccount;
-import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.dsl.Resource;
-import io.strimzi.api.kafka.model.common.CertSecretSource;
-import io.strimzi.api.kafka.model.common.authentication.KafkaClientAuthentication;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerStatus;
-import io.strimzi.certs.CertManager;
-import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
-import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.model.SharedEnvironmentProvider;
-import io.strimzi.operator.cluster.operator.VertxUtil;
-import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.DeploymentOperator;
-import io.strimzi.operator.common.Annotations;
-import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.ReconciliationException;
-import io.strimzi.operator.common.ReconciliationLogger;
-import io.strimzi.operator.common.Util;
-import io.strimzi.operator.common.model.PasswordGenerator;
-import io.strimzi.operator.common.model.StatusUtils;
-import io.strimzi.operator.common.operator.resource.ReconcileResult;
-import io.vertx.core.Future;
-import io.vertx.core.Promise;
-import io.vertx.core.Vertx;
-
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
-/**
- * <p>Assembly operator for a "Kafka Mirror Maker" assembly, which manages:</p>
- * <ul>
- *     <li>A Kafka Mirror Maker Deployment and related Services</li>
- * </ul>
- */
-// Deprecation is suppressed because of KafkaMirrorMaker
-@SuppressWarnings("deprecation")
-public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>, KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> {
-
-    private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(KafkaMirrorMakerAssemblyOperator.class.getName());
-
-    private final DeploymentOperator deploymentOperations;
-    private final KafkaVersion.Lookup versions;
-    private final SharedEnvironmentProvider sharedEnvironmentProvider;
-
-    /**
-     * @param vertx The Vertx instance
-     * @param pfa Platform features availability properties
-     * @param certManager Certificate manager
-     * @param passwordGenerator Password generator
-     * @param supplier Supplies the operators for different resources
-     * @param config ClusterOperator configuration. Used to get the user-configured image pull policy and the secrets.
-     */
-    public KafkaMirrorMakerAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa,
-                                            CertManager certManager, PasswordGenerator passwordGenerator,
-                                            ResourceOperatorSupplier supplier,
-                                            ClusterOperatorConfig config) {
-        super(vertx, pfa, KafkaMirrorMaker.RESOURCE_KIND, certManager, passwordGenerator, supplier.mirrorMakerOperator, supplier, config);
-        this.deploymentOperations = supplier.deploymentOperations;
-        this.versions = config.versions();
-        this.sharedEnvironmentProvider = supplier.sharedEnvironmentProvider;
-    }
-
-    @Override
-    protected Future<KafkaMirrorMakerStatus> createOrUpdate(Reconciliation reconciliation, KafkaMirrorMaker assemblyResource) {
-        String namespace = reconciliation.namespace();
-        KafkaMirrorMakerCluster mirror;
-        KafkaMirrorMakerStatus kafkaMirrorMakerStatus = new KafkaMirrorMakerStatus();
-
-        try {
-            mirror = KafkaMirrorMakerCluster.fromCrd(reconciliation, assemblyResource, versions, sharedEnvironmentProvider);
-        } catch (Exception e) {
-            LOGGER.warnCr(reconciliation, e);
-            StatusUtils.setStatusConditionAndObservedGeneration(assemblyResource, kafkaMirrorMakerStatus, e);
-            return Future.failedFuture(new ReconciliationException(kafkaMirrorMakerStatus, e));
-        }
-
-        Map<String, String> annotations = new HashMap<>(1);
-
-        KafkaClientAuthentication authConsumer = assemblyResource.getSpec().getConsumer().getAuthentication();
-        List<CertSecretSource> trustedCertificatesConsumer = assemblyResource.getSpec().getConsumer().getTls() == null ? Collections.emptyList() : assemblyResource.getSpec().getConsumer().getTls().getTrustedCertificates();
-        KafkaClientAuthentication authProducer = assemblyResource.getSpec().getProducer().getAuthentication();
-        List<CertSecretSource> trustedCertificatesProducer = assemblyResource.getSpec().getProducer().getTls() == null ? Collections.emptyList() : assemblyResource.getSpec().getProducer().getTls().getTrustedCertificates();
-
-        Promise<KafkaMirrorMakerStatus> createOrUpdatePromise = Promise.promise();
-
-        boolean mirrorHasZeroReplicas = mirror.getReplicas() == 0;
-
-        LOGGER.debugCr(reconciliation, "Updating Kafka Mirror Maker cluster");
-        mirrorMakerServiceAccount(reconciliation, namespace, mirror)
-                .compose(i -> deploymentOperations.scaleDown(reconciliation, namespace, mirror.getComponentName(), mirror.getReplicas(), operationTimeoutMs))
-                .compose(i -> MetricsAndLoggingUtils.metricsAndLogging(reconciliation, configMapOperations, mirror.logging(), mirror.metrics()))
-                .compose(metricsAndLoggingCm -> {
-                    ConfigMap logAndMetricsConfigMap = mirror.generateMetricsAndLogConfigMap(metricsAndLoggingCm);
-                    annotations.put(Annotations.ANNO_STRIMZI_LOGGING_HASH, Util.hashStub(logAndMetricsConfigMap.getData().get(mirror.logging().configMapKey())));
-                    return configMapOperations.reconcile(reconciliation, namespace, KafkaMirrorMakerResources.metricsAndLogConfigMapName(reconciliation.name()), logAndMetricsConfigMap);
-                })
-                .compose(i -> podDisruptionBudgetOperator.reconcile(reconciliation, namespace, mirror.getComponentName(), mirror.generatePodDisruptionBudget()))
-                .compose(i -> Future.join(VertxUtil.authTlsHash(secretOperations, namespace, authConsumer, trustedCertificatesConsumer),
-                        VertxUtil.authTlsHash(secretOperations, namespace, authProducer, trustedCertificatesProducer)))
-                .compose(hashFut -> {
-                    if (hashFut != null) {
-                        annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, Integer.toString((int) hashFut.resultAt(0) + (int) hashFut.resultAt(1)));
-                    }
-                    return Future.succeededFuture();
-                })
-                .compose(i -> deploymentOperations.reconcile(reconciliation, namespace, mirror.getComponentName(), mirror.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
-                .compose(i -> deploymentOperations.scaleUp(reconciliation, namespace, mirror.getComponentName(), mirror.getReplicas(), operationTimeoutMs))
-                .compose(i -> deploymentOperations.waitForObserved(reconciliation, namespace, mirror.getComponentName(), 1_000, operationTimeoutMs))
-                .compose(i -> mirrorHasZeroReplicas ? Future.succeededFuture() : deploymentOperations.readiness(reconciliation, namespace, mirror.getComponentName(), 1_000, operationTimeoutMs))
-                .onComplete(reconciliationResult -> {
-                        StatusUtils.setStatusConditionAndObservedGeneration(assemblyResource, kafkaMirrorMakerStatus, reconciliationResult.cause());
-
-                        // Add warning about Mirror Maker 1 being deprecated and removed soon
-                        LOGGER.warnCr(reconciliation, "MirrorMaker 1 is deprecated and will be removed in the next Strimzi release (0.46.0). Please migrate to MirrorMaker 2.");
-                        StatusUtils.addConditionsToStatus(kafkaMirrorMakerStatus, Set.of(StatusUtils.buildWarningCondition("MirrorMaker1Deprecation", "MirrorMaker 1 is deprecated and will be removed in the next Strimzi release (0.46.0). Please migrate to MirrorMaker 2.")));
-
-                        kafkaMirrorMakerStatus.setReplicas(mirror.getReplicas());
-                        kafkaMirrorMakerStatus.setLabelSelector(mirror.getSelectorLabels().toSelectorString());
-
-                        if (reconciliationResult.succeeded())   {
-                            createOrUpdatePromise.complete(kafkaMirrorMakerStatus);
-                        } else {
-                            createOrUpdatePromise.fail(new ReconciliationException(kafkaMirrorMakerStatus, reconciliationResult.cause()));
-                        }
-                }
-            );
-
-        return createOrUpdatePromise.future();
-    }
-
-    @Override
-    protected KafkaMirrorMakerStatus createStatus(KafkaMirrorMaker ignored) {
-        return new KafkaMirrorMakerStatus();
-    }
-
-    Future<ReconcileResult<ServiceAccount>> mirrorMakerServiceAccount(Reconciliation reconciliation, String namespace, KafkaMirrorMakerCluster mirror) {
-        return serviceAccountOperations.reconcile(reconciliation, namespace,
-                KafkaMirrorMakerResources.serviceAccountName(mirror.getCluster()),
-                mirror.generateServiceAccount());
-    }
-}
diff --git a/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java b/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
index b7a0fa7a03e..b4fbdb11970 100644
--- a/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
+++ b/cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
@@ -14,8 +14,6 @@
 import io.strimzi.api.kafka.model.connector.KafkaConnectorList;
 import io.strimzi.api.kafka.model.kafka.Kafka;
 import io.strimzi.api.kafka.model.kafka.KafkaList;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2List;
 import io.strimzi.api.kafka.model.nodepool.KafkaNodePool;
@@ -58,8 +56,7 @@
 /**
  * Class holding the various resource operator and providers of various clients
  */
-// Deprecation is suppressed because of KafkaMirrorMaker
-@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling", "deprecation"})
+@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling"})
 public class ResourceOperatorSupplier {
     /**
      * Secret operator
@@ -131,11 +128,6 @@ public class ResourceOperatorSupplier {
      */
     public final CrdOperator<KubernetesClient, KafkaConnect, KafkaConnectList> connectOperator;
 
-    /**
-     * KafkaMirrorMaker CR operator
-     */
-    public final CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mirrorMakerOperator;
-
     /**
      * KafkaBridge CR operator
      */
@@ -348,7 +340,6 @@ private ResourceOperatorSupplier(Vertx vertx,
                 pfa.hasBuilds() ? new BuildOperator(vertx, client.adapt(OpenShiftClient.class)) : null,
                 new CrdOperator<>(vertx, client, Kafka.class, KafkaList.class, Kafka.RESOURCE_KIND),
                 new CrdOperator<>(vertx, client, KafkaConnect.class, KafkaConnectList.class, KafkaConnect.RESOURCE_KIND),
-                new CrdOperator<>(vertx, client, KafkaMirrorMaker.class, KafkaMirrorMakerList.class, KafkaMirrorMaker.RESOURCE_KIND),
                 new CrdOperator<>(vertx, client, KafkaBridge.class, KafkaBridgeList.class, KafkaBridge.RESOURCE_KIND),
                 new CrdOperator<>(vertx, client, KafkaConnector.class, KafkaConnectorList.class, KafkaConnector.RESOURCE_KIND),
                 new CrdOperator<>(vertx, client, KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, KafkaMirrorMaker2.RESOURCE_KIND),
@@ -391,7 +382,6 @@ private ResourceOperatorSupplier(Vertx vertx,
      * @param buildOperations                       Build operator
      * @param kafkaOperator                         Kafka CR operator
      * @param connectOperator                       KafkaConnect CR operator
-     * @param mirrorMakerOperator                   KafkaMirrorMaker CR operator
      * @param kafkaBridgeOperator                   KafkaBridge operator
      * @param kafkaConnectorOperator                KafkaConnector operator
      * @param mirrorMaker2Operator                  KafkaMirrorMaker2 operator
@@ -431,7 +421,6 @@ public ResourceOperatorSupplier(ServiceOperator serviceOperations,
                                     BuildOperator buildOperations,
                                     CrdOperator<KubernetesClient, Kafka, KafkaList> kafkaOperator,
                                     CrdOperator<KubernetesClient, KafkaConnect, KafkaConnectList> connectOperator,
-                                    CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mirrorMakerOperator,
                                     CrdOperator<KubernetesClient, KafkaBridge, KafkaBridgeList> kafkaBridgeOperator,
                                     CrdOperator<KubernetesClient, KafkaConnector, KafkaConnectorList> kafkaConnectorOperator,
                                     CrdOperator<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List> mirrorMaker2Operator,
@@ -469,7 +458,6 @@ public ResourceOperatorSupplier(ServiceOperator serviceOperations,
         this.buildConfigOperations = buildConfigOperations;
         this.buildOperations = buildOperations;
         this.connectOperator = connectOperator;
-        this.mirrorMakerOperator = mirrorMakerOperator;
         this.kafkaBridgeOperator = kafkaBridgeOperator;
         this.storageClassOperations = storageClassOperator;
         this.kafkaConnectorOperator = kafkaConnectorOperator;
diff --git a/cluster-operator/src/main/resources/default-logging/KafkaMirrorMakerCluster.properties b/cluster-operator/src/main/resources/default-logging/KafkaMirrorMakerCluster.properties
deleted file mode 100644
index 9de400b40fd..00000000000
--- a/cluster-operator/src/main/resources/default-logging/KafkaMirrorMakerCluster.properties
+++ /dev/null
@@ -1,5 +0,0 @@
-log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender
-log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout
-log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n
-mirrormaker.root.logger=INFO
-log4j.rootLogger=${mirrormaker.root.logger}, CONSOLE
\ No newline at end of file
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
index b50910235fe..24d6abc6fe5 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
@@ -41,7 +41,6 @@ public class ClusterOperatorConfigTest {
         ENV_VARS.put(ClusterOperatorConfig.CONNECT_BUILD_TIMEOUT_MS.key(), "40000");
         ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         ENV_VARS.put(ClusterOperatorConfig.OPERATOR_NAMESPACE.key(), "operator-namespace");
         ENV_VARS.put(ClusterOperatorConfig.FEATURE_GATES.key(), "-ContinueReconciliationOnManualRollingUpdateFailure");
@@ -131,7 +130,6 @@ private Map<String, String> envWithImages() {
         Map<String, String> envVars = new HashMap<>(5);
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         return envVars;
     }
@@ -275,7 +273,6 @@ public void testConfigParsingWithAllVersionEnvVars() {
         Map<String, String> envVars = new HashMap<>(5);
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 
         assertDoesNotThrow(() -> ClusterOperatorConfig.buildFromMap(envVars));
@@ -286,7 +283,6 @@ public void testConfigParsingWithMissingEnvVar() {
         Map<String, String> envVars = new HashMap<>(5);
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 
         for (Map.Entry<String, String> envVar : envVars.entrySet())    {
@@ -303,7 +299,6 @@ public void testConfigUnsupportedVersions() {
         Map<String, String> envVars = new HashMap<>(5);
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString() + " 2.6.0=myimage:2.6.0");
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 
         Throwable exception = assertThrows(InvalidConfigurationException.class, () -> ClusterOperatorConfig.buildFromMap(envVars));
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
index 999ebbe5d89..c607793ea53 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
@@ -62,7 +62,6 @@ private static Map<String, String> buildEnv(String namespaces, boolean podSetsOn
         env.put(ClusterOperatorConfig.FULL_RECONCILIATION_INTERVAL_MS.key(), "120000");
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 
         if (podSetsOnly) {
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/KafkaVersionTestUtils.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/KafkaVersionTestUtils.java
index 2e291f8f152..288687c81d6 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/KafkaVersionTestUtils.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/KafkaVersionTestUtils.java
@@ -16,10 +16,9 @@
 public class KafkaVersionTestUtils {
     private static final String KAFKA_IMAGE_STR = "strimzi/kafka:latest-kafka-";
     private static final String KAFKA_CONNECT_IMAGE_STR = "strimzi/kafka-connect:latest-kafka-";
-    private static final String KAFKA_MIRROR_MAKER_IMAGE_STR = "strimzi/kafka-mirror-maker:latest-kafka-";
     private static final String KAFKA_MIRROR_MAKER_2_IMAGE_STR = "strimzi/kafka-connect:latest-kafka-";
 
-    private static final Set<String> SUPPORTED_VERSIONS = new KafkaVersion.Lookup(Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap()).supportedVersions();
+    private static final Set<String> SUPPORTED_VERSIONS = new KafkaVersion.Lookup(Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap()).supportedVersions();
 
     public static final String LATEST_KAFKA_VERSION = "3.9.0";
     public static final String LATEST_FORMAT_VERSION = "3.9";
@@ -30,7 +29,6 @@ public class KafkaVersionTestUtils {
     public static final String LATEST_THIRD_PARTY_VERSION = "3.9.x";
     public static final String LATEST_KAFKA_IMAGE = KAFKA_IMAGE_STR + LATEST_KAFKA_VERSION;
     public static final String LATEST_KAFKA_CONNECT_IMAGE = KAFKA_CONNECT_IMAGE_STR + LATEST_KAFKA_VERSION;
-    public static final String LATEST_KAFKA_MIRROR_MAKER_IMAGE = KAFKA_MIRROR_MAKER_IMAGE_STR + LATEST_KAFKA_VERSION;
     public static final String LATEST_KAFKA_MIRROR_MAKER_2_IMAGE = KAFKA_MIRROR_MAKER_2_IMAGE_STR + LATEST_KAFKA_VERSION;
 
     public static final String PREVIOUS_KAFKA_VERSION = "3.8.0";
@@ -42,13 +40,11 @@ public class KafkaVersionTestUtils {
     public static final String PREVIOUS_THIRD_PARTY_VERSION = "3.8.x";
     public static final String PREVIOUS_KAFKA_IMAGE = KAFKA_IMAGE_STR + PREVIOUS_KAFKA_VERSION;
     public static final String PREVIOUS_KAFKA_CONNECT_IMAGE = KAFKA_CONNECT_IMAGE_STR + PREVIOUS_KAFKA_VERSION;
-    public static final String PREVIOUS_KAFKA_MIRROR_MAKER_IMAGE = KAFKA_MIRROR_MAKER_IMAGE_STR + PREVIOUS_KAFKA_VERSION;
     public static final String PREVIOUS_KAFKA_MIRROR_MAKER_2_IMAGE = KAFKA_MIRROR_MAKER_2_IMAGE_STR + PREVIOUS_KAFKA_VERSION;
 
     public static final String DEFAULT_KAFKA_VERSION = LATEST_KAFKA_VERSION;
     public static final String DEFAULT_KAFKA_IMAGE = LATEST_KAFKA_IMAGE;
     public static final String DEFAULT_KAFKA_CONNECT_IMAGE = LATEST_KAFKA_CONNECT_IMAGE;
-    public static final String DEFAULT_KAFKA_MIRROR_MAKER_IMAGE = LATEST_KAFKA_MIRROR_MAKER_IMAGE;
 
     public static final KafkaVersionChange DEFAULT_ZOOKEEPER_VERSION_CHANGE = new KafkaVersionChange(getKafkaVersionLookup().defaultVersion(), getKafkaVersionLookup().defaultVersion(), getKafkaVersionLookup().defaultVersion().protocolVersion(), getKafkaVersionLookup().defaultVersion().messageVersion(), null);
     public static final KafkaVersionChange DEFAULT_KRAFT_VERSION_CHANGE = new KafkaVersionChange(getKafkaVersionLookup().defaultVersion(), getKafkaVersionLookup().defaultVersion(), null, null, getKafkaVersionLookup().defaultVersion().metadataVersion());
@@ -61,10 +57,6 @@ private static Map<String, String> getKafkaConnectImageMap() {
         return getImageMap(KAFKA_CONNECT_IMAGE_STR);
     }
 
-    private static Map<String, String> getKafkaMirrorMakerImageMap() {
-        return getImageMap(KAFKA_MIRROR_MAKER_IMAGE_STR);
-    }
-
     private static Map<String, String> getKafkaMirrorMaker2ImageMap() {
         return getImageMap(KAFKA_MIRROR_MAKER_2_IMAGE_STR);
     }
@@ -81,10 +73,6 @@ public static String getKafkaConnectImagesEnvVarString() {
         return envVarFromMap(getKafkaConnectImageMap());
     }
 
-    public static String getKafkaMirrorMakerImagesEnvVarString() {
-        return envVarFromMap(getKafkaMirrorMakerImageMap());
-    }
-
     public static String getKafkaMirrorMaker2ImagesEnvVarString() {
         return envVarFromMap(getKafkaMirrorMaker2ImageMap());
     }
@@ -103,7 +91,6 @@ public static KafkaVersion.Lookup getKafkaVersionLookup() {
         return new KafkaVersion.Lookup(
                 getKafkaImageMap(),
                 getKafkaConnectImageMap(),
-                getKafkaMirrorMakerImageMap(),
                 getKafkaMirrorMaker2ImageMap());
     }
 
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
index d0ec62d0f7e..93831781137 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
@@ -32,10 +32,6 @@
 import io.strimzi.api.kafka.model.kafka.exporter.KafkaExporterSpec;
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2Builder;
 import io.strimzi.api.kafka.model.zookeeper.ZookeeperClusterSpec;
@@ -270,57 +266,6 @@ public static KafkaBridge createEmptyKafkaBridge(String namespace, String name)
                 .build();
     }
 
-    /**
-     * Create an empty Kafka MirrorMaker custom resource
-     */
-    @SuppressWarnings("deprecation")
-    public static KafkaMirrorMaker createEmptyKafkaMirrorMaker(String namespace, String name) {
-        return new KafkaMirrorMakerBuilder()
-                .withMetadata(new ObjectMetaBuilder()
-                        .withName(name)
-                        .withNamespace(namespace)
-                        .withLabels(Map.of(Labels.KUBERNETES_DOMAIN + "part-of", "tests",
-                                "my-user-label", "cromulent"))
-                        .build())
-                .withNewSpec()
-                .endSpec()
-                .build();
-    }
-
-    @SuppressWarnings("deprecation")
-    public static KafkaMirrorMaker createKafkaMirrorMaker(String namespace, String name, String image, KafkaMirrorMakerProducerSpec producer,
-                                                          KafkaMirrorMakerConsumerSpec consumer, String include) {
-        return createKafkaMirrorMaker(namespace, name, image, null, producer, consumer, include);
-    }
-
-    @SuppressWarnings("deprecation")
-    public static KafkaMirrorMaker createKafkaMirrorMaker(String namespace, String name, String image, Integer replicas,
-                                                          KafkaMirrorMakerProducerSpec producer, KafkaMirrorMakerConsumerSpec consumer,
-                                                          String include) {
-
-        KafkaMirrorMakerBuilder builder = new KafkaMirrorMakerBuilder()
-                .withMetadata(new ObjectMetaBuilder()
-                        .withName(name)
-                        .withNamespace(namespace)
-                        .withLabels(Map.of(Labels.KUBERNETES_DOMAIN + "part-of", "tests",
-                                "my-user-label", "cromulent"))
-                        .build())
-                .withNewSpec()
-                    .withImage(image)
-                    .withProducer(producer)
-                    .withConsumer(consumer)
-                    .withInclude(include)
-                .endSpec();
-
-        if (replicas != null) {
-            builder.editOrNewSpec()
-                        .withReplicas(replicas)
-                    .endSpec();
-        }
-
-        return builder.build();
-    }
-
     public static KafkaBridge createKafkaBridge(String namespace, String name, String image, int replicas, String bootstrapServers, KafkaBridgeProducerSpec producer, KafkaBridgeConsumerSpec consumer, KafkaBridgeHttpConfig http, boolean enableMetrics) {
         return new KafkaBridgeBuilder()
                 .withMetadata(new ObjectMetaBuilder()
@@ -609,7 +554,6 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(CrdOperator.class),
                 mock(CrdOperator.class),
                 mock(CrdOperator.class),
-                mock(CrdOperator.class),
                 mock(StrimziPodSetOperator.class),
                 mock(StorageClassOperator.class),
                 mock(NodeOperator.class),
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
index 32a289348be..f2353fcd937 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
@@ -266,34 +266,6 @@ public void testKafkaConnectHostnameVerification() {
         assertThat(configuration.asOrderedProperties().asMap().get("ssl.endpoint.identification.algorithm"), is(""));
     }
 
-    @ParallelTest
-    public void testKafkaMirrorMakerConsumerHostnameVerification() {
-        Map<String, Object> conf = new HashMap<>();
-        conf.put("compression.type", "zstd"); // valid
-        conf.put("ssl.endpoint.identification.algorithm", ""); // valid
-        conf.put("ssl.keystore.location", "/tmp/my.keystore"); // invalid
-
-        KafkaMirrorMakerConsumerConfiguration configuration = new KafkaMirrorMakerConsumerConfiguration(Reconciliation.DUMMY_RECONCILIATION, conf.entrySet());
-
-        assertThat(configuration.asOrderedProperties().asMap().get("compression.type"), is("zstd"));
-        assertThat(configuration.asOrderedProperties().asMap().get("ssl.keystore.location"), is(nullValue()));
-        assertThat(configuration.asOrderedProperties().asMap().get("ssl.endpoint.identification.algorithm"), is(""));
-    }
-
-    @ParallelTest
-    public void testKafkaMirrorMakerProducerHostnameVerification() {
-        Map<String, Object> conf = new HashMap<>();
-        conf.put("compression.type", "zstd"); // valid
-        conf.put("ssl.endpoint.identification.algorithm", ""); // valid
-        conf.put("ssl.keystore.location", "/tmp/my.keystore"); // invalid
-
-        KafkaMirrorMakerProducerConfiguration configuration = new KafkaMirrorMakerProducerConfiguration(Reconciliation.DUMMY_RECONCILIATION, conf.entrySet());
-
-        assertThat(configuration.asOrderedProperties().asMap().get("compression.type"), is("zstd"));
-        assertThat(configuration.asOrderedProperties().asMap().get("ssl.keystore.location"), is(nullValue()));
-        assertThat(configuration.asOrderedProperties().asMap().get("ssl.endpoint.identification.algorithm"), is(""));
-    }
-
     @ParallelTest
     public void testSplittingOfPrefixes()   {
         String prefixes = "prefix1.field,prefix2.field , prefix3.field, prefix4.field,, ";
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
deleted file mode 100644
index 1c26e2588d4..00000000000
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
+++ /dev/null
@@ -1,1776 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.operator.cluster.model;
-
-import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.ConfigMapKeySelectorBuilder;
-import io.fabric8.kubernetes.api.model.Container;
-import io.fabric8.kubernetes.api.model.EnvVar;
-import io.fabric8.kubernetes.api.model.EnvVarBuilder;
-import io.fabric8.kubernetes.api.model.HostAlias;
-import io.fabric8.kubernetes.api.model.HostAliasBuilder;
-import io.fabric8.kubernetes.api.model.IntOrString;
-import io.fabric8.kubernetes.api.model.LocalObjectReference;
-import io.fabric8.kubernetes.api.model.PodSecurityContextBuilder;
-import io.fabric8.kubernetes.api.model.Probe;
-import io.fabric8.kubernetes.api.model.Quantity;
-import io.fabric8.kubernetes.api.model.ResourceRequirementsBuilder;
-import io.fabric8.kubernetes.api.model.ServiceAccount;
-import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudget;
-import io.strimzi.api.kafka.model.common.CertSecretSource;
-import io.strimzi.api.kafka.model.common.CertSecretSourceBuilder;
-import io.strimzi.api.kafka.model.common.JvmOptions;
-import io.strimzi.api.kafka.model.common.authentication.KafkaClientAuthenticationOAuthBuilder;
-import io.strimzi.api.kafka.model.common.authentication.KafkaClientAuthenticationTlsBuilder;
-import io.strimzi.api.kafka.model.common.metrics.JmxPrometheusExporterMetrics;
-import io.strimzi.api.kafka.model.common.metrics.JmxPrometheusExporterMetricsBuilder;
-import io.strimzi.api.kafka.model.common.metrics.MetricsConfig;
-import io.strimzi.api.kafka.model.common.template.ContainerEnvVar;
-import io.strimzi.api.kafka.model.common.template.ContainerTemplate;
-import io.strimzi.api.kafka.model.common.template.DeploymentStrategy;
-import io.strimzi.api.kafka.model.common.tracing.OpenTelemetryTracing;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpecBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpecBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
-import io.strimzi.kafka.oauth.client.ClientConfig;
-import io.strimzi.kafka.oauth.server.ServerConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.ResourceUtils;
-import io.strimzi.operator.cluster.model.metrics.MetricsModel;
-import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.model.InvalidResourceException;
-import io.strimzi.operator.common.model.Labels;
-import io.strimzi.platform.KubernetesVersion;
-import io.strimzi.plugin.security.profiles.impl.RestrictedPodSecurityProvider;
-import io.strimzi.test.ReadWriteUtils;
-import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.ParallelSuite;
-import io.strimzi.test.annotations.ParallelTest;
-
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.TreeMap;
-
-import static io.strimzi.test.TestUtils.LINE_SEPARATOR;
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonList;
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.CoreMatchers.notNullValue;
-import static org.hamcrest.CoreMatchers.nullValue;
-import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.containsInAnyOrder;
-import static org.junit.jupiter.api.Assertions.assertThrows;
-
-@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling"})
-@ParallelSuite
-public class KafkaMirrorMakerClusterTest {
-    private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
-    private static final SharedEnvironmentProvider SHARED_ENV_PROVIDER = new MockSharedEnvironmentProvider();
-    
-    private final String namespace = "test";
-    private final String cluster = "mirror";
-    private final int replicas = 2;
-    private final String image = "my-image:latest";
-    private final String metricsCmJson = "{\"animal\":\"wombat\"}";
-    private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
-
-    private final String producerConfigurationJson = "foo: bar";
-    private final String consumerConfigurationJson = "foo: buz";
-    private final String defaultProducerConfiguration = "";
-    private final String defaultConsumerConfiguration = "";
-    private final String expectedProducerConfiguration = "foo=bar" + LINE_SEPARATOR;
-    private final String expectedConsumerConfiguration = "foo=buz" + LINE_SEPARATOR;
-    private final String producerBootstrapServers = "target-kafka:9092";
-    private final String consumerBootstrapServers = "source-kafka:9092";
-    private final String groupId = "my-group-id";
-    private final int numStreams = 2;
-    private final String include = ".*";
-    private final int offsetCommitInterval = 42000;
-    private final boolean abortOnSendFailure = false;
-    private final String kafkaHeapOpts = "-Xms" + JvmOptionUtils.DEFAULT_JVM_XMS;
-
-    private final KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-            .withBootstrapServers(producerBootstrapServers)
-            .withAbortOnSendFailure(abortOnSendFailure)
-            .withConfig((Map<String, Object>) ReadWriteUtils.readObjectFromYamlString(producerConfigurationJson, Map.class))
-            .build();
-
-    private final KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-            .withBootstrapServers(consumerBootstrapServers)
-            .withGroupId(groupId)
-            .withNumStreams(numStreams)
-            .withOffsetCommitInterval(offsetCommitInterval)
-            .withConfig((Map<String, Object>) ReadWriteUtils.readObjectFromYamlString(consumerConfigurationJson, Map.class))
-            .build();
-
-    private final KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMaker(namespace, cluster))
-            .withNewSpec()
-                .withImage(image)
-                .withReplicas(replicas)
-                .withProducer(producer)
-                .withConsumer(consumer)
-                .withInclude(include)
-            .endSpec()
-            .build();
-
-    private final KafkaMirrorMaker resourceWithMetrics = new KafkaMirrorMakerBuilder(resource)
-            .editSpec()
-                .withMetricsConfig(jmxMetricsConfig)
-            .endSpec()
-            .build();
-
-    private final KafkaMirrorMakerCluster mm = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resourceWithMetrics, VERSIONS, SHARED_ENV_PROVIDER);
-
-    @ParallelTest
-    public void testMetricsConfigMap() {
-        ConfigMap metricsCm = mm.generateMetricsAndLogConfigMap(new MetricsAndLogging(metricsCM, null));
-        checkMetricsConfigMap(metricsCm);
-    }
-
-    private void checkMetricsConfigMap(ConfigMap metricsCm) {
-        assertThat(metricsCm.getData().get(MetricsModel.CONFIG_MAP_KEY), is(metricsCmJson));
-    }
-
-    private Map<String, String> expectedLabels(String name)    {
-        return Map.of(Labels.STRIMZI_CLUSTER_LABEL, this.cluster,
-                "my-user-label", "cromulent",
-                Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND,
-                Labels.STRIMZI_NAME_LABEL, name,
-                Labels.STRIMZI_COMPONENT_TYPE_LABEL, KafkaMirrorMakerCluster.COMPONENT_TYPE,
-                Labels.KUBERNETES_NAME_LABEL, KafkaMirrorMakerCluster.COMPONENT_TYPE,
-                Labels.KUBERNETES_INSTANCE_LABEL, this.cluster,
-                Labels.KUBERNETES_PART_OF_LABEL, Labels.APPLICATION_NAME + "-" + this.cluster,
-                Labels.KUBERNETES_MANAGED_BY_LABEL, AbstractModel.STRIMZI_CLUSTER_OPERATOR_NAME);
-    }
-
-    private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
-    }
-
-    private Map<String, String> expectedLabels()    {
-        return expectedLabels(KafkaMirrorMakerResources.componentName(cluster));
-    }
-
-    protected List<EnvVar> getExpectedEnvVars() {
-        List<EnvVar> expected = new ArrayList<>();
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER).withValue(expectedConsumerConfiguration).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER).withValue(expectedProducerConfiguration).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_METRICS_ENABLED).withValue("true").build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER).withValue(consumerBootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_PRODUCER).withValue(producerBootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_INCLUDE).withValue(include).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_GROUPID_CONSUMER).withValue(groupId).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS).withValue(Integer.toString(numStreams)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL).withValue(Integer.toString(offsetCommitInterval)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE).withValue(Boolean.toString(abortOnSendFailure)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_LIVENESS_PERIOD).withValue("10").build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_READINESS_PERIOD).withValue("10").build());
-        return expected;
-    }
-
-    @ParallelTest
-    public void testDefaultValues() {
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMaker(namespace, cluster))
-                .withNewSpec()
-                    .withReplicas(replicas)
-                    .withProducer(producer)
-                    .withConsumer(consumer)
-                    .withInclude(".*")
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mm = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        assertThat(mm.image, is(KafkaVersionTestUtils.DEFAULT_KAFKA_MIRROR_MAKER_IMAGE));
-        assertThat(new KafkaMirrorMakerConsumerConfiguration(Reconciliation.DUMMY_RECONCILIATION, mm.consumer.getConfig().entrySet()).getConfiguration(), is(defaultConsumerConfiguration));
-        assertThat(new KafkaMirrorMakerProducerConfiguration(Reconciliation.DUMMY_RECONCILIATION, mm.producer.getConfig().entrySet()).getConfiguration(), is(defaultProducerConfiguration));
-    }
-
-    @ParallelTest
-    public void testFromCrd() {
-        assertThat(mm.getReplicas(), is(replicas));
-        assertThat(mm.getImage(), is(image));
-        assertThat(mm.consumer.getBootstrapServers(), is(consumerBootstrapServers));
-        assertThat(mm.producer.getBootstrapServers(), is(producerBootstrapServers));
-        assertThat(mm.getInclude(), is(include));
-        assertThat(mm.consumer.getGroupId(), is(groupId));
-    }
-
-    // Tests handling of the new include field and the deprecated whitelist field
-    @ParallelTest
-    public void testIncludeHandling() {
-        KafkaMirrorMaker both = new KafkaMirrorMakerBuilder(resource)
-                .editSpec()
-                    .withInclude(include)
-                    .withWhitelist("alternative.*")
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster cluster = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, both, VERSIONS, SHARED_ENV_PROVIDER);
-
-        assertThat(cluster.getInclude(), is(include));
-
-        KafkaMirrorMaker legacy = new KafkaMirrorMakerBuilder(resource)
-                .editSpec()
-                    .withWhitelist("alternative.*")
-                    .withInclude(null)
-                .endSpec()
-                .build();
-        cluster = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, legacy, VERSIONS, SHARED_ENV_PROVIDER);
-
-        assertThat(cluster.getInclude(), is("alternative.*"));
-
-        KafkaMirrorMaker none = new KafkaMirrorMakerBuilder(resource)
-                .editSpec()
-                    .withWhitelist(null)
-                    .withInclude(null)
-                .endSpec()
-                .build();
-
-        assertThrows(InvalidResourceException.class, () -> KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, none, VERSIONS, SHARED_ENV_PROVIDER));
-    }
-
-    @ParallelTest
-    public void testEnvVars()   {
-        assertThat(mm.getEnvVars(), is(getExpectedEnvVars()));
-    }
-
-    @ParallelTest
-    public void testGenerateDeployment()   {
-        Deployment dep = mm.generateDeployment(new HashMap<>(), true, null, null);
-
-        assertThat(dep.getMetadata().getName(), is(KafkaMirrorMakerResources.componentName(cluster)));
-        assertThat(dep.getMetadata().getNamespace(), is(namespace));
-        Map<String, String> expectedLabels = expectedLabels();
-        assertThat(dep.getMetadata().getLabels(), is(expectedLabels));
-        assertThat(dep.getSpec().getSelector().getMatchLabels(), is(expectedSelectorLabels()));
-        assertThat(dep.getSpec().getReplicas(), is(replicas));
-        assertThat(dep.getSpec().getTemplate().getMetadata().getLabels(), is(expectedLabels));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().size(), is(1));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getName(), is(KafkaMirrorMakerResources.componentName(this.cluster)));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImage(), is(mm.image));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv(), is(getExpectedEnvVars()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().size(), is(1));
-        assertThat(dep.getSpec().getStrategy().getType(), is("RollingUpdate"));
-        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxSurge().getIntVal(), is(1));
-        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxUnavailable().getIntVal(), is(0));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream()
-            .filter(volume -> volume.getName().equalsIgnoreCase("strimzi-tmp"))
-            .findFirst().get().getEmptyDir().getSizeLimit(), is(new Quantity(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_SIZE)));
-
-        TestUtils.checkOwnerReference(dep, resource);
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithTls() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editOrNewConsumer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-c").withCertificate("cert.crt").build())
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-c").withCertificate("new-cert.crt").build())
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-another-secret-c").withCertificate("another-cert.crt").build())
-                .endTls()
-                .endConsumer()
-                .editOrNewProducer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-p").withCertificate("cert.crt").build())
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-p").withCertificate("new-cert.crt").build())
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-another-secret-p").withCertificate("another-cert.crt").build())
-                .endTls()
-                .endProducer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(2).getName(), is("my-secret-p"));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("my-another-secret-p"));
-
-        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
-
-        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_PRODUCER + "my-secret-p"));
-        assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_PRODUCER + "my-another-secret-p"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_PRODUCER), is("true"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER),
-                is("my-secret-p/cert.crt;my-secret-p/new-cert.crt;my-another-secret-p/another-cert.crt"));
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(4).getName(), is("my-secret-c"));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(5).getName(), is("my-another-secret-c"));
-
-        assertThat(containers.get(0).getVolumeMounts().get(4).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_CONSUMER + "my-secret-c"));
-        assertThat(containers.get(0).getVolumeMounts().get(5).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_CONSUMER + "my-another-secret-c"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_CONSUMER), is("true"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER),
-                is("my-secret-c/cert.crt;my-secret-c/new-cert.crt;my-another-secret-c/another-cert.crt"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithTlsAuth() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editOrNewConsumer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-c").withCertificate("cert.crt").build())
-                .endTls()
-                .withAuthentication(
-                        new KafkaClientAuthenticationTlsBuilder()
-                                .withNewCertificateAndKey()
-                                .withSecretName("user-secret-c")
-                                .withCertificate("user.crt")
-                                .withKey("user.key")
-                                .endCertificateAndKey()
-                                .build())
-                .endConsumer()
-                .editOrNewProducer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-p").withCertificate("cert.crt").build())
-                .endTls()
-                .withAuthentication(
-                        new KafkaClientAuthenticationTlsBuilder()
-                                .withNewCertificateAndKey()
-                                .withSecretName("user-secret-p")
-                                .withCertificate("user.crt")
-                                .withKey("user.key")
-                                .endCertificateAndKey()
-                                .build())
-                .endProducer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(5).getName(), is("user-secret-c"));
-
-        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
-
-        assertThat(containers.get(0).getVolumeMounts().get(5).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_CONSUMER + "user-secret-c"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_CERT_CONSUMER), is("user-secret-c/user.crt"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_KEY_CONSUMER), is("user-secret-c/user.key"));
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("user-secret-p"));
-
-        assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(KafkaMirrorMakerCluster.TLS_CERTS_VOLUME_MOUNT_PRODUCER + "user-secret-p"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_CERT_PRODUCER), is("user-secret-p/user.crt"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_TLS_AUTH_KEY_PRODUCER), is("user-secret-p/user.key"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithTlsSameSecret() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editOrNewConsumer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-c").withCertificate("cert.crt").build())
-                .endTls()
-                .withAuthentication(
-                        new KafkaClientAuthenticationTlsBuilder()
-                                .withNewCertificateAndKey()
-                                .withSecretName("my-secret-c")
-                                .withCertificate("user.crt")
-                                .withKey("user.key")
-                                .endCertificateAndKey()
-                                .build())
-                .endConsumer()
-                .editOrNewProducer()
-                .editOrNewTls()
-                .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName("my-secret-p").withCertificate("cert.crt").build())
-                .endTls()
-                .withAuthentication(
-                        new KafkaClientAuthenticationTlsBuilder()
-                                .withNewCertificateAndKey()
-                                .withSecretName("my-secret-p")
-                                .withCertificate("user.crt")
-                                .withKey("user.key")
-                                .endCertificateAndKey()
-                                .build())
-                .endProducer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().size(), is(4));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(0).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(2).getName(), is("my-secret-p"));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("my-secret-c"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithScramSha512Auth() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editOrNewProducer()
-                    .withNewKafkaClientAuthenticationScramSha512()
-                        .withUsername("producer")
-                        .withNewPasswordSecret()
-                            .withSecretName("producer-secret")
-                            .withPassword("password")
-                        .endPasswordSecret()
-                    .endKafkaClientAuthenticationScramSha512()
-                .endProducer()
-                .editOrNewConsumer()
-                    .withNewKafkaClientAuthenticationScramSha512()
-                        .withUsername("consumer")
-                        .withNewPasswordSecret()
-                            .withSecretName("consumer-secret")
-                            .withPassword("password")
-                        .endPasswordSecret()
-                    .endKafkaClientAuthenticationScramSha512()
-                .endConsumer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(2).getName(), is("producer-secret"));
-
-        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
-
-        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_PRODUCER + "producer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER), is("scram-sha-512"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER), is("producer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER), is("producer"));
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("consumer-secret"));
-
-
-        assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_CONSUMER + "consumer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER), is("scram-sha-512"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER), is("consumer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER), is("consumer"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithScramSha256Auth() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editOrNewProducer()
-                .withNewKafkaClientAuthenticationScramSha256()
-                .withUsername("producer")
-                .withNewPasswordSecret()
-                .withSecretName("producer-secret")
-                .withPassword("password")
-                .endPasswordSecret()
-                .endKafkaClientAuthenticationScramSha256()
-                .endProducer()
-                .editOrNewConsumer()
-                .withNewKafkaClientAuthenticationScramSha256()
-                .withUsername("consumer")
-                .withNewPasswordSecret()
-                .withSecretName("consumer-secret")
-                .withPassword("password")
-                .endPasswordSecret()
-                .endKafkaClientAuthenticationScramSha256()
-                .endConsumer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(2).getName(), is("producer-secret"));
-
-        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
-
-        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_PRODUCER + "producer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER), is("scram-sha-256"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER), is("producer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER), is("producer"));
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("consumer-secret"));
-
-
-        assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_CONSUMER + "consumer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER), is("scram-sha-256"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER), is("consumer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER), is("consumer"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithPlain() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editOrNewProducer()
-                        .withNewKafkaClientAuthenticationPlain()
-                            .withUsername("producer")
-                            .withNewPasswordSecret()
-                                .withSecretName("producer-secret")
-                                .withPassword("password")
-                            .endPasswordSecret()
-                        .endKafkaClientAuthenticationPlain()
-                    .endProducer()
-                    .editOrNewConsumer()
-                        .withNewKafkaClientAuthenticationPlain()
-                            .withUsername("consumer")
-                            .withNewPasswordSecret()
-                                .withSecretName("consumer-secret")
-                                .withPassword("password")
-                            .endPasswordSecret()
-                        .endKafkaClientAuthenticationPlain()
-                    .endConsumer()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(2).getName(), is("producer-secret"));
-
-        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
-
-        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_PRODUCER + "producer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER), is("plain"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER), is("producer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER), is("producer"));
-
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(3).getName(), is("consumer-secret"));
-
-
-        assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(KafkaMirrorMakerCluster.PASSWORD_VOLUME_MOUNT_CONSUMER + "consumer-secret"));
-
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER), is("plain"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER), is("consumer-secret/password"));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER), is("consumer"));
-    }
-
-    @ParallelTest
-    public void testTemplate() {
-        Map<String, String> depLabels = Map.of("l1", "v1", "l2", "v2",
-                Labels.KUBERNETES_PART_OF_LABEL, "custom-part",
-                Labels.KUBERNETES_MANAGED_BY_LABEL, "custom-managed-by");
-        Map<String, String> expectedDepLabels = new HashMap<>(depLabels);
-        expectedDepLabels.remove(Labels.KUBERNETES_MANAGED_BY_LABEL);
-        Map<String, String> depAnots = Map.of("a1", "v1", "a2", "v2");
-
-        Map<String, String> podLabels = Map.of("l3", "v3", "l4", "v4");
-        Map<String, String> podAnots = Map.of("a3", "v3", "a4", "v4");
-
-        Map<String, String> pdbLabels = Map.of("l5", "v5", "l6", "v6");
-        Map<String, String> pdbAnots = Map.of("a5", "v5", "a6", "v6");
-
-        Map<String, String> saLabels = Map.of("l7", "v7", "l8", "v8");
-        Map<String, String> saAnots = Map.of("a7", "v7", "a8", "v8");
-
-        HostAlias hostAlias1 = new HostAliasBuilder()
-                .withHostnames("my-host-1", "my-host-2")
-                .withIp("192.168.1.86")
-                .build();
-        HostAlias hostAlias2 = new HostAliasBuilder()
-                .withHostnames("my-host-3")
-                .withIp("192.168.1.87")
-                .build();
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewDeployment()
-                            .withNewMetadata()
-                                .withLabels(depLabels)
-                                .withAnnotations(depAnots)
-                            .endMetadata()
-                            .withDeploymentStrategy(DeploymentStrategy.RECREATE)
-                        .endDeployment()
-                        .withNewPod()
-                            .withNewMetadata()
-                                .withLabels(podLabels)
-                                .withAnnotations(podAnots)
-                            .endMetadata()
-                            .withPriorityClassName("top-priority")
-                            .withSchedulerName("my-scheduler")
-                            .withHostAliases(hostAlias1, hostAlias2)
-                            .withEnableServiceLinks(false)
-                            .withTmpDirSizeLimit("10Mi")
-                        .endPod()
-                        .withNewPodDisruptionBudget()
-                            .withNewMetadata()
-                                .withLabels(pdbLabels)
-                                .withAnnotations(pdbAnots)
-                            .endMetadata()
-                        .endPodDisruptionBudget()
-                        .withNewServiceAccount()
-                            .withNewMetadata()
-                                .withLabels(saLabels)
-                                .withAnnotations(saAnots)
-                            .endMetadata()
-                        .endServiceAccount()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        // Check Deployment
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getMetadata().getLabels().entrySet().containsAll(expectedDepLabels.entrySet()), is(true));
-        assertThat(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getPriorityClassName(), is("top-priority"));
-        assertThat(dep.getSpec().getStrategy().getType(), is("Recreate"));
-        assertThat(dep.getSpec().getStrategy().getRollingUpdate(), is(nullValue()));
-
-        // Check Pods
-        assertThat(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()), is(true));
-        assertThat(dep.getSpec().getTemplate().getMetadata().getAnnotations().entrySet().containsAll(podAnots.entrySet()), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getSchedulerName(), is("my-scheduler"));
-        assertThat(dep.getSpec().getTemplate().getSpec().getHostAliases(), containsInAnyOrder(hostAlias1, hostAlias2));
-        assertThat(dep.getSpec().getTemplate().getSpec().getEnableServiceLinks(), is(false));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream()
-            .filter(volume -> volume.getName().equalsIgnoreCase("strimzi-tmp"))
-            .findFirst().get().getEmptyDir().getSizeLimit(), is(new Quantity("10Mi")));
-
-        // Check PodDisruptionBudget
-        PodDisruptionBudget pdb = mmc.generatePodDisruptionBudget();
-        assertThat(pdb.getMetadata().getLabels().entrySet().containsAll(pdbLabels.entrySet()), is(true));
-        assertThat(pdb.getMetadata().getAnnotations().entrySet().containsAll(pdbAnots.entrySet()), is(true));
-
-        // Check Service Account
-        ServiceAccount sa = mmc.generateServiceAccount();
-        assertThat(sa.getMetadata().getLabels().entrySet().containsAll(saLabels.entrySet()), is(true));
-        assertThat(sa.getMetadata().getAnnotations().entrySet().containsAll(saAnots.entrySet()), is(true));
-    }
-
-    @ParallelTest
-    public void testGracePeriod() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewPod()
-                            .withTerminationGracePeriodSeconds(123)
-                        .endPod()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getTerminationGracePeriodSeconds(), is(123L));
-    }
-
-    @ParallelTest
-    public void testDefaultGracePeriod() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource).build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getTerminationGracePeriodSeconds(), is(30L));
-    }
-
-    @ParallelTest
-    public void testImagePullSecrets() {
-        LocalObjectReference secret1 = new LocalObjectReference("some-pull-secret");
-        LocalObjectReference secret2 = new LocalObjectReference("some-other-pull-secret");
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewPod()
-                            .withImagePullSecrets(secret1, secret2)
-                        .endPod()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(2));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret1), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret2), is(true));
-    }
-
-    @ParallelTest
-    public void testImagePullSecretsFromCo() {
-        LocalObjectReference secret1 = new LocalObjectReference("some-pull-secret");
-        LocalObjectReference secret2 = new LocalObjectReference("some-other-pull-secret");
-
-        List<LocalObjectReference> secrets = new ArrayList<>(2);
-        secrets.add(secret1);
-        secrets.add(secret2);
-
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, this.resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, secrets);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(2));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret1), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret2), is(true));
-    }
-
-    @ParallelTest
-    public void testImagePullSecretsFromBoth() {
-        LocalObjectReference secret1 = new LocalObjectReference("some-pull-secret");
-        LocalObjectReference secret2 = new LocalObjectReference("some-other-pull-secret");
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewPod()
-                            .withImagePullSecrets(secret2)
-                        .endPod()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, singletonList(secret1));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(1));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret1), is(false));
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().contains(secret2), is(true));
-    }
-
-    @ParallelTest
-    public void testDefaultImagePullSecrets() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource).build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
-    }
-
-    @ParallelTest
-    public void testSecurityContext() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewPod()
-                            .withSecurityContext(new PodSecurityContextBuilder().withFsGroup(123L).withRunAsGroup(456L).withRunAsUser(789L).build())
-                        .endPod()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext(), is(notNullValue()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext().getFsGroup(), is(123L));
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext().getRunAsGroup(), is(456L));
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext().getRunAsUser(), is(789L));
-    }
-
-    @ParallelTest
-    public void testDefaultSecurityContext() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource).build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext(), is(nullValue()));
-    }
-
-    @ParallelTest
-    public void testRestrictedSecurityContext() {
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        mmc.securityProvider = new RestrictedPodSecurityProvider();
-        mmc.securityProvider.configure(new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION));
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getSecurityContext(), is(nullValue()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getSecurityContext().getAllowPrivilegeEscalation(), is(false));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getSecurityContext().getRunAsNonRoot(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getSecurityContext().getSeccompProfile().getType(), is("RuntimeDefault"));
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getSecurityContext().getCapabilities().getDrop(), is(List.of("ALL")));
-    }
-
-    @ParallelTest
-    public void testPodDisruptionBudget() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withNewPodDisruptionBudget()
-                            .withMaxUnavailable(2)
-                        .endPodDisruptionBudget()
-                    .endTemplate()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        PodDisruptionBudget pdb = mmc.generatePodDisruptionBudget();
-        assertThat(pdb.getSpec().getMaxUnavailable(), is(new IntOrString(2)));
-    }
-
-    @ParallelTest
-    public void testDefaultPodDisruptionBudget() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource).build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        PodDisruptionBudget pdb = mmc.generatePodDisruptionBudget();
-        assertThat(pdb.getSpec().getMaxUnavailable(), is(new IntOrString(1)));
-    }
-
-    @ParallelTest
-    public void testImagePullPolicy() {
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = kc.generateDeployment(Collections.emptyMap(), true, ImagePullPolicy.ALWAYS, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImagePullPolicy(), is(ImagePullPolicy.ALWAYS.toString()));
-
-        dep = kc.generateDeployment(Collections.emptyMap(), true, ImagePullPolicy.IFNOTPRESENT, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImagePullPolicy(), is(ImagePullPolicy.IFNOTPRESENT.toString()));
-    }
-
-    @ParallelTest
-    public void testResources() {
-        Map<String, Quantity> requests = new HashMap<>(2);
-        requests.put("cpu", new Quantity("250m"));
-        requests.put("memory", new Quantity("512Mi"));
-
-        Map<String, Quantity> limits = new HashMap<>(2);
-        limits.put("cpu", new Quantity("500m"));
-        limits.put("memory", new Quantity("1024Mi"));
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withResources(new ResourceRequirementsBuilder().withLimits(limits).withRequests(requests).build())
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getResources().getLimits(), is(limits));
-        assertThat(cont.getResources().getRequests(), is(requests));
-    }
-
-    @ParallelTest
-    public void testJvmOptions() {
-        Map<String, String> xx = new HashMap<>(2);
-        xx.put("UseG1GC", "true");
-        xx.put("MaxGCPauseMillis", "20");
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewJvmOptions()
-                        .withXms("512m")
-                        .withXmx("1024m")
-                        .withXx(xx)
-                    .endJvmOptions()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(Collections.emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:MaxGCPauseMillis=20"), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xmx1024m"), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xms512m"), is(true));
-    }
-
-    @ParallelTest
-    public void testDefaultProbes() {
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, this.resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(Collections.emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        Probe livenessProbe = cont.getLivenessProbe();
-        Probe readinessProbe = cont.getReadinessProbe();
-
-        assertThat(livenessProbe.getExec().getCommand().get(0), is("/opt/kafka/kafka_mirror_maker_liveness.sh"));
-        assertThat(livenessProbe.getInitialDelaySeconds(), is(60));
-        assertThat(livenessProbe.getTimeoutSeconds(), is(5));
-
-        assertThat(readinessProbe.getExec().getCommand().size(), is(3));
-        assertThat(readinessProbe.getExec().getCommand().get(0), is("test"));
-        assertThat(readinessProbe.getExec().getCommand().get(1), is("-f"));
-        assertThat(readinessProbe.getExec().getCommand().get(2), is("/tmp/mirror-maker-ready"));
-        assertThat(readinessProbe.getInitialDelaySeconds(), is(60));
-        assertThat(readinessProbe.getTimeoutSeconds(), is(5));
-
-        assertThat(cont.getEnv().stream().filter(env -> "STRIMZI_READINESS_PERIOD".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").equals("10"), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> "STRIMZI_LIVENESS_PERIOD".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").equals("10"), is(true));
-    }
-
-    @ParallelTest
-    public void testConfiguredProbes() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewLivenessProbe()
-                        .withInitialDelaySeconds(120)
-                        .withTimeoutSeconds(10)
-                        .withPeriodSeconds(60)
-                    .endLivenessProbe()
-                    .withNewReadinessProbe()
-                        .withInitialDelaySeconds(121)
-                        .withTimeoutSeconds(11)
-                        .withPeriodSeconds(61)
-                    .endReadinessProbe()
-                .endSpec()
-                .build();
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(Collections.emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        Probe livenessProbe = cont.getLivenessProbe();
-        Probe readinessProbe = cont.getReadinessProbe();
-
-        assertThat(livenessProbe.getExec().getCommand().get(0), is("/opt/kafka/kafka_mirror_maker_liveness.sh"));
-        assertThat(livenessProbe.getInitialDelaySeconds(), is(120));
-        assertThat(livenessProbe.getTimeoutSeconds(), is(10));
-        assertThat(livenessProbe.getPeriodSeconds(), is(60));
-
-        assertThat(readinessProbe.getExec().getCommand().size(), is(3));
-        assertThat(readinessProbe.getExec().getCommand().get(0), is("test"));
-        assertThat(readinessProbe.getExec().getCommand().get(1), is("-f"));
-        assertThat(readinessProbe.getExec().getCommand().get(2), is("/tmp/mirror-maker-ready"));
-        assertThat(readinessProbe.getInitialDelaySeconds(), is(121));
-        assertThat(readinessProbe.getTimeoutSeconds(), is(11));
-        assertThat(readinessProbe.getPeriodSeconds(), is(61));
-
-        assertThat(cont.getEnv().stream().filter(env -> "STRIMZI_READINESS_PERIOD".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").equals("61"), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> "STRIMZI_LIVENESS_PERIOD".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").equals("60"), is(true));
-    }
-
-    @ParallelTest
-    public void testKafkaMMContainerEnvVars() {
-        ContainerEnvVar envVar1 = new ContainerEnvVar();
-        String testEnvOneKey = "TEST_ENV_1";
-        String testEnvOneValue = "test.env.one";
-        envVar1.setName(testEnvOneKey);
-        envVar1.setValue(testEnvOneValue);
-
-        ContainerEnvVar envVar2 = new ContainerEnvVar();
-        String testEnvTwoKey = "TEST_ENV_2";
-        String testEnvTwoValue = "test.env.two";
-        envVar2.setName(testEnvTwoKey);
-        envVar2.setValue(testEnvTwoValue);
-
-        List<ContainerEnvVar> testEnvs = new ArrayList<>();
-        testEnvs.add(envVar1);
-        testEnvs.add(envVar2);
-        ContainerTemplate kafkaMMContainer = new ContainerTemplate();
-        kafkaMMContainer.setEnv(testEnvs);
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewTemplate()
-                        .withMirrorMakerContainer(kafkaMMContainer)
-                    .endTemplate()
-                .endSpec()
-                .build();
-
-        List<EnvVar> kafkaEnvVars = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER).getEnvVars();
-
-        assertThat("Failed to correctly set container environment variable: " + testEnvOneKey,
-                kafkaEnvVars.stream().filter(env -> testEnvOneKey.equals(env.getName()))
-                        .map(EnvVar::getValue).findFirst().orElse("").equals(testEnvOneValue), is(true));
-        assertThat("Failed to correctly set container environment variable: " + testEnvTwoKey,
-                kafkaEnvVars.stream().filter(env -> testEnvTwoKey.equals(env.getName()))
-                        .map(EnvVar::getValue).findFirst().orElse("").equals(testEnvTwoValue), is(true));
-    }
-
-    @ParallelTest
-    public void testKafkaMMContainerEnvVarsConflict() {
-        ContainerEnvVar envVar1 = new ContainerEnvVar();
-        String testEnvOneKey = KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER;
-        String testEnvOneValue = "test.env.one";
-        envVar1.setName(testEnvOneKey);
-        envVar1.setValue(testEnvOneValue);
-
-        ContainerEnvVar envVar2 = new ContainerEnvVar();
-        String testEnvTwoKey = KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_INCLUDE;
-        String testEnvTwoValue = "test.env.two";
-        envVar2.setName(testEnvTwoKey);
-        envVar2.setValue(testEnvTwoValue);
-
-        List<ContainerEnvVar> testEnvs = new ArrayList<>();
-        testEnvs.add(envVar1);
-        testEnvs.add(envVar2);
-        ContainerTemplate kafkaMMContainer = new ContainerTemplate();
-        kafkaMMContainer.setEnv(testEnvs);
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .withNewTemplate()
-                .withMirrorMakerContainer(kafkaMMContainer)
-                .endTemplate()
-                .endSpec()
-                .build();
-
-        List<EnvVar> kafkaEnvVars = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER).getEnvVars();
-
-        assertThat("Failed to prevent over writing existing container environment variable: " + testEnvOneKey,
-                kafkaEnvVars.stream().filter(env -> testEnvOneKey.equals(env.getName()))
-                        .map(EnvVar::getValue).findFirst().orElse("").equals(testEnvOneValue), is(false));
-        assertThat("Failed to prevent over writing existing container environment variable: " + testEnvTwoKey,
-                kafkaEnvVars.stream().filter(env -> testEnvTwoKey.equals(env.getName()))
-                        .map(EnvVar::getValue).findFirst().orElse("").equals(testEnvTwoValue), is(false));
-    }
-
-    @ParallelTest
-    public void testOpenTelemetryTracing() {
-        KafkaMirrorMakerBuilder builder = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withNewOpenTelemetryTracing()
-                    .endOpenTelemetryTracing()
-                .endSpec();
-        KafkaMirrorMaker resource = builder.build();
-
-        KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Deployment dep = mmc.generateDeployment(Collections.emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getEnv().stream().filter(env -> KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_TRACING.equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").equals(OpenTelemetryTracing.TYPE_OPENTELEMETRY), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER.equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("interceptor.classes=" + OpenTelemetryTracing.CONSUMER_INTERCEPTOR_CLASS_NAME), is(true));
-        assertThat(cont.getEnv().stream().filter(env -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER.equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("interceptor.classes=" + OpenTelemetryTracing.PRODUCER_INTERCEPTOR_CLASS_NAME), is(true));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithAccessToken() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withNewAccessToken()
-                                            .withSecretName("my-token-secret")
-                                            .withKey("my-token-key")
-                                        .endAccessToken()
-                                        .build())
-                        .endConsumer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-token-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-token-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().isEmpty(), is(true));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithRefreshToken() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewRefreshToken()
-                                            .withSecretName("my-token-secret")
-                                            .withKey("my-token-key")
-                                        .endRefreshToken()
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-token-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-token-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithClientSecret() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                        .withSecretName("my-secret-secret")
-                                        .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithClientAssertion() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientAssertion()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientAssertion()
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithUsernameAndPassword() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editConsumer()
-                .withAuthentication(
-                        new KafkaClientAuthenticationOAuthBuilder()
-                                .withClientId("my-client-id")
-                                .withTokenEndpointUri("http://my-oauth-server")
-                                .withUsername("user1")
-                                .withNewPasswordSecret()
-                                .withSecretName("my-password-secret")
-                                .withPassword("user1.password")
-                                .endPasswordSecret()
-                                .withNewClientSecret()
-                                .withSecretName("my-secret-secret")
-                                .withKey("my-secret-key")
-                                .endClientSecret()
-                                .build())
-                .endConsumer()
-                .endSpec()
-                .build();
-
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(
-                emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-password-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("user1.password"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_PASSWORD_GRANT_USERNAME, "user1", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithMissingClientSecret() {
-        assertThrows(InvalidResourceException.class, () -> {
-            KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-            KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        });
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithMissingUri() {
-        assertThrows(InvalidResourceException.class, () -> {
-            KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withNewClientSecret()
-                                        .withSecretName("my-secret-secret")
-                                        .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-            KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        });
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithConsumerOAuthWithTls() {
-        CertSecretSource cert1 = new CertSecretSourceBuilder()
-                .withSecretName("first-certificate")
-                .withCertificate("ca.crt")
-                .build();
-
-        CertSecretSource cert2 = new CertSecretSourceBuilder()
-                .withSecretName("second-certificate")
-                .withCertificate("tls.crt")
-                .build();
-
-        CertSecretSource cert3 = new CertSecretSourceBuilder()
-                .withSecretName("first-certificate")
-                .withCertificate("ca2.crt")
-                .build();
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                        .withSecretName("my-secret-secret")
-                                        .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .withDisableTlsHostnameVerification(true)
-                                        .withTlsTrustedCertificates(cert1, cert2, cert3)
-                                        .build())
-                    .endConsumer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, "")));
-
-        // Volume mounts
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-first-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER + "first-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-second-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER + "second-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-third-certificate".equals(mount.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-fourth-certificate".equals(mount.getName())).findFirst().orElse(null), is(nullValue()));
-
-        // Volumes
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-first-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-second-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-third-certificate".equals(vol.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-fourth-certificate".equals(vol.getName())).findFirst().orElse(null), is(nullValue()));
-
-        // Environment variable
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_CONSUMER".equals(e.getName())).findFirst().orElseThrow().getValue(), is("first-certificate/ca.crt;second-certificate/tls.crt;first-certificate/ca2.crt"));
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_PRODUCER".equals(e.getName())).findFirst().orElse(null), is(nullValue()));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithAccessToken() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withNewAccessToken()
-                                            .withSecretName("my-token-secret")
-                                            .withKey("my-token-key")
-                                        .endAccessToken()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-token-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-token-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().isEmpty(), is(true));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithAccessTokenLocation() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editProducer()
-                .withAuthentication(
-                        new KafkaClientAuthenticationOAuthBuilder()
-                                .withAccessTokenLocation("/var/run/secrets/kubernetes.io/serviceaccount/token")
-                                .build())
-                .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\"", ClientConfig.OAUTH_ACCESS_TOKEN_LOCATION, "/var/run/secrets/kubernetes.io/serviceaccount/token")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithRefreshToken() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewRefreshToken()
-                                            .withSecretName("my-token-secret")
-                                            .withKey("my-token-key")
-                                        .endRefreshToken()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-token-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-token-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithClientSecret() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithClientSecretAndSaslExtensions() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editProducer()
-                .withAuthentication(
-                        new KafkaClientAuthenticationOAuthBuilder()
-                                .withClientId("my-client-id")
-                                .withTokenEndpointUri("http://my-oauth-server")
-                                .withNewClientSecret()
-                                    .withSecretName("my-secret-secret")
-                                    .withKey("my-secret-key")
-                                .endClientSecret()
-                                .withSaslExtensions(new TreeMap(Map.of("key1", "value1", "key2", "value2")))
-                                .build())
-                .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server",
-                        ClientConfig.OAUTH_SASL_EXTENSION_PREFIX + "key1", "value1", ClientConfig.OAUTH_SASL_EXTENSION_PREFIX + "key2", "value2")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithClientAssertion() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientAssertion()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientAssertion()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithUsernameAndPassword() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withUsername("user1")
-                                        .withNewPasswordSecret()
-                                        .withSecretName("my-password-secret")
-                                        .withPassword("user1.password")
-                                        .endPasswordSecret()
-                                        .withNewClientSecret()
-                                        .withSecretName("my-secret-secret")
-                                        .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(
-                emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-password-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("user1.password"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_PASSWORD_GRANT_USERNAME, "user1", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithMissingClientSecret() {
-        assertThrows(InvalidResourceException.class, () -> {
-            KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-            KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        });
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithMissingUri() {
-        assertThrows(InvalidResourceException.class, () -> {
-            KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withNewClientSecret()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-            KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        });
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithProducerOAuthWithTls() {
-        CertSecretSource cert4 = new CertSecretSourceBuilder()
-                .withSecretName("third-certificate")
-                .withCertificate("ca.crt")
-                .build();
-
-        CertSecretSource cert5 = new CertSecretSourceBuilder()
-                .withSecretName("fourth-certificate")
-                .withCertificate("tls.crt")
-                .build();
-
-        CertSecretSource cert6 = new CertSecretSourceBuilder()
-                .withSecretName("fourth-certificate")
-                .withCertificate("ca2.crt")
-                .build();
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .withDisableTlsHostnameVerification(true)
-                                        .withTlsTrustedCertificates(cert4, cert5, cert6)
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, "")));
-
-        // Volume mounts
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-first-certificate".equals(mount.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-second-certificate".equals(mount.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-third-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER + "third-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-fourth-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER + "fourth-certificate"));
-
-        // Volumes
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-first-certificate".equals(vol.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-second-certificate".equals(vol.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-third-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-fourth-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-
-        // Environment variable
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_CONSUMER".equals(e.getName())).findFirst().orElse(null), is(nullValue()));
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_PRODUCER".equals(e.getName())).findFirst().orElseThrow().getValue(), is("third-certificate/ca.crt;fourth-certificate/tls.crt;fourth-certificate/ca2.crt"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithBothSidedOAuthWithTls() {
-        CertSecretSource cert1 = new CertSecretSourceBuilder()
-                .withSecretName("first-certificate")
-                .withCertificate("ca.crt")
-                .build();
-
-        CertSecretSource cert2 = new CertSecretSourceBuilder()
-                .withSecretName("second-certificate")
-                .withCertificate("tls.crt")
-                .build();
-
-        CertSecretSource cert3 = new CertSecretSourceBuilder()
-                .withSecretName("first-certificate")
-                .withCertificate("ca2.crt")
-                .build();
-
-        CertSecretSource cert4 = new CertSecretSourceBuilder()
-                .withSecretName("third-certificate")
-                .withCertificate("ca.crt")
-                .build();
-
-        CertSecretSource cert5 = new CertSecretSourceBuilder()
-                .withSecretName("fourth-certificate")
-                .withCertificate("tls.crt")
-                .build();
-
-        CertSecretSource cert6 = new CertSecretSourceBuilder()
-                .withSecretName("fourth-certificate")
-                .withCertificate("ca2.crt")
-                .build();
-
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .editConsumer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .withDisableTlsHostnameVerification(true)
-                                        .withTlsTrustedCertificates(cert1, cert2, cert3)
-                                        .build())
-                    .endConsumer()
-                    .editProducer()
-                        .withAuthentication(
-                                new KafkaClientAuthenticationOAuthBuilder()
-                                        .withClientId("my-client-id")
-                                        .withTokenEndpointUri("http://my-oauth-server")
-                                        .withNewClientSecret()
-                                            .withSecretName("my-secret-secret")
-                                            .withKey("my-secret-key")
-                                        .endClientSecret()
-                                        .withDisableTlsHostnameVerification(true)
-                                        .withTlsTrustedCertificates(cert4, cert5, cert6)
-                                        .build())
-                    .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, "")));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, "")));
-
-        // Volume mounts
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-first-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER + "first-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "consumer-oauth-certs-second-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_CONSUMER + "second-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-third-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER + "third-certificate"));
-        assertThat(cont.getVolumeMounts().stream().filter(mount -> "producer-oauth-certs-fourth-certificate".equals(mount.getName())).findFirst().orElseThrow().getMountPath(), is(KafkaMirrorMakerCluster.OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER + "fourth-certificate"));
-
-        // Volumes
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-first-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "consumer-oauth-certs-second-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-third-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().stream().filter(vol -> "producer-oauth-certs-fourth-certificate".equals(vol.getName())).findFirst().orElseThrow().getSecret().getItems().isEmpty(), is(true));
-
-        // Environment variable
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_CONSUMER".equals(e.getName())).findFirst().orElseThrow().getValue(), is("first-certificate/ca.crt;second-certificate/tls.crt;first-certificate/ca2.crt"));
-        assertThat(cont.getEnv().stream().filter(e -> "KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_PRODUCER".equals(e.getName())).findFirst().orElseThrow().getValue(), is("third-certificate/ca.crt;fourth-certificate/tls.crt;fourth-certificate/ca2.crt"));
-    }
-
-    @ParallelTest
-    public void testGenerateDeploymentWithOAuthUsingOpaqueTokens() {
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                .editConsumer()
-                .withAuthentication(
-                        new KafkaClientAuthenticationOAuthBuilder()
-                                .withClientId("my-client-id")
-                                .withTokenEndpointUri("http://my-oauth-server")
-                                .withNewClientSecret()
-                                .withSecretName("my-secret-secret")
-                                .withKey("my-secret-key")
-                                .endClientSecret()
-                                .withAccessTokenIsJwt(false)
-                                .withMaxTokenExpirySeconds(600)
-                                .build())
-                .endConsumer()
-                .editProducer()
-                .withAuthentication(
-                        new KafkaClientAuthenticationOAuthBuilder()
-                                .withClientId("my-client-id")
-                                .withTokenEndpointUri("http://my-oauth-server")
-                                .withNewClientSecret()
-                                .withSecretName("my-secret-secret")
-                                .withKey("my-secret-key")
-                                .endClientSecret()
-                                .withAccessTokenIsJwt(false)
-                                .withMaxTokenExpirySeconds(600)
-                                .build())
-                .endProducer()
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kc = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, resource, VERSIONS, SHARED_ENV_PROVIDER);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_ACCESS_TOKEN_IS_JWT, "false", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
-
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue(), is("oauth"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElseThrow().getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_ACCESS_TOKEN_IS_JWT, "false", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
-    }
-
-    @ParallelTest
-    public void testMetricsParsingFromConfigMap() {
-        MetricsConfig metrics = new JmxPrometheusExporterMetricsBuilder()
-                .withNewValueFrom()
-                    .withConfigMapKeyRef(new ConfigMapKeySelectorBuilder().withName("my-metrics-configuration").withKey("config.yaml").build())
-                .endValueFrom()
-                .build();
-
-        KafkaMirrorMaker mirrorMaker = new KafkaMirrorMakerBuilder(this.resource)
-                .editSpec()
-                    .withMetricsConfig(metrics)
-                .endSpec()
-                .build();
-
-        KafkaMirrorMakerCluster kmm = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, mirrorMaker, VERSIONS, SHARED_ENV_PROVIDER);
-
-        assertThat(kmm.metrics().isEnabled(), is(true));
-        assertThat(kmm.metrics().getConfigMapName(), is("my-metrics-configuration"));
-        assertThat(kmm.metrics().getConfigMapKey(), is("config.yaml"));
-    }
-
-    @ParallelTest
-    public void testMetricsParsingNoMetrics() {
-        KafkaMirrorMakerCluster kmm = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, this.resource, VERSIONS, SHARED_ENV_PROVIDER);
-
-        assertThat(kmm.metrics().isEnabled(), is(false));
-        assertThat(kmm.metrics().getConfigMapName(), is(nullValue()));
-        assertThat(kmm.metrics().getConfigMapKey(), is(nullValue()));
-    }
-}
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/BaselinePodSecurityProviderTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/BaselinePodSecurityProviderTest.java
index d02af5991ae..6a1e9c42648 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/BaselinePodSecurityProviderTest.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/BaselinePodSecurityProviderTest.java
@@ -96,11 +96,6 @@ public void testPodContextOnOpenShift() {
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
 
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
@@ -145,11 +140,6 @@ public void testPodContextWithUserProvidedContextOnOpenShift() {
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
 
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(null, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(null, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
@@ -194,11 +184,6 @@ public void testPodContextOnKubernetes() {
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
 
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
@@ -243,11 +228,6 @@ public void testPodContextOnKubernetesWithEmptyTemplate() {
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
 
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(null, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(null, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, new PodTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
@@ -292,11 +272,6 @@ public void testPodContextWithUserProvidedContextOnKubernetes() {
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.kafkaConnectBuildPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
 
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(null, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerPodSecurityContext(new PodSecurityProviderContextImpl(JBOD, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
-
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(null, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(EPHEMERAL, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgePodSecurityContext(new PodSecurityProviderContextImpl(PERSISTENT, CUSTOM_POD_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_POD_SECURITY_CONTEXT.getSecurityContext()));
@@ -353,11 +328,6 @@ public void testContainerContext() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(CoreMatchers.nullValue()));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(CoreMatchers.nullValue()));
@@ -419,11 +389,6 @@ public void testContainerContextWithEmptyTemplate() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(CoreMatchers.nullValue()));
@@ -485,11 +450,6 @@ public void testRestrictedContainerContextWithUserProvidedContext() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/RestrictedPodSecurityProviderTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/RestrictedPodSecurityProviderTest.java
index 194ce0f3456..d5a1d93028c 100644
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/RestrictedPodSecurityProviderTest.java
+++ b/cluster-operator/src/test/java/io/strimzi/operator/cluster/model/securityprofiles/RestrictedPodSecurityProviderTest.java
@@ -81,11 +81,6 @@ public void testContainerContext() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, null)), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
@@ -147,11 +142,6 @@ public void testContainerContextWithEmptyTemplate() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, new ContainerTemplate())), CoreMatchers.is(RESTRICTED_CONTAINER_SECURITY_CONTEXT));
@@ -213,11 +203,6 @@ public void testRestrictedContainerContextWithUserProvidedContext() {
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.kafkaConnectInitContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
 
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-        assertThat(provider.kafkaMirrorMakerContainerSecurityContext(new ContainerSecurityProviderContextImpl(JBOD, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
-
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(null, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(EPHEMERAL, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
         assertThat(provider.bridgeContainerSecurityContext(new ContainerSecurityProviderContextImpl(PERSISTENT, CUSTOM_CONTAINER_SECURITY_CONTEXT)), CoreMatchers.is(CUSTOM_CONTAINER_SECURITY_CONTEXT.getSecurityContext()));
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
deleted file mode 100644
index dba1516899e..00000000000
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
+++ /dev/null
@@ -1,724 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.operator.cluster.operator.assembly;
-
-import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.ConfigMapBuilder;
-import io.fabric8.kubernetes.api.model.LabelSelector;
-import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudget;
-import io.fabric8.kubernetes.client.KubernetesClient;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpecBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpecBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerStatus;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.ResourceUtils;
-import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
-import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.model.MockSharedEnvironmentProvider;
-import io.strimzi.operator.cluster.model.SharedEnvironmentProvider;
-import io.strimzi.operator.cluster.model.metrics.MetricsModel;
-import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.ConfigMapOperator;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.CrdOperator;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.DeploymentOperator;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.PodDisruptionBudgetOperator;
-import io.strimzi.operator.cluster.operator.resource.kubernetes.SecretOperator;
-import io.strimzi.operator.common.Annotations;
-import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.model.Labels;
-import io.strimzi.operator.common.model.PasswordGenerator;
-import io.strimzi.operator.common.operator.MockCertManager;
-import io.strimzi.operator.common.operator.resource.ReconcileResult;
-import io.strimzi.platform.KubernetesVersion;
-import io.strimzi.test.TestUtils;
-import io.vertx.core.Future;
-import io.vertx.core.Vertx;
-import io.vertx.junit5.Checkpoint;
-import io.vertx.junit5.VertxExtension;
-import io.vertx.junit5.VertxTestContext;
-import org.junit.jupiter.api.AfterAll;
-import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
-import org.junit.jupiter.api.extension.ExtendWith;
-import org.mockito.ArgumentCaptor;
-
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.CopyOnWriteArraySet;
-
-import static java.util.Arrays.asList;
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.hasSize;
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.ArgumentMatchers.anyInt;
-import static org.mockito.ArgumentMatchers.anyLong;
-import static org.mockito.ArgumentMatchers.anyString;
-import static org.mockito.ArgumentMatchers.eq;
-import static org.mockito.ArgumentMatchers.isNull;
-import static org.mockito.Mockito.doAnswer;
-import static org.mockito.Mockito.never;
-import static org.mockito.Mockito.verify;
-import static org.mockito.Mockito.when;
-
-@SuppressWarnings("deprecation")
-@ExtendWith(VertxExtension.class)
-public class KafkaMirrorMakerAssemblyOperatorTest {
-    private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
-    private static final SharedEnvironmentProvider SHARED_ENV_PROVIDER = new MockSharedEnvironmentProvider();
-    protected static Vertx vertx;
-    private static final String METRICS_CONFIG = "{\"foo\":\"bar\"}";
-
-    private final String producerBootstrapServers = "foo-kafka:9092";
-    private final String consumerBootstrapServers = "bar-kafka:9092";
-    private final String groupId = "my-group-id";
-    private final int numStreams = 2;
-    private final String include = ".*";
-    private final String image = "my-image:latest";
-
-    private final KubernetesVersion kubernetesVersion = KubernetesVersion.MINIMAL_SUPPORTED_VERSION;
-
-    @BeforeAll
-    public static void before() {
-        vertx = Vertx.vertx();
-    }
-
-    @AfterAll
-    public static void after() {
-        vertx.close();
-    }
-
-    @Test
-    public void testCreateCluster(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-
-        ArgumentCaptor<Deployment> dcCaptor = ArgumentCaptor.forClass(Deployment.class);
-        when(mockDcOps.reconcile(any(), anyString(), anyString(), dcCaptor.capture())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.scaleUp(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.succeededFuture(42));
-        when(mockDcOps.scaleDown(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.succeededFuture(42));
-        when(mockDcOps.readiness(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<PodDisruptionBudget> pdbCaptor = ArgumentCaptor.forClass(PodDisruptionBudget.class);
-        when(mockPdbOps.reconcile(any(), anyString(), any(), pdbCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<KafkaMirrorMaker> statusCaptor = ArgumentCaptor.forClass(KafkaMirrorMaker.class);
-        when(mockMirrorOps.updateStatusAsync(any(), statusCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-
-        Checkpoint async = context.checkpoint();
-        ops.reconcile(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName))
-            .onComplete(context.succeeding(v -> context.verify(() -> {
-                // Verify Deployment
-                List<Deployment> capturedDc = dcCaptor.getAllValues();
-                assertThat(capturedDc, hasSize(1));
-                Deployment dc = capturedDc.get(0);
-                assertThat(dc.getMetadata().getName(), is(mirror.getComponentName()));
-                Map<String, String> annotations = new HashMap<>();
-                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_HASH, "e697cf66");
-                annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
-                assertThat("Deployments are not equal", dc, is(mirror.generateDeployment(annotations, true, null, null)));
-
-                // Verify PodDisruptionBudget
-                List<PodDisruptionBudget> capturedPdb = pdbCaptor.getAllValues();
-                assertThat(capturedPdb, hasSize(1));
-                PodDisruptionBudget pdb = capturedPdb.get(0);
-                assertThat(pdb.getMetadata().getName(), is(mirror.getComponentName()));
-                assertThat("PodDisruptionBudgets are not equal", pdb, is(mirror.generatePodDisruptionBudget()));
-
-                // Verify status
-                List<KafkaMirrorMaker> capturedMM = statusCaptor.getAllValues();
-                assertThat(capturedMM, hasSize(1));
-                KafkaMirrorMaker mm = capturedMM.get(0);
-                assertThat(mm.getStatus().getReplicas(), is(mirror.getReplicas()));
-                assertThat(mm.getStatus().getLabelSelector(), is(mirror.getSelectorLabels().toSelectorString()));
-                assertThat(mm.getStatus().getConditions().size(), is(2));
-                assertThat(mm.getStatus().getConditions().get(0).getType(), is("Ready"));
-                assertThat(mm.getStatus().getConditions().get(0).getStatus(), is("True"));
-                assertThat(mm.getStatus().getConditions().get(1).getType(), is("Warning"));
-                assertThat(mm.getStatus().getConditions().get(1).getReason(), is("MirrorMaker1Deprecation"));
-                assertThat(mm.getStatus().getConditions().get(1).getStatus(), is("True"));
-                assertThat(mm.getStatus().getConditions().get(1).getMessage(), is("MirrorMaker 1 is deprecated and will be removed in the next Strimzi release (0.46.0). Please migrate to MirrorMaker 2."));
-
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testUpdateClusterNoDiff(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockMirrorOps.updateStatusAsync(any(), any(KafkaMirrorMaker.class))).thenReturn(Future.succeededFuture());
-        when(mockDcOps.get(kmmNamespace, mirror.getComponentName())).thenReturn(mirror.generateDeployment(new HashMap<>(), true, null, null));
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Deployment> dcCaptor = ArgumentCaptor.forClass(Deployment.class);
-        when(mockDcOps.reconcile(any(), eq(kmmNamespace), dcNameCaptor.capture(), dcCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcScaleUpNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleUpReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleUp(any(), eq(kmmNamespace), dcScaleUpNameCaptor.capture(), dcScaleUpReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcScaleDownNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleDownReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleDown(any(), eq(kmmNamespace), dcScaleDownNameCaptor.capture(), dcScaleDownReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(mirror.getComponentName()), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<PodDisruptionBudget> pdbCaptor = ArgumentCaptor.forClass(PodDisruptionBudget.class);
-        when(mockPdbOps.reconcile(any(), anyString(), any(), pdbCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.createOrUpdate(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName), kmm)
-            .onComplete(context.succeeding(v -> context.verify(() -> {
-                // Verify Deployment Config
-                List<Deployment> capturedDc = dcCaptor.getAllValues();
-                assertThat(capturedDc, hasSize(1));
-
-                // Verify PodDisruptionBudget
-                List<PodDisruptionBudget> capturedPdb = pdbCaptor.getAllValues();
-                assertThat(capturedPdb, hasSize(1));
-                PodDisruptionBudget pdb = capturedPdb.get(0);
-                assertThat(pdb.getMetadata().getName(), is(mirror.getComponentName()));
-                assertThat("PodDisruptionBudgets are not equal", pdb, is(mirror.generatePodDisruptionBudget()));
-
-                // Verify scaleDown / scaleUp were not called
-                assertThat(dcScaleDownNameCaptor.getAllValues(), hasSize(1));
-                assertThat(dcScaleUpNameCaptor.getAllValues(), hasSize(1));
-
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testUpdateCluster(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-        kmm.getSpec().setImage("some/different:image"); // Change the image to generate some diff
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockMirrorOps.updateStatusAsync(any(), any(KafkaMirrorMaker.class))).thenReturn(Future.succeededFuture());
-        when(mockDcOps.get(kmmNamespace, mirror.getComponentName())).thenReturn(mirror.generateDeployment(new HashMap<>(), true, null, null));
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(mirror.getComponentName()), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Deployment> dcCaptor = ArgumentCaptor.forClass(Deployment.class);
-        when(mockDcOps.reconcile(any(), eq(kmmNamespace), dcNameCaptor.capture(), dcCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcScaleUpNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleUpReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleUp(any(), eq(kmmNamespace), dcScaleUpNameCaptor.capture(), dcScaleUpReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcScaleDownNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleDownReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleDown(any(), eq(kmmNamespace), dcScaleDownNameCaptor.capture(), dcScaleDownReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<PodDisruptionBudget> pdbCaptor = ArgumentCaptor.forClass(PodDisruptionBudget.class);
-        when(mockPdbOps.reconcile(any(), anyString(), any(), pdbCaptor.capture())).thenReturn(Future.succeededFuture());
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-
-        // Mock CM get
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        ConfigMap metricsCm = new ConfigMapBuilder().withNewMetadata()
-                    .withName(KafkaMirrorMakerResources.metricsAndLogConfigMapName(kmmName))
-                    .withNamespace(kmmNamespace)
-                .endMetadata()
-                .withData(Collections.singletonMap(MetricsModel.CONFIG_MAP_KEY, METRICS_CONFIG))
-                .build();
-        when(mockCmOps.get(kmmNamespace, KafkaMirrorMakerResources.metricsAndLogConfigMapName(kmmName))).thenReturn(metricsCm);
-
-        // Mock CM patch
-        Set<String> metricsCms = TestUtils.modifiableSet();
-        doAnswer(invocation -> {
-            metricsCms.add(invocation.getArgument(1));
-            return Future.succeededFuture();
-        }).when(mockCmOps).reconcile(any(), eq(kmmNamespace), anyString(), any());
-
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.createOrUpdate(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName), kmm)
-            .onComplete(context.succeeding(v -> context.verify(() -> {
-                KafkaMirrorMakerCluster compareTo = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-
-                // Verify Deployment
-                List<Deployment> capturedDc = dcCaptor.getAllValues();
-                assertThat(capturedDc, hasSize(1));
-                Deployment dc = capturedDc.get(0);
-                assertThat(dc.getMetadata().getName(), is(compareTo.getComponentName()));
-                Map<String, String> annotations = new HashMap<>();
-                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_HASH, "e697cf66");
-                annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
-                assertThat("Deployments are not equal", dc, is(compareTo.generateDeployment(annotations, true, null, null)));
-
-                // Verify PodDisruptionBudget
-                List<PodDisruptionBudget> capturedPdb = pdbCaptor.getAllValues();
-                assertThat(capturedPdb, hasSize(1));
-                PodDisruptionBudget pdb = capturedPdb.get(0);
-                assertThat(pdb.getMetadata().getName(), is(compareTo.getComponentName()));
-                assertThat("PodDisruptionBudgets are not equal", pdb, is(compareTo.generatePodDisruptionBudget()));
-
-                // Verify scaleDown / scaleUp were not called
-                assertThat(dcScaleDownNameCaptor.getAllValues(), hasSize(1));
-                assertThat(dcScaleUpNameCaptor.getAllValues(), hasSize(1));
-
-                // No metrics config  => no CMs created
-                verify(mockCmOps, never()).createOrUpdate(any(), any());
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testUpdateClusterFailure(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-        kmm.getSpec().setImage("some/different:image"); // Change the image to generate some diff
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockDcOps.get(kmmNamespace, mirror.getComponentName())).thenReturn(mirror.generateDeployment(new HashMap<>(), true, null, null));
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(mirror.getComponentName()), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcNamespaceCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<String> dcNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Deployment> dcCaptor = ArgumentCaptor.forClass(Deployment.class);
-        when(mockDcOps.reconcile(any(), dcNamespaceCaptor.capture(), dcNameCaptor.capture(), dcCaptor.capture())).thenReturn(Future.failedFuture("Failed"));
-
-        ArgumentCaptor<String> dcScaleUpNamespaceCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<String> dcScaleUpNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleUpReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleUp(any(), dcScaleUpNamespaceCaptor.capture(), dcScaleUpNameCaptor.capture(), dcScaleUpReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<String> dcScaleDownNamespaceCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<String> dcScaleDownNameCaptor = ArgumentCaptor.forClass(String.class);
-        ArgumentCaptor<Integer> dcScaleDownReplicasCaptor = ArgumentCaptor.forClass(Integer.class);
-        when(mockDcOps.scaleDown(any(), dcScaleDownNamespaceCaptor.capture(), dcScaleDownNameCaptor.capture(), dcScaleDownReplicasCaptor.capture(), anyLong())).thenReturn(Future.succeededFuture());
-
-        when(mockPdbOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture());
-
-        when(mockMirrorOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new KafkaMirrorMaker())));
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockMirrorOps.updateStatusAsync(any(), any(KafkaMirrorMaker.class))).thenReturn(Future.succeededFuture());
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.createOrUpdate(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName), kmm)
-            .onComplete(context.failing(v -> context.verify(() -> async.flag())));
-    }
-
-    @Test
-    public void testUpdateClusterScaleUp(VertxTestContext context) {
-        final int scaleTo = 4;
-
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-        kmm.getSpec().setReplicas(scaleTo); // Change replicas to create ScaleUp
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockDcOps.get(kmmNamespace, mirror.getComponentName())).thenReturn(mirror.generateDeployment(new HashMap<>(), true, null, null));
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(mirror.getComponentName()), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.reconcile(any(), eq(kmmNamespace), any(), any())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        doAnswer(i -> Future.succeededFuture(scaleTo))
-                .when(mockDcOps).scaleUp(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-
-        doAnswer(i -> Future.succeededFuture(scaleTo))
-                .when(mockDcOps).scaleDown(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-
-        when(mockMirrorOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new KafkaMirrorMaker())));
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockMirrorOps.updateStatusAsync(any(), any(KafkaMirrorMaker.class))).thenReturn(Future.succeededFuture());
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-
-        when(mockPdbOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture());
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.createOrUpdate(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName), kmm)
-            .onComplete(context.succeeding(v -> context.verify(() -> {
-                verify(mockDcOps).scaleUp(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testUpdateClusterScaleDown(VertxTestContext context) {
-        int scaleTo = 2;
-
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-        KafkaMirrorMakerCluster mirror = KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kmm, VERSIONS, SHARED_ENV_PROVIDER);
-        kmm.getSpec().setReplicas(scaleTo); // Change replicas to create ScaleDown
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockMirrorOps.updateStatusAsync(any(), any(KafkaMirrorMaker.class))).thenReturn(Future.succeededFuture());
-        when(mockDcOps.get(kmmNamespace, mirror.getComponentName())).thenReturn(mirror.generateDeployment(new HashMap<>(), true, null, null));
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(mirror.getComponentName()), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.reconcile(any(), eq(kmmNamespace), any(), any())).thenReturn(Future.succeededFuture());
-
-        doAnswer(i -> Future.succeededFuture(scaleTo))
-                .when(mockDcOps).scaleUp(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-
-        doAnswer(i -> Future.succeededFuture(scaleTo))
-                .when(mockDcOps).scaleDown(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-
-        when(mockMirrorOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new KafkaMirrorMaker())));
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-
-        when(mockPdbOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture());
-
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.createOrUpdate(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName), kmm)
-            .onComplete(context.succeeding(v -> context.verify(() -> {
-                verify(mockDcOps).scaleUp(any(), eq(kmmNamespace), eq(mirror.getComponentName()), eq(scaleTo), anyLong());
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testReconcile(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        SecretOperator mockSecretOps = supplier.secretOperations;
-
-        String kmmNamespace = "test";
-
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker foo = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, "foo", image, producer, consumer, include);
-        KafkaMirrorMaker bar = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, "bar", image, producer, consumer, include);
-
-        when(mockMirrorOps.listAsync(eq(kmmNamespace), isNull(LabelSelector.class))).thenReturn(Future.succeededFuture(asList(foo, bar)));
-        // when requested ConfigMap for a specific Kafka Mirror Maker cluster
-        when(mockMirrorOps.getAsync(anyString(), eq("foo"))).thenReturn(Future.succeededFuture(foo));
-        when(mockMirrorOps.getAsync(anyString(), eq("bar"))).thenReturn(Future.succeededFuture(bar));
-
-        // providing the list of ALL Deployments for all the Kafka Mirror Maker clusters
-        Labels newLabels = Labels.forStrimziKind(KafkaMirrorMaker.RESOURCE_KIND);
-        when(mockDcOps.list(eq(kmmNamespace), eq(newLabels))).thenReturn(
-                asList(KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, bar, VERSIONS, SHARED_ENV_PROVIDER).generateDeployment(new HashMap<>(), true, null, null)));
-
-        // providing the list Deployments for already "existing" Kafka Mirror Maker clusters
-        Labels barLabels = Labels.forStrimziCluster("bar");
-        when(mockDcOps.list(eq(kmmNamespace), eq(barLabels))).thenReturn(
-                asList(KafkaMirrorMakerCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, bar, VERSIONS, SHARED_ENV_PROVIDER).generateDeployment(new HashMap<>(), true, null, null))
-        );
-        when(mockDcOps.readiness(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-
-        when(mockSecretOps.reconcile(any(), eq(kmmNamespace), any(), any())).thenReturn(Future.succeededFuture());
-
-        Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
-
-        Checkpoint createdOrUpdateAsync = context.checkpoint(2);
-
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS)) {
-
-            @Override
-            public Future<KafkaMirrorMakerStatus> createOrUpdate(Reconciliation reconciliation, KafkaMirrorMaker kafkaMirrorMakerAssembly) {
-                createdOrUpdated.add(kafkaMirrorMakerAssembly.getMetadata().getName());
-                createdOrUpdateAsync.flag();
-                return Future.succeededFuture();
-            }
-        };
-
-        Checkpoint async = context.checkpoint();
-        // Now try to reconcile all the Kafka Mirror Maker clusters
-        ops.reconcileAll("test", kmmNamespace,
-            context.succeeding(v -> context.verify(() -> {
-                assertThat(createdOrUpdated, is(new HashSet<>(asList("foo", "bar"))));
-                async.flag();
-            })));
-
-    }
-
-    @Test
-    public void testCreateClusterStatusNotReady(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String failureMsg = "failure";
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, producer, consumer, include);
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockDcOps.reconcile(any(), anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.scaleUp(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.failedFuture(failureMsg));
-        when(mockDcOps.scaleDown(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.succeededFuture(42));
-        when(mockDcOps.readiness(any(), eq(kmmNamespace), eq(kmmName), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockPdbOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture());
-
-        ArgumentCaptor<KafkaMirrorMaker> statusCaptor = ArgumentCaptor.forClass(KafkaMirrorMaker.class);
-        when(mockMirrorOps.updateStatusAsync(any(), statusCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.reconcile(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName))
-            .onComplete(context.failing(e -> context.verify(() -> {
-                // Verify status
-                List<KafkaMirrorMaker> capturedMM = statusCaptor.getAllValues();
-                assertThat(capturedMM, hasSize(1));
-                KafkaMirrorMaker mm = capturedMM.get(0);
-                assertThat(mm.getStatus().getConditions().size(), is(2));
-                assertThat(mm.getStatus().getConditions().get(0).getType(), is("NotReady"));
-                assertThat(mm.getStatus().getConditions().get(0).getStatus(), is("True"));
-                assertThat(mm.getStatus().getConditions().get(0).getMessage(), is(failureMsg));
-                assertThat(mm.getStatus().getConditions().get(1).getType(), is("Warning"));
-                assertThat(mm.getStatus().getConditions().get(1).getReason(), is("MirrorMaker1Deprecation"));
-                assertThat(mm.getStatus().getConditions().get(1).getStatus(), is("True"));
-                assertThat(mm.getStatus().getConditions().get(1).getMessage(), is("MirrorMaker 1 is deprecated and will be removed in the next Strimzi release (0.46.0). Please migrate to MirrorMaker 2."));
-
-                async.flag();
-            })));
-    }
-
-    @Test
-    public void testCreateOrUpdateZeroReplica(VertxTestContext context) {
-        ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
-        CrdOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> mockMirrorOps = supplier.mirrorMakerOperator;
-        DeploymentOperator mockDcOps = supplier.deploymentOperations;
-        PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
-        ConfigMapOperator mockCmOps = supplier.configMapOperations;
-
-        String kmmName = "foo";
-        String kmmNamespace = "test";
-        KafkaMirrorMakerConsumerSpec consumer = new KafkaMirrorMakerConsumerSpecBuilder()
-                .withBootstrapServers(consumerBootstrapServers)
-                .withGroupId(groupId)
-                .withNumStreams(numStreams)
-                .build();
-        KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
-                .withBootstrapServers(producerBootstrapServers)
-                .build();
-        KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, 0, producer, consumer, include);
-
-        when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);
-        when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kmm));
-        when(mockDcOps.reconcile(any(), anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
-        when(mockDcOps.scaleUp(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.succeededFuture(42));
-        when(mockDcOps.scaleDown(any(), anyString(), anyString(), anyInt(), anyLong())).thenReturn(Future.succeededFuture(42));
-        when(mockDcOps.waitForObserved(any(), anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
-        when(mockPdbOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture());
-        when(mockCmOps.reconcile(any(), anyString(), any(), any())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
-
-        ArgumentCaptor<KafkaMirrorMaker> mirrorMakerCaptor = ArgumentCaptor.forClass(KafkaMirrorMaker.class);
-        when(mockMirrorOps.updateStatusAsync(any(), mirrorMakerCaptor.capture())).thenReturn(Future.succeededFuture());
-
-        KafkaMirrorMakerAssemblyOperator ops = new KafkaMirrorMakerAssemblyOperator(vertx,
-                new PlatformFeaturesAvailability(true, kubernetesVersion),
-                new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
-
-        Checkpoint async = context.checkpoint();
-        ops.reconcile(new Reconciliation("test-trigger", KafkaMirrorMaker.RESOURCE_KIND, kmmNamespace, kmmName))
-                .onComplete(context.succeeding(v -> context.verify(() -> {
-                    // 0 Replicas - readiness should never get called.
-                    verify(mockDcOps, never()).readiness(any(), anyString(), anyString(), anyLong(), anyLong());
-
-                    List<KafkaMirrorMaker> capturedMM = mirrorMakerCaptor.getAllValues();
-                    assertThat(capturedMM, hasSize(1));
-                    KafkaMirrorMaker mm = capturedMM.get(0);
-
-                    assertThat(mm.getStatus().getConditions().size(), is(2));
-                    assertThat(mm.getStatus().getConditions().get(0).getType(), is("Ready"));
-                    assertThat(mm.getStatus().getConditions().get(0).getStatus(), is("True"));
-                    assertThat(mm.getStatus().getConditions().get(1).getType(), is("Warning"));
-                    assertThat(mm.getStatus().getConditions().get(1).getReason(), is("MirrorMaker1Deprecation"));
-                    assertThat(mm.getStatus().getConditions().get(1).getStatus(), is("True"));
-                    assertThat(mm.getStatus().getConditions().get(1).getMessage(), is("MirrorMaker 1 is deprecated and will be removed in the next Strimzi release (0.46.0). Please migrate to MirrorMaker 2."));
-
-                    async.flag();
-                })));
-    }
-}
diff --git a/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/kubernetes/KafkaMirrorMakerCrdOperatorIT.java b/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/kubernetes/KafkaMirrorMakerCrdOperatorIT.java
deleted file mode 100644
index 890b7a36900..00000000000
--- a/cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/kubernetes/KafkaMirrorMakerCrdOperatorIT.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.operator.cluster.operator.resource.kubernetes;
-
-import io.fabric8.kubernetes.client.KubernetesClient;
-import io.strimzi.api.kafka.model.common.InlineLogging;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerBuilder;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
-import io.strimzi.test.CrdUtils;
-import io.vertx.junit5.VertxExtension;
-import io.vertx.junit5.VertxTestContext;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
-import org.junit.jupiter.api.extension.ExtendWith;
-
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.MatcherAssert.assertThat;
-
-/**
- * The main purpose of the Integration Tests for the operators is to test them against a real Kubernetes cluster.
- * Real Kubernetes cluster has often some quirks such as some fields being immutable, some fields in the spec section
- * being created by the Kubernetes API etc. These things are hard to test with mocks. These IT tests make it easy to
- * test them against real clusters.
- */
-@ExtendWith(VertxExtension.class)
-public class KafkaMirrorMakerCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> {
-    protected static final Logger LOGGER = LogManager.getLogger(KafkaMirrorMakerCrdOperatorIT.class);
-
-    @Override
-    protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaMirrorMaker.class, KafkaMirrorMakerList.class, KafkaMirrorMaker.RESOURCE_KIND);
-    }
-
-    @Override
-    protected String getCrd() {
-        return CrdUtils.CRD_KAFKA_MIRROR_MAKER;
-    }
-
-    @Override
-    protected String getCrdName() {
-        return KafkaMirrorMaker.CRD_NAME;
-    }
-
-    @Override
-    protected String getNamespace() {
-        return "kafka-mirror-maker-2-crd-it-namespace";
-    }
-
-    @Override
-    protected KafkaMirrorMaker getResource(String resourceName) {
-        return new KafkaMirrorMakerBuilder()
-                .withNewMetadata()
-                    .withName(resourceName)
-                    .withNamespace(getNamespace())
-                .endMetadata()
-                .withNewSpec()
-                    .withNewConsumer()
-                        .withBootstrapServers("localhost:9092")
-                        .withGroupId("my-group")
-                    .endConsumer()
-                    .withNewProducer()
-                        .withBootstrapServers("localhost:9092")
-                    .endProducer()
-                    .withInclude(".*")
-                .endSpec()
-                .withNewStatus()
-                .endStatus()
-                .build();
-    }
-
-    @Override
-    protected KafkaMirrorMaker getResourceWithModifications(KafkaMirrorMaker resourceInCluster) {
-        return new KafkaMirrorMakerBuilder(resourceInCluster)
-                .editSpec()
-                    .withLogging(new InlineLogging())
-                .endSpec()
-                .build();
-    }
-
-    @Override
-    protected KafkaMirrorMaker getResourceWithNewReadyStatus(KafkaMirrorMaker resourceInCluster) {
-        return new KafkaMirrorMakerBuilder(resourceInCluster)
-                .withNewStatus()
-                    .withConditions(READY_CONDITION)
-                .endStatus()
-                .build();
-    }
-
-    @Override
-    protected void assertReady(VertxTestContext context, KafkaMirrorMaker resource) {
-        context.verify(() -> assertThat(resource.getStatus()
-                .getConditions()
-                .get(0), is(READY_CONDITION)));
-    }
-}
diff --git a/development-docs/TESTING.md b/development-docs/TESTING.md
index 7e1a26de0fe..a95bb15a8c2 100644
--- a/development-docs/TESTING.md
+++ b/development-docs/TESTING.md
@@ -216,7 +216,7 @@ class spawns as many threads as we specify in the `JUnit-platform.properties`.
 - **@ParallelTest** = overrides parallelism configuration by `@Execution(ExecutionMode.CONCURRENT)` and thus test case will
   run simultaneously with other parallel tests
 - **@ParallelNamespaceTest** = same as @ParallelTest but with additional change. This type of test automatically creates
-  its namespace where all resources will be deployed (f.e., needed where we deploy `Kafka` or `KafkaMirrorMaker`).
+  its namespace where all resources will be deployed (f.e., needed where we deploy `Kafka` or `KafkaMirrorMaker2`).
 
 #### 3. Auxiliary classes
 
@@ -272,7 +272,6 @@ The following table shows currently used tags:
 | recovery           |                                Execute recovery tests                                 |
 | connectoroperator  |                   Execute tests that deploy KafkaConnector resource                   |
 | connect            |                    Execute tests that deploy KafkaConnect resource                    |
-| mirrormaker        |                  Execute tests that deploy KafkaMirrorMaker resource                  |
 | mirrormaker2       |                 Execute tests that deploy KafkaMirrorMaker2 resource                  |
 | conneccomponents   |  Execute tests that deploy KafkaConnect, KafkaMirrorMaker2, KafkaConnector resources  |
 | bridge             |                          Execute tests that use Kafka Bridge                          |
diff --git a/docker-images/kafka-based/kafka/Dockerfile b/docker-images/kafka-based/kafka/Dockerfile
index 4014e737cc1..4fa57891b79 100644
--- a/docker-images/kafka-based/kafka/Dockerfile
+++ b/docker-images/kafka-based/kafka/Dockerfile
@@ -95,7 +95,6 @@ RUN set -ex; \
 # Add Strimzi agents
 #####
 COPY ./tmp/kafka-agent-${STRIMZI_VERSION}.jar ${KAFKA_HOME}/libs/
-COPY ./tmp/mirror-maker-agent-${STRIMZI_VERSION}.jar ${KAFKA_HOME}/libs/
 COPY ./tmp/tracing-agent-${STRIMZI_VERSION}.jar ${KAFKA_HOME}/libs/
 
 #####
diff --git a/docker-images/kafka-based/kafka/Makefile b/docker-images/kafka-based/kafka/Makefile
index d5fde45886d..197f310a9c9 100644
--- a/docker-images/kafka-based/kafka/Makefile
+++ b/docker-images/kafka-based/kafka/Makefile
@@ -4,7 +4,6 @@ PROJECT_NAME=kafka
 include ../../../Makefile.docker
 
 kafka_agent_dist := ../../artifacts/binaries/kafka-agent-$(RELEASE_VERSION)-dist.zip
-mirror_maker_agent_dist := ../../artifacts/binaries/mirror-maker-agent-$(RELEASE_VERSION)-dist.zip
 tracing_agent_dist := ../../artifacts/binaries/tracing-agent-$(RELEASE_VERSION)-dist.zip
 
 clean:
@@ -17,12 +16,6 @@ clean:
 	mv tmp/io.strimzi.kafka-agent-$(RELEASE_VERSION).jar tmp/kafka-agent-$(RELEASE_VERSION).jar
 	touch .kafka-agent.tmp
 
-.mirror-maker-agent.tmp: $(mirror_maker_agent_dist)
-	test -d tmp || mkdir tmp
-	unzip -qoj $(mirror_maker_agent_dist) lib/io.strimzi.mirror-maker-agent-$(RELEASE_VERSION).jar -d tmp/
-	mv tmp/io.strimzi.mirror-maker-agent-$(RELEASE_VERSION).jar tmp/mirror-maker-agent-$(RELEASE_VERSION).jar
-	touch .mirror-maker-agent.tmp
-
 .tracing-agent.tmp: $(tracing_agent_dist)
 	test -d tmp || mkdir tmp
 	unzip -qoj $(tracing_agent_dist) lib/io.strimzi.tracing-agent-$(RELEASE_VERSION).jar -d tmp/
@@ -49,7 +42,7 @@ clean:
 	cp ../../artifacts/binaries/kafka/$(KAFKA_VERSION).ignorelist tmp/$(KAFKA_VERSION).ignorelist
 	touch .kafka-$(KAFKA_VERSION)-ignorelist.tmp
 
-docker_build: .kafka-agent.tmp .tracing-agent.tmp .mirror-maker-agent.tmp .thirdparty-libs-$(THIRD_PARTY_LIBS).tmp .thirdparty-libs-cc.tmp .kafka-$(KAFKA_VERSION).tmp .kafka-$(KAFKA_VERSION)-ignorelist.tmp docker_build_default
+docker_build: .kafka-agent.tmp .tracing-agent.tmp .thirdparty-libs-$(THIRD_PARTY_LIBS).tmp .thirdparty-libs-cc.tmp .kafka-$(KAFKA_VERSION).tmp .kafka-$(KAFKA_VERSION)-ignorelist.tmp docker_build_default
 	# Pull dependencies first
 
 docker_build:
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_run.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_run.sh
index 28cd1b88025..1176365d82c 100755
--- a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_run.sh
+++ b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_run.sh
@@ -62,7 +62,7 @@ if [ -n "$KAFKA_MIRRORMAKER_2_CLUSTERS" ]; then
         echo "  with tls auth keys ${TLS_AUTH_KEYS["${clusterAlias}"]}"
         echo "  with OAuth trusted certs ${OAUTH_TRUSTED_CERTS["${clusterAlias}"]}"
         # $1 = trusted certs, $2 = TLS auth cert, $3 = TLS auth key, $4 = truststore path, $5 = keystore path, $6 = certs and key path
-        ./kafka_mirror_maker_tls_prepare_certificates.sh \
+        ./kafka_mirror_maker_2_tls_prepare_certificates.sh \
             "${TRUSTED_CERTS["${clusterAlias}"]}" \
             "${TLS_AUTH_CERTS["${clusterAlias}"]}" \
             "${TLS_AUTH_KEYS["${clusterAlias}"]}" \
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_tls_prepare_certificates.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_tls_prepare_certificates.sh
similarity index 100%
rename from docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_tls_prepare_certificates.sh
rename to docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_2_tls_prepare_certificates.sh
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_consumer_config_generator.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_consumer_config_generator.sh
deleted file mode 100755
index a57e09d8788..00000000000
--- a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_consumer_config_generator.sh
+++ /dev/null
@@ -1,99 +0,0 @@
-#!/usr/bin/env bash
-set -e
-
-SECURITY_PROTOCOL=PLAINTEXT
-
-if [ "$KAFKA_MIRRORMAKER_TLS_CONSUMER" = "true" ]; then
-    SECURITY_PROTOCOL="SSL"
-
-    if [ -n "$KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER" ]; then
-        TLS_CONFIGURATION=$(cat <<EOF
-# TLS / SSL
-ssl.truststore.location=/tmp/kafka/consumer.truststore.p12
-ssl.truststore.password=${CERTS_STORE_PASSWORD}
-ssl.truststore.type=PKCS12
-EOF
-)
-    fi
-
-    if [ -n "$KAFKA_MIRRORMAKER_TLS_AUTH_CERT_CONSUMER" ] && [ -n "$KAFKA_MIRRORMAKER_TLS_AUTH_KEY_CONSUMER" ]; then
-        TLS_AUTH_CONFIGURATION=$(cat <<EOF
-ssl.keystore.location=/tmp/kafka/consumer.keystore.p12
-ssl.keystore.password=${CERTS_STORE_PASSWORD}
-ssl.keystore.type=PKCS12
-EOF
-)
-    fi
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER" ]; then
-    if [ "$SECURITY_PROTOCOL" = "SSL" ]; then
-        SECURITY_PROTOCOL="SASL_SSL"
-    else
-        SECURITY_PROTOCOL="SASL_PLAINTEXT"
-    fi
-
-    if [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER" = "plain" ]; then
-        PASSWORD=$(cat "/opt/kafka/consumer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER")
-        SASL_MECHANISM="PLAIN"
-        JAAS_CONFIG="org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER" = "scram-sha-512" ]; then
-        PASSWORD=$(cat "/opt/kafka/consumer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER")
-        SASL_MECHANISM="SCRAM-SHA-512"
-        JAAS_CONFIG="org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER" = "scram-sha-256" ]; then
-        PASSWORD=$(cat "/opt/kafka/consumer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_CONSUMER")
-        SASL_MECHANISM="SCRAM-SHA-256"
-        JAAS_CONFIG="org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_CONSUMER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_CONSUMER" = "oauth" ]; then
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER" ]; then
-            OAUTH_ACCESS_TOKEN="oauth.access.token=\"$KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_CONSUMER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER" ]; then
-            OAUTH_REFRESH_TOKEN="oauth.refresh.token=\"$KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_CONSUMER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER" ]; then
-            OAUTH_CLIENT_SECRET="oauth.client.secret=\"$KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER" ]; then
-            OAUTH_PASSWORD_GRANT_PASSWORD="oauth.password.grant.password=\"$KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_CONSUMER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER" ]; then
-            OAUTH_CLIENT_ASSERTION="oauth.client.assertion=\"$KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_CONSUMER\""
-        fi
-
-        if [ -f "/tmp/kafka/consumer-oauth.keystore.p12" ]; then
-            OAUTH_TRUSTSTORE="oauth.ssl.truststore.location=\"/tmp/kafka/consumer-oauth.keystore.p12\" oauth.ssl.truststore.password=\"${CERTS_STORE_PASSWORD}\" oauth.ssl.truststore.type=\"PKCS12\""
-        fi
-
-        SASL_MECHANISM="OAUTHBEARER"
-        JAAS_CONFIG="org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required ${KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER} ${OAUTH_CLIENT_SECRET} ${OAUTH_REFRESH_TOKEN} ${OAUTH_ACCESS_TOKEN} ${OAUTH_PASSWORD_GRANT_PASSWORD} ${OAUTH_CLIENT_ASSERTION} ${OAUTH_TRUSTSTORE};"
-        OAUTH_CALLBACK_CLASS="sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler"
-    fi
-
-    SASL_AUTH_CONFIGURATION=$(cat <<EOF
-sasl.mechanism=${SASL_MECHANISM}
-sasl.jaas.config=${JAAS_CONFIG}
-${OAUTH_CALLBACK_CLASS}
-EOF
-)
-fi
-
-# Write the config file
-cat <<EOF
-# Bootstrap servers
-bootstrap.servers=${KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_CONSUMER}
-# Consumer group
-group.id=${KAFKA_MIRRORMAKER_GROUPID_CONSUMER}
-# Provided configuration
-${KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER}
-
-security.protocol=${SECURITY_PROTOCOL}
-${TLS_CONFIGURATION}
-${TLS_AUTH_CONFIGURATION}
-${SASL_AUTH_CONFIGURATION}
-EOF
\ No newline at end of file
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_liveness.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_liveness.sh
deleted file mode 100755
index c240c55acd9..00000000000
--- a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_liveness.sh
+++ /dev/null
@@ -1,9 +0,0 @@
-#!/usr/bin/env bash
-set -e
-
-if [ -f /tmp/mirror-maker-alive ] ; then
-  rm -f /tmp/mirror-maker-alive 2&> /dev/null
-  exit 0
-else
-  exit 1
-fi
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_producer_config_generator.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_producer_config_generator.sh
deleted file mode 100755
index b64265bfd50..00000000000
--- a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_producer_config_generator.sh
+++ /dev/null
@@ -1,97 +0,0 @@
-#!/usr/bin/env bash
-set -e
-
-SECURITY_PROTOCOL=PLAINTEXT
-
-if [ "$KAFKA_MIRRORMAKER_TLS_PRODUCER" = "true" ]; then
-    SECURITY_PROTOCOL="SSL"
-
-    if [ -n "$KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER" ]; then
-        TLS_CONFIGURATION=$(cat <<EOF
-# TLS / SSL
-ssl.truststore.location=/tmp/kafka/producer.truststore.p12
-ssl.truststore.password=${CERTS_STORE_PASSWORD}
-ssl.truststore.type=PKCS12
-EOF
-)
-    fi
-
-    if [ -n "$KAFKA_MIRRORMAKER_TLS_AUTH_CERT_PRODUCER" ] && [ -n "$KAFKA_MIRRORMAKER_TLS_AUTH_KEY_PRODUCER" ]; then
-        TLS_AUTH_CONFIGURATION=$(cat <<EOF
-ssl.keystore.location=/tmp/kafka/producer.keystore.p12
-ssl.keystore.password=${CERTS_STORE_PASSWORD}
-ssl.keystore.type=PKCS12
-EOF
-)
-    fi
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER" ]; then
-    if [ "$SECURITY_PROTOCOL" = "SSL" ]; then
-        SECURITY_PROTOCOL="SASL_SSL"
-    else
-        SECURITY_PROTOCOL="SASL_PLAINTEXT"
-    fi
-
-    if [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER" = "plain" ]; then
-        PASSWORD=$(cat "/opt/kafka/producer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER")
-        SASL_MECHANISM="PLAIN"
-        JAAS_CONFIG="org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER" = "scram-sha-512" ]; then
-        PASSWORD=$(cat "/opt/kafka/producer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER")
-        SASL_MECHANISM="SCRAM-SHA-512"
-        JAAS_CONFIG="org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER" = "scram-sha-256" ]; then
-        PASSWORD=$(cat "/opt/kafka/producer-password/$KAFKA_MIRRORMAKER_SASL_PASSWORD_FILE_PRODUCER")
-        SASL_MECHANISM="SCRAM-SHA-256"
-        JAAS_CONFIG="org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_MIRRORMAKER_SASL_USERNAME_PRODUCER}\" password=\"${PASSWORD}\";"
-    elif [ "$KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER" = "oauth" ]; then
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER" ]; then
-            OAUTH_ACCESS_TOKEN="oauth.access.token=\"$KAFKA_MIRRORMAKER_OAUTH_ACCESS_TOKEN_PRODUCER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER" ]; then
-            OAUTH_REFRESH_TOKEN="oauth.refresh.token=\"$KAFKA_MIRRORMAKER_OAUTH_REFRESH_TOKEN_PRODUCER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER" ]; then
-            OAUTH_CLIENT_SECRET="oauth.client.secret=\"$KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER" ]; then
-            OAUTH_PASSWORD_GRANT_PASSWORD="oauth.password.grant.password=\"$KAFKA_MIRRORMAKER_OAUTH_PASSWORD_GRANT_PASSWORD_PRODUCER\""
-        fi
-
-        if [ -n "$KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER" ]; then
-            OAUTH_CLIENT_ASSERTION="oauth.client.assertion=\"$KAFKA_MIRRORMAKER_OAUTH_CLIENT_ASSERTION_PRODUCER\""
-        fi
-
-        if [ -f "/tmp/kafka/producer-oauth.keystore.p12" ]; then
-            OAUTH_TRUSTSTORE="oauth.ssl.truststore.location=\"/tmp/kafka/producer-oauth.keystore.p12\" oauth.ssl.truststore.password=\"${CERTS_STORE_PASSWORD}\" oauth.ssl.truststore.type=\"PKCS12\""
-        fi
-
-        SASL_MECHANISM="OAUTHBEARER"
-        JAAS_CONFIG="org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required ${KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER} ${OAUTH_CLIENT_SECRET} ${OAUTH_REFRESH_TOKEN} ${OAUTH_ACCESS_TOKEN} ${OAUTH_PASSWORD_GRANT_PASSWORD} ${OAUTH_CLIENT_ASSERTION} ${OAUTH_TRUSTSTORE};"
-        OAUTH_CALLBACK_CLASS="sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler"
-    fi
-
-    SASL_AUTH_CONFIGURATION=$(cat <<EOF
-sasl.mechanism=${SASL_MECHANISM}
-sasl.jaas.config=${JAAS_CONFIG}
-${OAUTH_CALLBACK_CLASS}
-EOF
-)
-fi
-
-# Write the config file
-cat <<EOF
-# Bootstrap servers
-bootstrap.servers=${KAFKA_MIRRORMAKER_BOOTSTRAP_SERVERS_PRODUCER}
-# Provided configuration
-${KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER}
-
-security.protocol=${SECURITY_PROTOCOL}
-${TLS_CONFIGURATION}
-${TLS_AUTH_CONFIGURATION}
-${SASL_AUTH_CONFIGURATION}
-EOF
\ No newline at end of file
diff --git a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_run.sh b/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_run.sh
deleted file mode 100755
index 2005bc0245c..00000000000
--- a/docker-images/kafka-based/kafka/scripts/kafka_mirror_maker_run.sh
+++ /dev/null
@@ -1,131 +0,0 @@
-#!/usr/bin/env bash
-set -e
-set +x
-
-# Generate temporary keystore password
-CERTS_STORE_PASSWORD=$(< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c32)
-export CERTS_STORE_PASSWORD
-
-# Create dir where keystores and truststores will be stored
-mkdir -p /tmp/kafka
-
-# Import certificates into keystore and truststore
-# $1 = trusted certs, $2 = TLS auth cert, $3 = TLS auth key, $4 = truststore path, $5 = keystore path, $6 = certs and key path
-./kafka_mirror_maker_tls_prepare_certificates.sh \
-    "$KAFKA_MIRRORMAKER_TRUSTED_CERTS_CONSUMER" \
-    "$KAFKA_MIRRORMAKER_TLS_AUTH_CERT_CONSUMER" \
-    "$KAFKA_MIRRORMAKER_TLS_AUTH_KEY_CONSUMER" \
-    "/tmp/kafka/consumer.truststore.p12" \
-    "/tmp/kafka/consumer.keystore.p12" \
-    "/opt/kafka/consumer-certs" \
-    "$KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_CONSUMER" \
-    "/opt/kafka/consumer-oauth-certs" \
-    "/tmp/kafka/consumer-oauth.keystore.p12"
-
-./kafka_mirror_maker_tls_prepare_certificates.sh \
-    "$KAFKA_MIRRORMAKER_TRUSTED_CERTS_PRODUCER" \
-    "$KAFKA_MIRRORMAKER_TLS_AUTH_CERT_PRODUCER" \
-    "$KAFKA_MIRRORMAKER_TLS_AUTH_KEY_PRODUCER" \
-    "/tmp/kafka/producer.truststore.p12" \
-    "/tmp/kafka/producer.keystore.p12" \
-    "/opt/kafka/producer-certs" \
-    "$KAFKA_MIRRORMAKER_OAUTH_TRUSTED_CERTS_PRODUCER" \
-    "/opt/kafka/producer-oauth-certs" \
-    "/tmp/kafka/producer-oauth.keystore.p12"
-
-# Generate and print the consumer config file
-echo "Kafka Mirror Maker consumer configuration:"
-./kafka_mirror_maker_consumer_config_generator.sh | tee /tmp/strimzi-consumer.properties | sed -e 's/sasl.jaas.config=.*/sasl.jaas.config=[hidden]/g' -e 's/password=.*/password=[hidden]/g'
-echo ""
-
-# Generate and print the producer config file
-echo "Kafka Mirror Maker producer configuration:"
-./kafka_mirror_maker_producer_config_generator.sh | tee /tmp/strimzi-producer.properties | sed -e 's/sasl.jaas.config=.*/sasl.jaas.config=[hidden]/g' -e 's/password=.*/password=[hidden]/g'
-echo ""
-
-# Disable Kafka's GC logging (which logs to a file)...
-export GC_LOG_ENABLED="false"
-
-if [ -z "$KAFKA_LOG4J_OPTS" ]; then
-  export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$KAFKA_HOME/custom-config/log4j.properties"
-fi
-
-# We don't need LOG_DIR because we write no log files, but setting it to a
-# directory avoids trying to create it (and logging a permission denied error)
-export LOG_DIR="$KAFKA_HOME"
-
-# Enabling the Mirror Maker agent which monitors readiness / liveness
-rm -f /tmp/mirror-maker-ready /tmp/mirror-maker-alive 2> /dev/null
-KAFKA_OPTS="$KAFKA_OPTS -javaagent:$(ls "$KAFKA_HOME"/libs/mirror-maker-agent*.jar)=/tmp/mirror-maker-ready:/tmp/mirror-maker-alive:${STRIMZI_READINESS_PERIOD:-10}:${STRIMZI_LIVENESS_PERIOD:-10}"
-export KAFKA_OPTS
-
-# enabling Prometheus JMX exporter as Java agent
-if [ "$KAFKA_MIRRORMAKER_METRICS_ENABLED" = "true" ]; then
-  KAFKA_OPTS="$KAFKA_OPTS -javaagent:$(ls "$JMX_EXPORTER_HOME"/jmx_prometheus_javaagent*.jar)=9404:$KAFKA_HOME/custom-config/metrics-config.json"
-  export KAFKA_OPTS
-fi
-
-# Disable FIPS if needed
-if [ "$FIPS_MODE" = "disabled" ]; then
-    export KAFKA_OPTS="${KAFKA_OPTS} -Dcom.redhat.fips=false"
-fi
-
-# enabling Tracing agent (initializes tracing) as Java agent
-if [ "$STRIMZI_TRACING" = "jaeger" ] || [ "$STRIMZI_TRACING" = "opentelemetry" ]; then
-    KAFKA_OPTS="$KAFKA_OPTS -javaagent:$(ls "$KAFKA_HOME"/libs/tracing-agent*.jar)=$STRIMZI_TRACING"
-    export KAFKA_OPTS
-    if [ "$STRIMZI_TRACING" = "opentelemetry" ] && [ -z "$OTEL_TRACES_EXPORTER" ]; then
-      # auto-set OTLP exporter
-      export OTEL_TRACES_EXPORTER="otlp"
-    fi
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_INCLUDE" ]; then
-    # shellcheck disable=SC2089
-    include="--whitelist \"${KAFKA_MIRRORMAKER_INCLUDE}\""
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_NUMSTREAMS" ]; then
-    numstreams="--num.streams ${KAFKA_MIRRORMAKER_NUMSTREAMS}"
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL" ]; then
-    offset_commit_interval="--offset.commit.interval.ms $KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL"
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE" ]; then
-    abort_on_send_failure="--abort.on.send.failure $KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE"
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_MESSAGE_HANDLER" ]; then
-    message_handler="--message.handler $KAFKA_MIRRORMAKER_MESSAGE_HANDLER"
-fi
-
-if [ -n "$KAFKA_MIRRORMAKER_MESSAGE_HANDLER_ARGS" ]; then
-    # shellcheck disable=SC2089
-    message_handler_args="--message.handler.args \"${KAFKA_MIRRORMAKER_MESSAGE_HANDLER_ARGS}\""
-fi
-
-if [ -n "$STRIMZI_JAVA_SYSTEM_PROPERTIES" ]; then
-    export KAFKA_OPTS="${KAFKA_OPTS} ${STRIMZI_JAVA_SYSTEM_PROPERTIES}"
-fi
-
-# Configure heap based on the available resources if needed
-. ./dynamic_resources.sh
-
-# Configure Garbage Collection logging
-. ./set_kafka_gc_options.sh
-
-set -x
-
-# starting Kafka Mirror Maker with final configuration
-# shellcheck disable=SC2086,SC2090
-exec /usr/bin/tini -w -e 143 -- "$KAFKA_HOME"/bin/kafka-mirror-maker.sh \
---consumer.config /tmp/strimzi-consumer.properties \
---producer.config /tmp/strimzi-producer.properties \
-$include \
-$numstreams \
-$offset_commit_interval \
-$abort_on_send_failure \
-$message_handler \
-$message_handler_args
diff --git a/documentation/api/io.strimzi.api.kafka.model.common.ClientTls.adoc b/documentation/api/io.strimzi.api.kafka.model.common.ClientTls.adoc
index 424697fc778..96569ab16a8 100644
--- a/documentation/api/io.strimzi.api.kafka.model.common.ClientTls.adoc
+++ b/documentation/api/io.strimzi.api.kafka.model.common.ClientTls.adoc
@@ -1 +1 @@
-Configures xref:con-common-configuration-trusted-certificates-reference[TLS trusted certificates] for connecting KafkaConnect, KafkaBridge, KafkaMirror, KafkaMirrorMaker2 to the cluster.
+Configures xref:con-common-configuration-trusted-certificates-reference[TLS trusted certificates] for connecting KafkaConnect, KafkaBridge, KafkaMirrorMaker2 to the cluster.
diff --git a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec.adoc b/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec.adoc
deleted file mode 100644
index 4df72ef5d11..00000000000
--- a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec.adoc
+++ /dev/null
@@ -1,67 +0,0 @@
-Configures a MirrorMaker consumer.
-
-[id='property-consumer-streams-{context}']
-= `numStreams`
-
-Use the `consumer.numStreams` property to configure the number of streams for the consumer.
-
-You can increase the throughput in mirroring topics by increasing the number of consumer threads.
-Consumer threads belong to the consumer group specified for Kafka MirrorMaker.
-Topic partitions are assigned across the consumer threads, which consume messages in parallel.
-
-[id='property-consumer-offset-autocommit-{context}']
-= `offsetCommitInterval`
-
-Use the `consumer.offsetCommitInterval` property to configure an offset auto-commit interval for the consumer.
-
-You can specify the regular time interval at which an offset is committed after Kafka MirrorMaker has consumed data from the source Kafka cluster.
-The time interval is set in milliseconds, with a default value of 60,000.
-
-[id='property-consumer-config-{context}']
-= `config`
-
-Use the `consumer.config` properties to configure Kafka options for the consumer as keys.
-
-The values can be one of the following JSON types:
-
-* String
-* Number
-* Boolean
-
-*Exceptions*
-
-You can specify and configure the options listed in the {ApacheKafkaConsumerConfig}.
-
-However, Strimzi takes care of configuring and managing options related to the following, which cannot be changed:
-
-* Kafka cluster bootstrap address
-* Security (encryption, authentication, and authorization)
-* Consumer group identifier
-* Interceptors
-
-Properties with the following prefixes cannot be set:
-
-* `bootstrap.servers`
-* `group.id`
-* `interceptor.classes`
-* `sasl.`
-* `security.`
-* `ssl.`
-
-If the `config` property contains an option that cannot be changed, it is disregarded, and a warning message is logged to the Cluster Operator log file.
-All other supported options are forwarded to MirrorMaker, including the following exceptions to the options configured by Strimzi:
-
-* Any `ssl` configuration for xref:con-common-configuration-ssl-reference[supported TLS versions and cipher suites]
-
-IMPORTANT: The Cluster Operator does not validate keys or values in the `config` object provided.
-If an invalid configuration is provided, the MirrorMaker cluster might not start or might become unstable.
-In this case, fix the configuration so that the Cluster Operator can roll out the new configuration to all MirrorMaker nodes.
-
-[id='property-consumer-group-{context}']
-= `groupId`
-
-Use the `consumer.groupId` property to configure a consumer group identifier for the consumer.
-
-Kafka MirrorMaker uses a Kafka consumer to consume messages, behaving like any other Kafka consumer client.
-Messages consumed from the source Kafka cluster are mirrored to a target Kafka cluster.
-A group identifier is required, as the consumer needs to be part of a consumer group for the assignment of partitions.
diff --git a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec.adoc b/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec.adoc
deleted file mode 100644
index a9069c3b5e3..00000000000
--- a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec.adoc
+++ /dev/null
@@ -1,51 +0,0 @@
-Configures a MirrorMaker producer.
-
-[id='property-producer-abort-on-send-{context}']
-= `abortOnSendFailure`
-
-Use the `producer.abortOnSendFailure` property to configure how to handle message send failure from the producer.
-
-By default, if an error occurs when sending a message from Kafka MirrorMaker to a Kafka cluster:
-
-* The Kafka MirrorMaker container is terminated in Kubernetes.
-* The container is then recreated.
-
-If the `abortOnSendFailure` option is set to `false`, message sending errors are ignored.
-
-[id='property-producer-config-{context}']
-= `config`
-
-Use the `producer.config` properties to configure Kafka options for the producer as keys.
-
-The values can be one of the following JSON types:
-
-* String
-* Number
-* Boolean
-
-*Exceptions*
-
-You can specify and configure the options listed in the {ApacheKafkaProducerConfig}.
-
-However, Strimzi takes care of configuring and managing options related to the following, which cannot be changed:
-
-* Kafka cluster bootstrap address
-* Security (encryption, authentication, and authorization)
-* Interceptors
-
-Properties with the following prefixes cannot be set:
-
-* `bootstrap.servers`
-* `interceptor.classes`
-* `sasl.`
-* `security.`
-* `ssl.`
-
-If the `config` property contains an option that cannot be changed, it is disregarded, and a warning message is logged to the Cluster Operator log file.
-All other supported options are forwarded to MirrorMaker, including the following exceptions to the options configured by Strimzi:
-
-* Any `ssl` configuration for xref:con-common-configuration-ssl-reference[supported TLS versions and cipher suites]
-
-IMPORTANT: The Cluster Operator does not validate keys or values in the `config` object provided.
-If an invalid configuration is provided, the MirrorMaker cluster might not start or might become unstable.
-In this case, fix the configuration so that the Cluster Operator can roll out the new configuration to all MirrorMaker nodes.
diff --git a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec.adoc b/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec.adoc
deleted file mode 100644
index 7b251a91296..00000000000
--- a/documentation/api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec.adoc
+++ /dev/null
@@ -1,74 +0,0 @@
-Configures Kafka MirrorMaker.
-
-[id='property-mm-include-{context}']
-= `include`
-
-Use the `include` property to configure a list of topics that Kafka MirrorMaker mirrors from the source to the target Kafka cluster.
-
-The property allows any regular expression from the simplest case with a single topic name to complex patterns.
-For example, you can mirror topics A and B using `A|B` or all topics using `*`.
-You can also pass multiple regular expressions separated by commas to the Kafka MirrorMaker.
-
-[id='property-mm-producer-consumer-{context}']
-= `KafkaMirrorMakerConsumerSpec` and `KafkaMirrorMakerProducerSpec`
-
-Use the `KafkaMirrorMakerConsumerSpec` and `KafkaMirrorMakerProducerSpec` to configure source (consumer) and target (producer) clusters.
-
-Kafka MirrorMaker always works together with two Kafka clusters (source and target).
-To establish a connection, the bootstrap servers for the source and the target Kafka clusters are specified as comma-separated lists of `_HOSTNAME:PORT_` pairs.
-Each comma-separated list contains one or more Kafka brokers or a `Service` pointing to Kafka brokers specified as a `_HOSTNAME:PORT_` pair.
-
-[id='property-mm-loggers-{context}']
-= `logging`
-
-Kafka MirrorMaker has its own configurable logger:
-
-* `mirrormaker.root.logger`
-
-MirrorMaker uses the Apache `log4j` logger implementation.
-
-Use the `logging` property to configure loggers and logger levels.
-
-You can set the log levels by specifying the logger and level directly (inline) or use a custom (external) ConfigMap.
-If a ConfigMap is used, you set `logging.valueFrom.configMapKeyRef.name` property to the name of the ConfigMap containing the external logging configuration. Inside the ConfigMap, the logging configuration is described using `log4j.properties`. Both `logging.valueFrom.configMapKeyRef.name` and `logging.valueFrom.configMapKeyRef.key` properties are mandatory. A ConfigMap using the exact logging configuration specified is created with the custom resource when the Cluster Operator is running, then recreated after each reconciliation. If you do not specify a custom ConfigMap, default logging settings are used. If a specific logger value is not set, upper-level logger settings are inherited for that logger.
-For more information about log levels, see {ApacheLoggers}.
-
-Here we see examples of `inline` and `external` logging.
-The `inline` logging specifies the root logger level.
-You can also set log levels for specific classes or loggers by adding them to the loggers property.
-
-[source,yaml,subs="+quotes,attributes"]
-----
-apiVersion: {KafkaMirrorMakerApiVersion}
-kind: KafkaMirrorMaker
-spec:
-  # ...
-  logging:
-    type: inline
-    loggers:
-      mirrormaker.root.logger: INFO
-      log4j.logger.org.apache.kafka.clients.NetworkClient: TRACE
-      log4j.logger.org.apache.kafka.common.network.Selector: DEBUG
-  # ...
-----
-
-NOTE: Setting a log level to `DEBUG` may result in a large amount of log output and may have performance implications.
-
-[source,yaml,subs="+quotes,attributes"]
-----
-apiVersion: {KafkaMirrorMakerApiVersion}
-kind: KafkaMirrorMaker
-spec:
-  # ...
-  logging:
-    type: external
-    valueFrom:
-      configMapKeyRef:
-        name: customConfigMap
-        key: mirror-maker-log4j.properties
-  # ...
-----
-
-.Garbage collector (GC)
-
-Garbage collector logging can also be enabled (or disabled) using the xref:con-common-configuration-garbage-collection-reference[`jvmOptions` property].
diff --git a/documentation/assemblies/configuring/assembly-config.adoc b/documentation/assemblies/configuring/assembly-config.adoc
index 5496095304e..3e028a2f5e6 100644
--- a/documentation/assemblies/configuring/assembly-config.adoc
+++ b/documentation/assemblies/configuring/assembly-config.adoc
@@ -166,9 +166,6 @@ include::../../modules/configuring/proc-manual-restart-mirrormaker2-connector.ad
 //Procedure to restart an MM2 connector task
 include::../../modules/configuring/proc-manual-restart-mirrormaker2-connector-task.adoc[leveloffset=+2]
 
-//`KafkaMirrorMaker` resource config
-include::../../modules/configuring/con-config-mirrormaker.adoc[leveloffset=+1]
-
 //`KafkaBridge` resource config
 include::../../modules/configuring/con-config-kafka-bridge.adoc[leveloffset=+1]
 
diff --git a/documentation/modules/appendix_crds.adoc b/documentation/modules/appendix_crds.adoc
index cba2cb4715f..d5dd99dab36 100644
--- a/documentation/modules/appendix_crds.adoc
+++ b/documentation/modules/appendix_crds.adoc
@@ -911,7 +911,7 @@ include::../api/io.strimzi.api.kafka.model.common.Rack.adoc[leveloffset=+1]
 [id='type-Probe-{context}']
 = `Probe` schema reference
 
-Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaExporterSpec-{context}[`KafkaExporterSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`], xref:type-TlsSidecar-{context}[`TlsSidecar`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
+Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaExporterSpec-{context}[`KafkaExporterSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-TlsSidecar-{context}[`TlsSidecar`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
 
 
 [cols="2,2,3a",options="header"]
@@ -937,7 +937,7 @@ Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-E
 [id='type-JvmOptions-{context}']
 = `JvmOptions` schema reference
 
-Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`], xref:type-KafkaNodePoolSpec-{context}[`KafkaNodePoolSpec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
+Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaNodePoolSpec-{context}[`KafkaNodePoolSpec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
 
 
 [cols="2,2,3a",options="header"]
@@ -1017,7 +1017,7 @@ It must have the value `password` for the type `KafkaJmxAuthenticationPassword`.
 [id='type-JmxPrometheusExporterMetrics-{context}']
 = `JmxPrometheusExporterMetrics` schema reference
 
-Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
+Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
 
 
 The `type` property is a discriminator that distinguishes use of the `JmxPrometheusExporterMetrics` type from other subtypes which may be added in the future.
@@ -1050,7 +1050,7 @@ Used in: xref:type-ExternalLogging-{context}[`ExternalLogging`], xref:type-JmxPr
 [id='type-InlineLogging-{context}']
 = `InlineLogging` schema reference
 
-Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
+Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
 
 
 The `type` property is a discriminator that distinguishes use of the `InlineLogging` type from xref:type-ExternalLogging-{context}[`ExternalLogging`].
@@ -1069,7 +1069,7 @@ It must have the value `inline` for the type `InlineLogging`.
 [id='type-ExternalLogging-{context}']
 = `ExternalLogging` schema reference
 
-Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
+Used in: xref:type-CruiseControlSpec-{context}[`CruiseControlSpec`], xref:type-EntityTopicOperatorSpec-{context}[`EntityTopicOperatorSpec`], xref:type-EntityUserOperatorSpec-{context}[`EntityUserOperatorSpec`], xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaClusterSpec-{context}[`KafkaClusterSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-ZookeeperClusterSpec-{context}[`ZookeeperClusterSpec`]
 
 
 The `type` property is a discriminator that distinguishes use of the `ExternalLogging` type from xref:type-InlineLogging-{context}[`InlineLogging`].
@@ -1197,7 +1197,7 @@ include::../api/io.strimzi.api.kafka.model.common.template.MetadataTemplate.adoc
 [id='type-PodTemplate-{context}']
 = `PodTemplate` schema reference
 
-Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
+Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
 
 xref:type-PodTemplate-schema-{context}[Full list of `PodTemplate` schema properties]
 
@@ -1303,7 +1303,7 @@ Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xre
 [id='type-ResourceTemplate-{context}']
 = `ResourceTemplate` schema reference
 
-Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-KafkaUserTemplate-{context}[`KafkaUserTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
+Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-KafkaUserTemplate-{context}[`KafkaUserTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
 
 
 [cols="2,2,3a",options="header"]
@@ -1317,7 +1317,7 @@ Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xre
 [id='type-PodDisruptionBudgetTemplate-{context}']
 = `PodDisruptionBudgetTemplate` schema reference
 
-Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
+Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
 
 xref:type-PodDisruptionBudgetTemplate-schema-{context}[Full list of `PodDisruptionBudgetTemplate` schema properties]
 
@@ -1341,7 +1341,7 @@ include::../api/io.strimzi.api.kafka.model.common.template.PodDisruptionBudgetTe
 [id='type-ContainerTemplate-{context}']
 = `ContainerTemplate` schema reference
 
-Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
+Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaClusterTemplate-{context}[`KafkaClusterTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaNodePoolTemplate-{context}[`KafkaNodePoolTemplate`], xref:type-ZookeeperClusterTemplate-{context}[`ZookeeperClusterTemplate`]
 
 xref:type-ContainerTemplate-schema-{context}[Full list of `ContainerTemplate` schema properties]
 
@@ -1806,7 +1806,7 @@ Used in: xref:type-EntityOperatorSpec-{context}[`EntityOperatorSpec`]
 [id='type-DeploymentTemplate-{context}']
 = `DeploymentTemplate` schema reference
 
-Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`], xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`]
+Used in: xref:type-CruiseControlTemplate-{context}[`CruiseControlTemplate`], xref:type-EntityOperatorTemplate-{context}[`EntityOperatorTemplate`], xref:type-JmxTransTemplate-{context}[`JmxTransTemplate`], xref:type-KafkaBridgeTemplate-{context}[`KafkaBridgeTemplate`], xref:type-KafkaConnectTemplate-{context}[`KafkaConnectTemplate`], xref:type-KafkaExporterTemplate-{context}[`KafkaExporterTemplate`]
 
 xref:type-DeploymentTemplate-schema-{context}[Full list of `DeploymentTemplate` schema properties]
 
@@ -2283,7 +2283,7 @@ Used in: xref:type-Kafka-{context}[`Kafka`]
 [id='type-Condition-{context}']
 = `Condition` schema reference
 
-Used in: xref:type-KafkaBridgeStatus-{context}[`KafkaBridgeStatus`], xref:type-KafkaConnectorStatus-{context}[`KafkaConnectorStatus`], xref:type-KafkaConnectStatus-{context}[`KafkaConnectStatus`], xref:type-KafkaMirrorMaker2Status-{context}[`KafkaMirrorMaker2Status`], xref:type-KafkaMirrorMakerStatus-{context}[`KafkaMirrorMakerStatus`], xref:type-KafkaNodePoolStatus-{context}[`KafkaNodePoolStatus`], xref:type-KafkaRebalanceStatus-{context}[`KafkaRebalanceStatus`], xref:type-KafkaStatus-{context}[`KafkaStatus`], xref:type-KafkaTopicStatus-{context}[`KafkaTopicStatus`], xref:type-KafkaUserStatus-{context}[`KafkaUserStatus`], xref:type-StrimziPodSetStatus-{context}[`StrimziPodSetStatus`]
+Used in: xref:type-KafkaBridgeStatus-{context}[`KafkaBridgeStatus`], xref:type-KafkaConnectorStatus-{context}[`KafkaConnectorStatus`], xref:type-KafkaConnectStatus-{context}[`KafkaConnectStatus`], xref:type-KafkaMirrorMaker2Status-{context}[`KafkaMirrorMaker2Status`], xref:type-KafkaNodePoolStatus-{context}[`KafkaNodePoolStatus`], xref:type-KafkaRebalanceStatus-{context}[`KafkaRebalanceStatus`], xref:type-KafkaStatus-{context}[`KafkaStatus`], xref:type-KafkaTopicStatus-{context}[`KafkaTopicStatus`], xref:type-KafkaUserStatus-{context}[`KafkaUserStatus`], xref:type-StrimziPodSetStatus-{context}[`StrimziPodSetStatus`]
 
 
 [cols="2,2,3a",options="header"]
@@ -2509,7 +2509,7 @@ include::../api/io.strimzi.api.kafka.model.connect.KafkaConnectSpec.adoc[levelof
 [id='type-ClientTls-{context}']
 = `ClientTls` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-ClientTls-schema-{context}[Full list of `ClientTls` schema properties]
 
@@ -2530,7 +2530,7 @@ include::../api/io.strimzi.api.kafka.model.common.ClientTls.adoc[leveloffset=+1]
 [id='type-KafkaClientAuthenticationTls-{context}']
 = `KafkaClientAuthenticationTls` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-KafkaClientAuthenticationTls-schema-{context}[Full list of `KafkaClientAuthenticationTls` schema properties]
 
@@ -2556,7 +2556,7 @@ It must have the value `tls` for the type `KafkaClientAuthenticationTls`.
 [id='type-KafkaClientAuthenticationScramSha256-{context}']
 = `KafkaClientAuthenticationScramSha256` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-KafkaClientAuthenticationScramSha256-schema-{context}[Full list of `KafkaClientAuthenticationScramSha256` schema properties]
 
@@ -2600,7 +2600,7 @@ Used in: xref:type-KafkaClientAuthenticationOAuth-{context}[`KafkaClientAuthenti
 [id='type-KafkaClientAuthenticationScramSha512-{context}']
 = `KafkaClientAuthenticationScramSha512` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-KafkaClientAuthenticationScramSha512-schema-{context}[Full list of `KafkaClientAuthenticationScramSha512` schema properties]
 
@@ -2627,7 +2627,7 @@ include::../api/io.strimzi.api.kafka.model.common.authentication.KafkaClientAuth
 [id='type-KafkaClientAuthenticationPlain-{context}']
 = `KafkaClientAuthenticationPlain` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-KafkaClientAuthenticationPlain-schema-{context}[Full list of `KafkaClientAuthenticationPlain` schema properties]
 
@@ -2656,7 +2656,7 @@ It must have the value `plain` for the type `KafkaClientAuthenticationPlain`.
 [id='type-KafkaClientAuthenticationOAuth-{context}']
 = `KafkaClientAuthenticationOAuth` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`], xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`], xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2ClusterSpec-{context}[`KafkaMirrorMaker2ClusterSpec`]
 
 xref:type-KafkaClientAuthenticationOAuth-schema-{context}[Full list of `KafkaClientAuthenticationOAuth` schema properties]
 
@@ -2753,7 +2753,7 @@ It must have the value `oauth` for the type `KafkaClientAuthenticationOAuth`.
 
 *The type `JaegerTracing` has been deprecated.*
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`]
 
 
 The `type` property is a discriminator that distinguishes use of the `JaegerTracing` type from xref:type-OpenTelemetryTracing-{context}[`OpenTelemetryTracing`].
@@ -2769,7 +2769,7 @@ It must have the value `jaeger` for the type `JaegerTracing`.
 [id='type-OpenTelemetryTracing-{context}']
 = `OpenTelemetryTracing` schema reference
 
-Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`], xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
+Used in: xref:type-KafkaBridgeSpec-{context}[`KafkaBridgeSpec`], xref:type-KafkaConnectSpec-{context}[`KafkaConnectSpec`], xref:type-KafkaMirrorMaker2Spec-{context}[`KafkaMirrorMaker2Spec`]
 
 
 The `type` property is a discriminator that distinguishes use of the `OpenTelemetryTracing` type from xref:type-JaegerTracing-{context}[`JaegerTracing`].
@@ -3610,208 +3610,6 @@ Used in: xref:type-KafkaUser-{context}[`KafkaUser`]
 |The name of `Secret` where the credentials are stored.
 |====
 
-[id='type-KafkaMirrorMaker-{context}']
-= `KafkaMirrorMaker` schema reference
-
-*The type `KafkaMirrorMaker` has been deprecated.*
-Please use xref:type-KafkaMirrorMaker2-{context}[`KafkaMirrorMaker2`] instead.
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|spec
-|xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
-|The specification of Kafka MirrorMaker.
-|status
-|xref:type-KafkaMirrorMakerStatus-{context}[`KafkaMirrorMakerStatus`]
-|The status of Kafka MirrorMaker.
-|====
-
-[id='type-KafkaMirrorMakerSpec-{context}']
-= `KafkaMirrorMakerSpec` schema reference
-
-Used in: xref:type-KafkaMirrorMaker-{context}[`KafkaMirrorMaker`]
-
-xref:type-KafkaMirrorMakerSpec-schema-{context}[Full list of `KafkaMirrorMakerSpec` schema properties]
-
-include::../api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerSpec.adoc[leveloffset=+1]
-
-[id='type-KafkaMirrorMakerSpec-schema-{context}']
-== `KafkaMirrorMakerSpec` schema properties
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|version
-|string
-|The Kafka MirrorMaker version. Defaults to the latest version. Consult the documentation to understand the process required to upgrade or downgrade the version.
-|replicas
-|integer
-|The number of pods in the `Deployment`.
-|image
-|string
-|The container image used for Kafka MirrorMaker pods. If no image name is explicitly specified, it is determined based on the `spec.version` configuration. The image names are specifically mapped to corresponding versions in the Cluster Operator configuration.
-|consumer
-|xref:type-KafkaMirrorMakerConsumerSpec-{context}[`KafkaMirrorMakerConsumerSpec`]
-|Configuration of source cluster.
-|producer
-|xref:type-KafkaMirrorMakerProducerSpec-{context}[`KafkaMirrorMakerProducerSpec`]
-|Configuration of target cluster.
-|resources
-|https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core[ResourceRequirements]
-|CPU and memory resources to reserve.
-|whitelist
-|string
-|**The `whitelist` property has been deprecated, and should now be configured using `spec.include`.** List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas.
-|include
-|string
-|List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas.
-|jvmOptions
-|xref:type-JvmOptions-{context}[`JvmOptions`]
-|JVM Options for pods.
-|logging
-|xref:type-InlineLogging-{context}[`InlineLogging`], xref:type-ExternalLogging-{context}[`ExternalLogging`]
-|Logging configuration for MirrorMaker.
-|metricsConfig
-|xref:type-JmxPrometheusExporterMetrics-{context}[`JmxPrometheusExporterMetrics`]
-|Metrics configuration.
-|tracing
-|xref:type-JaegerTracing-{context}[`JaegerTracing`], xref:type-OpenTelemetryTracing-{context}[`OpenTelemetryTracing`]
-|The configuration of tracing in Kafka MirrorMaker.
-|template
-|xref:type-KafkaMirrorMakerTemplate-{context}[`KafkaMirrorMakerTemplate`]
-|Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.
-|livenessProbe
-|xref:type-Probe-{context}[`Probe`]
-|Pod liveness checking.
-|readinessProbe
-|xref:type-Probe-{context}[`Probe`]
-|Pod readiness checking.
-|====
-
-[id='type-KafkaMirrorMakerConsumerSpec-{context}']
-= `KafkaMirrorMakerConsumerSpec` schema reference
-
-Used in: xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
-
-xref:type-KafkaMirrorMakerConsumerSpec-schema-{context}[Full list of `KafkaMirrorMakerConsumerSpec` schema properties]
-
-include::../api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerConsumerSpec.adoc[leveloffset=+1]
-
-[id='type-KafkaMirrorMakerConsumerSpec-schema-{context}']
-== `KafkaMirrorMakerConsumerSpec` schema properties
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|numStreams
-|integer
-|Specifies the number of consumer stream threads to create.
-|offsetCommitInterval
-|integer
-|Specifies the offset auto-commit interval in ms. Default value is 60000.
-|bootstrapServers
-|string
-|A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-|groupId
-|string
-|A unique string that identifies the consumer group this consumer belongs to.
-|authentication
-|xref:type-KafkaClientAuthenticationTls-{context}[`KafkaClientAuthenticationTls`], xref:type-KafkaClientAuthenticationScramSha256-{context}[`KafkaClientAuthenticationScramSha256`], xref:type-KafkaClientAuthenticationScramSha512-{context}[`KafkaClientAuthenticationScramSha512`], xref:type-KafkaClientAuthenticationPlain-{context}[`KafkaClientAuthenticationPlain`], xref:type-KafkaClientAuthenticationOAuth-{context}[`KafkaClientAuthenticationOAuth`]
-|Authentication configuration for connecting to the cluster.
-|tls
-|xref:type-ClientTls-{context}[`ClientTls`]
-|TLS configuration for connecting MirrorMaker to the cluster.
-|config
-|map
-|The MirrorMaker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
-|====
-
-[id='type-KafkaMirrorMakerProducerSpec-{context}']
-= `KafkaMirrorMakerProducerSpec` schema reference
-
-Used in: xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
-
-xref:type-KafkaMirrorMakerProducerSpec-schema-{context}[Full list of `KafkaMirrorMakerProducerSpec` schema properties]
-
-include::../api/io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerProducerSpec.adoc[leveloffset=+1]
-
-[id='type-KafkaMirrorMakerProducerSpec-schema-{context}']
-== `KafkaMirrorMakerProducerSpec` schema properties
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|bootstrapServers
-|string
-|A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-|abortOnSendFailure
-|boolean
-|Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.
-|authentication
-|xref:type-KafkaClientAuthenticationTls-{context}[`KafkaClientAuthenticationTls`], xref:type-KafkaClientAuthenticationScramSha256-{context}[`KafkaClientAuthenticationScramSha256`], xref:type-KafkaClientAuthenticationScramSha512-{context}[`KafkaClientAuthenticationScramSha512`], xref:type-KafkaClientAuthenticationPlain-{context}[`KafkaClientAuthenticationPlain`], xref:type-KafkaClientAuthenticationOAuth-{context}[`KafkaClientAuthenticationOAuth`]
-|Authentication configuration for connecting to the cluster.
-|config
-|map
-|The MirrorMaker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
-|tls
-|xref:type-ClientTls-{context}[`ClientTls`]
-|TLS configuration for connecting MirrorMaker to the cluster.
-|====
-
-[id='type-KafkaMirrorMakerTemplate-{context}']
-= `KafkaMirrorMakerTemplate` schema reference
-
-Used in: xref:type-KafkaMirrorMakerSpec-{context}[`KafkaMirrorMakerSpec`]
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|deployment
-|xref:type-DeploymentTemplate-{context}[`DeploymentTemplate`]
-|Template for Kafka MirrorMaker `Deployment`.
-|pod
-|xref:type-PodTemplate-{context}[`PodTemplate`]
-|Template for Kafka MirrorMaker `Pods`.
-|podDisruptionBudget
-|xref:type-PodDisruptionBudgetTemplate-{context}[`PodDisruptionBudgetTemplate`]
-|Template for Kafka MirrorMaker `PodDisruptionBudget`.
-|mirrorMakerContainer
-|xref:type-ContainerTemplate-{context}[`ContainerTemplate`]
-|Template for Kafka MirrorMaker container.
-|serviceAccount
-|xref:type-ResourceTemplate-{context}[`ResourceTemplate`]
-|Template for the Kafka MirrorMaker service account.
-|====
-
-[id='type-KafkaMirrorMakerStatus-{context}']
-= `KafkaMirrorMakerStatus` schema reference
-
-Used in: xref:type-KafkaMirrorMaker-{context}[`KafkaMirrorMaker`]
-
-
-[cols="2,2,3a",options="header"]
-|====
-|Property |Property type |Description
-|conditions
-|xref:type-Condition-{context}[`Condition`] array
-|List of status conditions.
-|observedGeneration
-|integer
-|The generation of the CRD that was last reconciled by the operator.
-|labelSelector
-|string
-|Label selector for pods providing this resource.
-|replicas
-|integer
-|The current number of pods being used to provide this resource.
-|====
-
 [id='type-KafkaBridge-{context}']
 = `KafkaBridge` schema reference
 
diff --git a/documentation/modules/con-common-configuration-properties.adoc b/documentation/modules/con-common-configuration-properties.adoc
index 6fa7254c0f6..b1a655ce9bb 100644
--- a/documentation/modules/con-common-configuration-properties.adoc
+++ b/documentation/modules/con-common-configuration-properties.adoc
@@ -55,7 +55,7 @@ The combination is encapsulated in the `TLS_AES_256_GCM_SHA384` cipher suite spe
 
 The `ssl.enabled.protocols` property specifies the available TLS versions that can be used for secure communication between the cluster and its clients. 
 The `ssl.protocol` property sets the default TLS version for all connections, and it must be chosen from the enabled protocols.
-Use the `ssl.endpoint.identification.algorithm` property to enable or disable hostname verification (configurable only in components based on Kafka clients - Kafka Connect, MirrorMaker 1/2, and Kafka Bridge).
+Use the `ssl.endpoint.identification.algorithm` property to enable or disable hostname verification (configurable only in components based on Kafka clients - Kafka Connect, MirrorMaker 2, and Kafka Bridge).
 
 .Example SSL configuration
 [source,yaml,subs="attributes+"]
@@ -310,7 +310,6 @@ You can specify which container image to use for a component using the `image` p
 * `Kafka.spec.kafkaExporter`
 * `Kafka.spec.kafkaBridge`
 * `KafkaConnect.spec`
-* `KafkaMirrorMaker.spec`
 * `KafkaMirrorMaker2.spec`
 * `KafkaBridge.spec`
 
@@ -519,7 +518,6 @@ To optimize their performance on different platforms and architectures, you conf
 * `Kafka.spec.cruiseControl`
 * `KafkaNodePool.spec`
 * `KafkaConnect.spec`
-* `KafkaMirrorMaker.spec`
 * `KafkaMirrorMaker2.spec`
 * `KafkaBridge.spec`
 
diff --git a/documentation/modules/configuring/con-config-examples.adoc b/documentation/modules/configuring/con-config-examples.adoc
index f200969cd60..6af62b896fe 100644
--- a/documentation/modules/configuring/con-config-examples.adoc
+++ b/documentation/modules/configuring/con-config-examples.adoc
@@ -42,7 +42,7 @@ examples
 <1> `KafkaUser` custom resource configuration, which is managed by the User Operator.
 <2> `KafkaTopic` custom resource configuration, which is managed by Topic Operator.
 <3> Authentication and authorization configuration for Kafka components. Includes example configuration for TLS and SCRAM-SHA-512 authentication. The Keycloak example includes `Kafka` custom resource configuration and a Keycloak realm specification. You can use the example to try Keycloak authorization services. There is also an example with enabled `oauth` authentication and `keycloak` authorization metrics.
-<4> `KafkaMirrorMaker` and `KafkaMirrorMaker2` custom resource configurations for a deployment of MirrorMaker. Includes example configuration for replication policy and synchronization frequency.
+<4> `KafkaMirrorMaker2` custom resource configurations for a deployment of MirrorMaker 2. Includes example configuration for replication policy and synchronization frequency.
 <5> xref:assembly-metrics-config-files-{context}[Metrics configuration], including Prometheus installation and Grafana dashboard files.
 <6> `Kafka` and `KafkaNodePool` custom resource configurations for a deployment of Kafka clusters that use ZooKeeper mode. Includes example configuration for an ephemeral or persistent single or multi-node deployment.
 <7> `Kafka` and `KafkaNodePool` configurations for a deployment of Kafka clusters that use KRaft (Kafka Raft metadata) mode.
diff --git a/documentation/modules/configuring/con-config-mirrormaker.adoc b/documentation/modules/configuring/con-config-mirrormaker.adoc
deleted file mode 100644
index 5e943b0fff0..00000000000
--- a/documentation/modules/configuring/con-config-mirrormaker.adoc
+++ /dev/null
@@ -1,134 +0,0 @@
-// Module included in the following assemblies:
-//
-// assembly-config.adoc
-
-[id='con-config-mirrormaker-{context}']
-= Configuring Kafka MirrorMaker (deprecated)
-
-[role="_abstract"]
-Update the `spec` properties of the `KafkaMirrorMaker` custom resource to configure your Kafka MirrorMaker deployment.
-
-You can configure access control for producers and consumers using TLS or SASL authentication.
-This procedure shows a configuration that uses TLS encryption and mTLS authentication on the consumer and producer side.
-
-For a deeper understanding of the Kafka MirrorMaker cluster configuration options, refer to the link:{BookURLConfiguring}[Strimzi Custom Resource API Reference^].
-
-IMPORTANT: Kafka MirrorMaker 1 (referred to as just _MirrorMaker_ in the documentation) has been deprecated in Apache Kafka 3.0.0 and will be removed in Apache Kafka 4.0.0.  
-As a result, the `KafkaMirrorMaker` custom resource which is used to deploy Kafka MirrorMaker 1 has been deprecated in Strimzi as well.
-The `KafkaMirrorMaker` resource will be removed from Strimzi when we adopt Apache Kafka 4.0.0.
-As a replacement, use the `KafkaMirrorMaker2` custom resource with the xref:unidirectional_replication_activepassive[`IdentityReplicationPolicy`].
-
-.Example `KafkaMirrorMaker` custom resource configuration
-[source,yaml,subs="+attributes"]
-----
-apiVersion: {KafkaMirrorMakerApiVersion}
-kind: KafkaMirrorMaker
-metadata:
-  name: my-mirror-maker
-spec:
-  replicas: 3 # <1>
-  consumer:
-    bootstrapServers: my-source-cluster-kafka-bootstrap:9092 # <2>
-    groupId: "my-group" # <3>
-    numStreams: 2 # <4>
-    offsetCommitInterval: 120000 # <5>
-    tls: # <6>
-      trustedCertificates:
-        - secretName: my-source-cluster-ca-cert
-          pattern: "*.crt"
-    authentication: # <7>
-      type: tls
-      certificateAndKey:
-        secretName: my-source-secret
-        certificate: public.crt
-        key: private.key
-    config: # <8>
-      max.poll.records: 100
-      receive.buffer.bytes: 32768
-  producer:
-    bootstrapServers: my-target-cluster-kafka-bootstrap:9092
-    abortOnSendFailure: false # <9>
-    tls:
-      trustedCertificates:
-        - secretName: my-target-cluster-ca-cert
-          pattern: "*.crt"
-    authentication:
-      type: tls
-      certificateAndKey:
-        secretName: my-target-secret
-        certificate: public.crt
-        key: private.key
-    config:
-      compression.type: gzip
-      batch.size: 8192
-  include: "my-topic|other-topic" # <10>
-  resources: # <11>
-    requests:
-      cpu: "1"
-      memory: 2Gi
-    limits:
-      cpu: "2"
-      memory: 2Gi
-  logging: # <12>
-    type: inline
-    loggers:
-      mirrormaker.root.logger: INFO
-  readinessProbe: # <13>
-    initialDelaySeconds: 15
-    timeoutSeconds: 5
-  livenessProbe:
-    initialDelaySeconds: 15
-    timeoutSeconds: 5
-  metricsConfig: # <14>
-   type: jmxPrometheusExporter
-   valueFrom:
-     configMapKeyRef:
-       name: my-config-map
-       key: my-key
-  jvmOptions: # <15>
-    "-Xmx": "1g"
-    "-Xms": "1g"
-  image: my-org/my-image:latest # <16>
-  template: # <17>
-    pod:
-      affinity:
-        podAntiAffinity:
-          requiredDuringSchedulingIgnoredDuringExecution:
-            - labelSelector:
-                matchExpressions:
-                  - key: application
-                    operator: In
-                    values:
-                      - postgresql
-                      - mongodb
-              topologyKey: "kubernetes.io/hostname"
-    mirrorMakerContainer: # <18>
-      env:
-        - name: OTEL_SERVICE_NAME
-          value: my-otel-service
-        - name: OTEL_EXPORTER_OTLP_ENDPOINT
-          value: "http://otlp-host:4317"
-  tracing: # <19>
-    type: opentelemetry
-----
-<1> The number of replica nodes.
-<2> Bootstrap servers for consumer and producer.
-<3> Group ID for the consumer.
-<4> The number of consumer streams.
-<5> The offset auto-commit interval in milliseconds.
-<6> TLS configuration for encrypted connections to the Kafka cluster, with trusted certificates stored in X.509 format within the specified secrets.
-<7> Authentication for consumer or producer, specified as mTLS, token-based OAuth, SASL-based SCRAM-SHA-256/SCRAM-SHA-512, or PLAIN.
-<8> Kafka configuration options for consumer and producer.
-<9> If the `abortOnSendFailure` property is set to `true`, Kafka MirrorMaker will exit and the container will restart following a send failure for a message.
-<10> A list of included topics mirrored from source to target Kafka cluster.
-<11> Requests for reservation of supported resources, currently `cpu` and `memory`, and limits to specify the maximum resources that can be consumed.
-<12> Specified loggers and log levels added directly (`inline`) or indirectly (`external`) through a ConfigMap. A custom Log4j configuration must be placed under the `log4j.properties` or `log4j2.properties` key in the ConfigMap. MirrorMaker has a single logger called `mirrormaker.root.logger`. You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF.
-<13> Healthchecks to know when to restart a container (liveness) and when a container can accept traffic (readiness).
-<14> Prometheus metrics, which are enabled by referencing a ConfigMap containing configuration for the Prometheus JMX exporter in this example. You can enable metrics without further configuration using a reference to a ConfigMap containing an empty file under `metricsConfig.valueFrom.configMapKeyRef.key`.
-<15> JVM configuration options to optimize performance for the Virtual Machine (VM) running Kafka MirrorMaker.
-<16> ADVANCED OPTION: Container image configuration, which is recommended only in special situations.
-<17> Template customization. Here a pod is scheduled with anti-affinity, so the pod is not scheduled on nodes with the same hostname.
-<18> Environment variables are set for distributed tracing.
-<19> Distributed tracing is enabled by using OpenTelemetry.
-+
-WARNING: With the `abortOnSendFailure` property set to `false`, the producer attempts to send the next message in a topic. The original message might be lost, as there is no attempt to resend a failed message.
\ No newline at end of file
diff --git a/documentation/modules/configuring/ref-affinity.adoc b/documentation/modules/configuring/ref-affinity.adoc
index b0f2275eb40..0812ad8ae4d 100644
--- a/documentation/modules/configuring/ref-affinity.adoc
+++ b/documentation/modules/configuring/ref-affinity.adoc
@@ -13,7 +13,6 @@ Affinity, tolerations and topology spread constraints are configured using the `
 * `Kafka.spec.entityOperator.template.pod`
 * `KafkaConnect.spec.template.pod`
 * `KafkaBridge.spec.template.pod`
-* `KafkaMirrorMaker.spec.template.pod`
 * `KafkaMirrorMaker2.spec.template.pod`
 
 The format of the `affinity`, `tolerations`, and `topologySpreadConstraint` properties follows the Kubernetes specification.
diff --git a/documentation/modules/deploying/con-deploy-cluster-operator-watch-options.adoc b/documentation/modules/deploying/con-deploy-cluster-operator-watch-options.adoc
index 5e3feaf7e22..f0ee608519b 100644
--- a/documentation/modules/deploying/con-deploy-cluster-operator-watch-options.adoc
+++ b/documentation/modules/deploying/con-deploy-cluster-operator-watch-options.adoc
@@ -24,7 +24,6 @@ The Cluster Operator watches for changes to the following resources:
 * `Kafka` for the Kafka cluster.
 * `KafkaConnect` for the Kafka Connect cluster.
 * `KafkaConnector` for creating and managing connectors in a Kafka Connect cluster.
-* `KafkaMirrorMaker` for the Kafka MirrorMaker instance.
 * `KafkaMirrorMaker2` for the Kafka MirrorMaker 2 instance.
 * `KafkaBridge` for the Kafka Bridge instance.
 * `KafkaRebalance` for the Cruise Control optimization requests.
diff --git a/documentation/modules/deploying/proc-deploy-kafka-mirror-maker.adoc b/documentation/modules/deploying/proc-deploy-kafka-mirror-maker.adoc
index afeb25fe571..f8294c2a63a 100644
--- a/documentation/modules/deploying/proc-deploy-kafka-mirror-maker.adoc
+++ b/documentation/modules/deploying/proc-deploy-kafka-mirror-maker.adoc
@@ -8,18 +8,12 @@
 [role="_abstract"]
 This procedure shows how to deploy a Kafka MirrorMaker cluster to your Kubernetes cluster using the Cluster Operator.
 
-The deployment uses a YAML file to provide the specification to create a `KafkaMirrorMaker` or `KafkaMirrorMaker2` resource depending on the version of MirrorMaker deployed.
+The deployment uses a YAML file to provide the specification to create a `KafkaMirrorMaker2` resource.
 MirrorMaker 2 is based on Kafka Connect and uses its configuration properties. 
 
-IMPORTANT: Kafka MirrorMaker 1 (referred to as just _MirrorMaker_ in the documentation) has been deprecated in Apache Kafka 3.0.0 and will be removed in Apache Kafka 4.0.0.
-As a result, the `KafkaMirrorMaker` custom resource which is used to deploy Kafka MirrorMaker 1 has been deprecated in Strimzi as well.
-The `KafkaMirrorMaker` resource will be removed from Strimzi when we adopt Apache Kafka 4.0.0.
-As a replacement, use the `KafkaMirrorMaker2` custom resource with the xref:unidirectional_replication_activepassive[`IdentityReplicationPolicy`].
-
 Strimzi provides xref:config-examples-{context}[example configuration files].
-In this procedure, we use the following example files:
+In this procedure, we use the following example file:
 
-* `examples/mirror-maker/kafka-mirror-maker.yaml`
 * `examples/mirror-maker/kafka-mirror-maker-2.yaml`
 
 IMPORTANT: If deploying MirrorMaker 2 clusters to run in parallel, using the same target Kafka cluster, each instance must use unique names for internal Kafka Connect topics. 
@@ -33,15 +27,6 @@ To do this, xref:con-config-mm2-multiple-instances-{context}[configure each Mirr
 
 . Deploy Kafka MirrorMaker to your Kubernetes cluster:
 +
-For MirrorMaker:
-+
-[source,shell,subs="attributes+"]
-----
-kubectl apply -f examples/mirror-maker/kafka-mirror-maker.yaml
-----
-+
-For MirrorMaker 2:
-+
 [source,shell,subs="attributes+"]
 ----
 kubectl apply -f examples/mirror-maker/kafka-mirror-maker-2.yaml
@@ -58,16 +43,14 @@ kubectl get pods -n _<my_cluster_operator_namespace>_
 [source,shell,subs="+quotes"]
 ----
 NAME                                    READY  STATUS   RESTARTS
-my-mirror-maker-mirror-maker-<pod_id>   1/1    Running  1
 my-mm2-cluster-mirrormaker2-<pod_id>    1/1    Running  1
 ----
 +
-`my-mirror-maker` is the name of the Kafka MirrorMaker cluster. 
 `my-mm2-cluster` is the name of the Kafka MirrorMaker 2 cluster.
 +
 A pod ID identifies each pod created.
 +
-With the default deployment, you install a single MirrorMaker or MirrorMaker 2 pod.
+With the default deployment, you install a single MirrorMaker 2 pod.
 +
 `READY` shows the number of replicas that are ready/expected.
 The deployment is successful when the `STATUS` displays as `Running`.
@@ -75,4 +58,4 @@ The deployment is successful when the `STATUS` displays as `Running`.
 [role="_additional-resources"]
 .Additional resources
 
-* xref:con-config-mirrormaker-str[Kafka MirrorMaker cluster configuration]
+* xref:con-config-mirrormaker2-str[Kafka MirrorMaker cluster configuration]
diff --git a/documentation/modules/managing/con-custom-resources-info.adoc b/documentation/modules/managing/con-custom-resources-info.adoc
index 4dcd3570d38..4cebc949b78 100644
--- a/documentation/modules/managing/con-custom-resources-info.adoc
+++ b/documentation/modules/managing/con-custom-resources-info.adoc
@@ -38,7 +38,6 @@ m|Strimzi resource      |Long name          |Short name
 | Kafka User            | kafkauser         | ku
 | Kafka Connect         | kafkaconnect      | kc
 | Kafka Connector       | kafkaconnector    | kctr
-| Kafka MirrorMaker     | kafkamirrormaker  | kmm
 | Kafka MirrorMaker 2   | kafkamirrormaker2 | kmm2
 | Kafka Bridge          | kafkabridge       | kb
 | Kafka Rebalance       | kafkarebalance    | kr
diff --git a/documentation/modules/managing/con-custom-resources-status.adoc b/documentation/modules/managing/con-custom-resources-status.adoc
index 897183777ab..2d2df9552a3 100644
--- a/documentation/modules/managing/con-custom-resources-status.adoc
+++ b/documentation/modules/managing/con-custom-resources-status.adoc
@@ -51,10 +51,6 @@ KafkaAutoRebalanceStatus
 KafkaMirrorMaker2Status
 The Kafka MirrorMaker 2 cluster and internal connectors
 
-KafkaMirrorMaker
-KafkaMirrorMakerStatus
-The Kafka MirrorMaker cluster
-
 KafkaBridge
 KafkaBridgeStatus
 The Kafka Bridge
diff --git a/documentation/modules/snip-images.adoc b/documentation/modules/snip-images.adoc
index e6a750569c3..7930b620380 100644
--- a/documentation/modules/snip-images.adoc
+++ b/documentation/modules/snip-images.adoc
@@ -15,7 +15,7 @@ Strimzi image for running Kafka, including:
 
 * Kafka Broker
 * Kafka Connect
-* Kafka MirrorMaker
+* Kafka MirrorMaker 2
 * ZooKeeper
 * Cruise Control
 
diff --git a/documentation/modules/tracing/proc-enabling-tracing-in-connect-mirror-maker-bridge-resources.adoc b/documentation/modules/tracing/proc-enabling-tracing-in-connect-mirror-maker-bridge-resources.adoc
index bb4d9eedf67..74c8028fdcc 100644
--- a/documentation/modules/tracing/proc-enabling-tracing-in-connect-mirror-maker-bridge-resources.adoc
+++ b/documentation/modules/tracing/proc-enabling-tracing-in-connect-mirror-maker-bridge-resources.adoc
@@ -26,9 +26,9 @@ Enabling tracing in a resource triggers the following events:
 
 * For the Kafka Bridge, a tracer based on the tracing configuration defined in the resource is initialized by the Kafka Bridge itself.
 
-.Tracing in MirrorMaker and MirrorMaker 2
+.Tracing in MirrorMaker 2
 
-For MirrorMaker and MirrorMaker 2, messages are traced from the source cluster to the target cluster. The trace data records messages entering and leaving the MirrorMaker or MirrorMaker 2 component.
+For MirrorMaker 2, messages are traced from the source cluster to the target cluster. The trace data records messages entering and leaving the MirrorMaker 2 component.
 
 .Tracing in Kafka Connect
 
@@ -41,7 +41,7 @@ To have end-to-end tracing, you must configure tracing in your HTTP clients.
 
 .Procedure
 
-Perform these steps for each `KafkaMirrorMaker`, `KafkaMirrorMaker2`, `KafkaConnect`, and `KafkaBridge` resource.
+Perform these steps for each `KafkaMirrorMaker2`, `KafkaConnect`, and `KafkaBridge` resource.
 
 . In the `spec.template` property, configure the tracer service.
 +
@@ -72,27 +72,6 @@ spec:
   #...
 ----
 
-.Example tracing configuration for MirrorMaker using OpenTelemetry
-[source,yaml,subs=attributes+]
-----
-apiVersion: {KafkaMirrorMakerApiVersion}
-kind: KafkaMirrorMaker
-metadata:
-  name: my-mirror-maker
-spec:
-  #...
-  template:
-    mirrorMakerContainer:
-      env:
-        - name: OTEL_SERVICE_NAME
-          value: my-otel-service
-        - name: OTEL_EXPORTER_OTLP_ENDPOINT
-          value: "http://otlp-host:4317"
-  tracing:
-    type: opentelemetry
-#...
-----
-
 .Example tracing configuration for MirrorMaker 2 using OpenTelemetry
 [source,yaml,subs=attributes+]
 ----
diff --git a/documentation/modules/upgrading/proc-upgrade-kafka-kraft.adoc b/documentation/modules/upgrading/proc-upgrade-kafka-kraft.adoc
index b28d9cd8e5d..7f040429dc7 100644
--- a/documentation/modules/upgrading/proc-upgrade-kafka-kraft.adoc
+++ b/documentation/modules/upgrading/proc-upgrade-kafka-kraft.adoc
@@ -92,7 +92,6 @@ The rolling updates ensure that each pod is using the broker binaries for the ne
 . If required, set the `version` property for Kafka Connect and MirrorMaker as the new version of Kafka:
 +
 .. For Kafka Connect, update `KafkaConnect.spec.version`.
-.. For MirrorMaker, update `KafkaMirrorMaker.spec.version`.
 .. For MirrorMaker 2, update `KafkaMirrorMaker2.spec.version`.
 +
 NOTE: If you are using custom images that are built manually, you must rebuild those images to ensure that they are up-to-date with the latest Strimzi base image. 
diff --git a/documentation/shared/attributes.adoc b/documentation/shared/attributes.adoc
index e8f2dfd53e6..cc5f8bff592 100644
--- a/documentation/shared/attributes.adoc
+++ b/documentation/shared/attributes.adoc
@@ -164,7 +164,6 @@
 :KafkaConnectorApiVersion: kafka.strimzi.io/v1beta2
 :KafkaTopicApiVersion: kafka.strimzi.io/v1beta2
 :KafkaUserApiVersion: kafka.strimzi.io/v1beta2
-:KafkaMirrorMakerApiVersion: kafka.strimzi.io/v1beta2
 :KafkaMirrorMaker2ApiVersion: kafka.strimzi.io/v1beta2
 :KafkaRebalanceApiVersion: kafka.strimzi.io/v1beta2
 :KafkaBridgeApiVersion: kafka.strimzi.io/v1beta2
diff --git a/documentation/snip-images.sh b/documentation/snip-images.sh
index 5e209784f50..2fab68cbf9c 100755
--- a/documentation/snip-images.sh
+++ b/documentation/snip-images.sh
@@ -32,7 +32,7 @@ Strimzi image for running Kafka, including:
 
 * Kafka Broker
 * Kafka Connect
-* Kafka MirrorMaker
+* Kafka MirrorMaker 2
 * ZooKeeper
 * Cruise Control
 
diff --git a/mirror-maker-agent/Makefile b/mirror-maker-agent/Makefile
deleted file mode 100644
index 420eb5d5d38..00000000000
--- a/mirror-maker-agent/Makefile
+++ /dev/null
@@ -1,11 +0,0 @@
-PROJECT_NAME=mirror-maker-agent
-
-docker_build: java_install
-docker_push:
-docker_tag:
-all: docker_build docker_push
-clean: java_clean
-
-include ../Makefile.maven
-
-.PHONY: build clean release
diff --git a/mirror-maker-agent/pom.xml b/mirror-maker-agent/pom.xml
deleted file mode 100644
index 99f08a52f1b..00000000000
--- a/mirror-maker-agent/pom.xml
+++ /dev/null
@@ -1,61 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
-    <parent>
-        <artifactId>strimzi</artifactId>
-        <groupId>io.strimzi</groupId>
-        <version>0.46.0-SNAPSHOT</version>
-    </parent>
-    <modelVersion>4.0.0</modelVersion>
-
-    <artifactId>mirror-maker-agent</artifactId>
-
-    <properties>
-        <!-- Points to the root directory of the Strimzi project directory and can be used for fixed location to configuration files -->
-        <strimziRootDirectory>${basedir}${file.separator}..</strimziRootDirectory>
-    </properties>
-
-    <dependencies>
-        <!-- Note these dependencies are aligned with those in Kafka.
-        The scope is provided because the agent's classloader is the system class loader,
-        which is the class loader which loads the class containing the application main method.
-        So these classes will already be available to that classloader (because they're on the classpath).
-        -->
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>slf4j-api</artifactId>
-            <version>${slf4j.version}</version>
-            <scope>provided</scope>
-        </dependency>
-    </dependencies>
-
-    <build>
-        <plugins>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-jar-plugin</artifactId>
-                <version>${maven.jar.version}</version>
-                <configuration>
-                    <archive>
-                        <manifestEntries>
-                            <Premain-Class>io.strimzi.mirrormaker.agent.MirrorMakerAgent</Premain-Class>
-                        </manifestEntries>
-                    </archive>
-                </configuration>
-            </plugin>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-assembly-plugin</artifactId>
-                <version>${maven.assembly.version}</version>
-                <executions>
-                    <execution>
-                        <id>make-dist-assembly</id>
-                        <phase>package</phase>
-                    </execution>
-                </executions>
-            </plugin>
-        </plugins>
-    </build>
-
-</project>
\ No newline at end of file
diff --git a/mirror-maker-agent/src/main/java/io/strimzi/mirrormaker/agent/MirrorMakerAgent.java b/mirror-maker-agent/src/main/java/io/strimzi/mirrormaker/agent/MirrorMakerAgent.java
deleted file mode 100644
index acfae1238c2..00000000000
--- a/mirror-maker-agent/src/main/java/io/strimzi/mirrormaker/agent/MirrorMakerAgent.java
+++ /dev/null
@@ -1,230 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.mirrormaker.agent;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.management.JMException;
-import javax.management.MBeanServerConnection;
-import javax.management.ObjectName;
-
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.lang.management.ManagementFactory;
-import java.util.Set;
-
-/**
- * A Java agent which helps with the Readiness and Liveness check in Kafka Mirror Maker.
- *
- * Liveness:
- *   In every loop it touches a liveness file if it doesn't exist. The file is expected to tbe deleted by the Kubernetes
- *   liveness probe. So it should be periodically deleted and recreated.
- *
- * Readiness:
- *   Readiness checks the number of connections to the source and target Kafka clusters. If at least one connection
- *   exists to each of the clusters, the readiness file will be created. If not it will be deleted.
- */
-public class MirrorMakerAgent {
-    private static final Logger LOGGER = LoggerFactory.getLogger(MirrorMakerAgent.class);
-
-    private final File livenessFile;
-    private final File readinessFile;
-    private final long readinessSleepInterval;
-    private final long livenessSleepInterval;
-
-    /**
-     * Constructor of the MirrorMakerAgent
-     *
-     * @param readinessFile             File which is touched (created) when Mirror Maker 1 is ready
-     * @param livenessFile              File which is touched (created) when Mirror Maker 1 is alive
-     * @param readinessSleepInterval    Sleep interval of the readiness check
-     * @param livenessSleepInterval     Sleep interval of the liveness check
-     */
-    public MirrorMakerAgent(File readinessFile, File livenessFile, long readinessSleepInterval, long livenessSleepInterval) {
-        this.readinessFile = readinessFile;
-        this.livenessFile = livenessFile;
-        this.readinessSleepInterval = readinessSleepInterval;
-        this.livenessSleepInterval = livenessSleepInterval;
-    }
-
-    /**
-     * Starts two poller threads - one for readiness and one for liveness.
-     */
-    private void run() {
-        LOGGER.info("Starting readiness poller");
-        Thread readinessThread = new Thread(readinessPoller(), "ReadinessPoller");
-        readinessThread.setDaemon(true);
-        readinessThread.start();
-
-        LOGGER.info("Starting liveness poller");
-        Thread livenessThread = new Thread(livenessPoller(), "LivenessPoller");
-        livenessThread.setDaemon(true);
-        livenessThread.start();
-    }
-
-    /**
-     * Creates the poller thread for the liveness check
-     *
-     * @return Runable for liveness check
-     */
-    private Runnable livenessPoller() {
-        return () -> {
-            while (true) {
-                if (!livenessFile.exists()) {
-                    try {
-                        LOGGER.debug("Mirror Maker is alive");
-                        touch(livenessFile);
-                    } catch (IOException e) {
-                        LOGGER.error("Could not write liveness file {}", livenessFile, e);
-                    }
-                }
-
-                try {
-                    Thread.sleep(livenessSleepInterval);
-                } catch (InterruptedException e) {
-                    // In theory this should never normally happen
-                    LOGGER.warn("Unexpectedly interrupted");
-                    break;
-                }
-            }
-            LOGGER.debug("Exiting thread");
-        };
-    }
-
-    /**
-     * Creates the poller thread for the readiness check
-     *
-     * @return Runable for readiness check
-     */
-    private Runnable readinessPoller() {
-        return new Runnable() {
-            private final MBeanServerConnection beanConn = ManagementFactory.getPlatformMBeanServer();
-
-            @Override
-            public void run() {
-                while (true) {
-                    if (handleProducerConnected() && handleConsumerConnected()) {
-                        try {
-                            LOGGER.debug("Mirror Maker is ready");
-                            touch(readinessFile);
-                        } catch (IOException e) {
-                            LOGGER.error("Could not write readiness file {}", readinessFile, e);
-                        }
-                    } else {
-                        LOGGER.debug("Mirror Maker is not ready");
-
-                        if (readinessFile.exists() && !readinessFile.delete()) {
-                            LOGGER.error("Could not delete readiness indicator file {}", readinessFile);
-                        }
-                    }
-
-                    try {
-                        Thread.sleep(readinessSleepInterval);
-                    } catch (InterruptedException e) {
-                        // In theory this should never normally happen
-                        LOGGER.warn("Unexpectedly interrupted");
-                        break;
-                    }
-                }
-                LOGGER.debug("Exiting thread");
-            }
-
-            /**
-             * Gets the producer connections from JMX and counts them.
-             *
-             * @return True if at least one producer connections exists. False otherwise.
-             */
-            boolean handleProducerConnected() {
-                LOGGER.debug("Polling for producer connections");
-                Double connectionCount = 0.0D;
-
-                try {
-                    Set<ObjectName> mbeans = beanConn.queryNames(new ObjectName("kafka.producer:type=producer-metrics,client-id=*"), null);
-
-                    for (ObjectName oName : mbeans) {
-                        Double attr = (Double) beanConn.getAttribute(oName, "connection-count");
-                        connectionCount += attr;
-                        LOGGER.trace("Found connection metric with name {} and value: {}", oName, attr);
-                    }
-                }   catch (IOException | JMException e) {
-                    LOGGER.error("Failed to query JMX metrics", e);
-                }   finally {
-                    LOGGER.trace("Total producer connections {}", connectionCount);
-                }
-                return connectionCount > 0;
-            }
-
-            /**
-             * Gets the consumer connections from JMX and counts them.
-             *
-             * @return True if at least one consumer connections exists. False otherwise.
-             */
-            boolean handleConsumerConnected() {
-                LOGGER.debug("Polling for consumer connections");
-                Double connectionCount = 0.0D;
-
-                try {
-                    Set<ObjectName> mbeans = beanConn.queryNames(new ObjectName("kafka.consumer:type=consumer-metrics,client-id=*"), null);
-
-                    for (ObjectName oName : mbeans) {
-                        Double attr = (Double) beanConn.getAttribute(oName, "connection-count");
-                        connectionCount += attr;
-                        LOGGER.trace("Found connection metric with name {} and value: {}", oName, attr);
-                    }
-                }   catch (IOException | JMException e) {
-                    LOGGER.error("Failed to query JMX metrics", e);
-                }   finally {
-                    LOGGER.trace("Total consumer connections {}", connectionCount);
-                }
-                return connectionCount > 0;
-            }
-        };
-    }
-
-    /**
-     * Creates the file which indicates readiness or liveness.
-     *
-     * @param file  File which should be created
-     *
-     * @throws IOException if the file can't be created
-     */
-    private void touch(File file) throws IOException {
-        try (FileOutputStream ignored = new FileOutputStream(file)) {
-            file.deleteOnExit();
-        }
-    }
-
-    /**
-     * Agent entry point
-     *
-     * @param agentArgs The agent arguments
-     */
-    public static void premain(String agentArgs) {
-        String[] args = agentArgs.split(":");
-
-        if (args.length != 4) {
-            LOGGER.error("Unexpected number of arguments ({}): {}", args.length, agentArgs);
-            System.exit(1);
-        } else {
-            File mirrorMakerReadyFile = new File(args[0]);
-            File livenessFile = new File(args[1]);
-
-            if (mirrorMakerReadyFile.exists() && !mirrorMakerReadyFile.delete()) {
-                LOGGER.error("Mirror Maker readiness file already exists and could not be deleted: {}", mirrorMakerReadyFile);
-                System.exit(1);
-            } else if (livenessFile.exists() && !livenessFile.delete()) {
-                LOGGER.error("Liveness file already exists and could not be deleted: {}", livenessFile);
-                System.exit(1);
-            } else {
-                long readinessSleepInterval = Long.parseLong(args[2]) / 2L * 1000L;
-                long livenessSleepInterval = Long.parseLong(args[3]) / 2L * 1000L;
-
-                new MirrorMakerAgent(mirrorMakerReadyFile, livenessFile, readinessSleepInterval, livenessSleepInterval).run();
-            }
-        }
-    }
-}
diff --git a/operator-common/src/test/java/io/strimzi/operator/common/UtilTest.java b/operator-common/src/test/java/io/strimzi/operator/common/UtilTest.java
index bfcc39fdbbe..cb80a7f6000 100644
--- a/operator-common/src/test/java/io/strimzi/operator/common/UtilTest.java
+++ b/operator-common/src/test/java/io/strimzi/operator/common/UtilTest.java
@@ -129,15 +129,18 @@ public void testMergeLabelsOrAnnotations()  {
     public void testVarExpansion() {
         String input = "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                 "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
-                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
-                "mirrormaker.root.logger=INFO\n" +
-                "log4j.rootLogger=${mirrormaker.root.logger}, CONSOLE";
+                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %X{connector.context}%m (%c) [%t]%n\n" +
+                "connect.root.logger.level=INFO\n" +
+                "log4j.rootLogger=${connect.root.logger.level}, CONSOLE\n" +
+                "log4j.logger.org.reflections=ERROR";
 
         String expectedOutput = "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                 "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
-                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
-                "mirrormaker.root.logger=INFO\n" +
-                "log4j.rootLogger=INFO, CONSOLE\n";
+                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %X{connector.context}%m (%c) [%t]%n\n" +
+                "connect.root.logger.level=INFO\n" +
+                "log4j.rootLogger=INFO, CONSOLE\n" +
+                "log4j.logger.org.reflections=ERROR\n";
+
         String result = Util.expandVars(input);
         assertThat(result, is(expectedOutput));
     }
diff --git a/packaging/examples/metrics/grafana-dashboards/strimzi-operators.json b/packaging/examples/metrics/grafana-dashboards/strimzi-operators.json
index 8b3a05af086..317156b2178 100644
--- a/packaging/examples/metrics/grafana-dashboards/strimzi-operators.json
+++ b/packaging/examples/metrics/grafana-dashboards/strimzi-operators.json
@@ -493,13 +493,13 @@
       "targets": [
         {
           "datasource": "${DS_PROMETHEUS}",
-          "expr": "sum(strimzi_resources{kind=\"KafkaMirrorMaker\"})",
+          "expr": "sum(strimzi_resources{kind=\"KafkaNodePool\"})",
           "format": "time_series",
           "intervalFactor": 1,
           "refId": "A"
         }
       ],
-      "title": "Mirror Maker CRs",
+      "title": "Node Pool CRs",
       "type": "stat"
     },
     {
diff --git a/packaging/examples/metrics/prometheus-install/prometheus-rules.yaml b/packaging/examples/metrics/prometheus-install/prometheus-rules.yaml
index a44ca7decdf..9f67e2a33f2 100644
--- a/packaging/examples/metrics/prometheus-install/prometheus-rules.yaml
+++ b/packaging/examples/metrics/prometheus-install/prometheus-rules.yaml
@@ -225,16 +225,16 @@ spec:
       annotations:
         summary: 'Kafka Bridge returns code 5xx too often'
         description: 'Kafka Bridge returns code 5xx too much ({{ $value }}) for the path {{ $labels.path }}'
-  - name: mirrorMaker
+  - name: mirrorMaker2
     rules:
-    - alert: MirrorMakerContainerDown
-      expr: absent(container_last_seen{container=~".+-mirror-maker",pod=~".+-mirror-maker-.+"})
+    - alert: MirrorMaker2ContainerDown
+      expr: absent(container_last_seen{container=~".+-mirrormaker2",pod=~".+-mirrormaker2-.+"})
       for: 3m
       labels:
         severity: major
       annotations:
-        summary: 'All Kafka Mirror Maker containers down or in CrashLookBackOff status'
-        description: 'All Kafka Mirror Maker containers have been down or in CrashLookBackOff status for 3 minutes'
+        summary: 'All Kafka Mirror Maker 2 containers down or in CrashLookBackOff status'
+        description: 'All Kafka Mirror Maker 2 containers have been down or in CrashLookBackOff status for 3 minutes'
   - name: kafkaExporter
     rules:
     - alert: UnderReplicatedPartition
diff --git a/packaging/examples/metrics/prometheus-install/strimzi-pod-monitor.yaml b/packaging/examples/metrics/prometheus-install/strimzi-pod-monitor.yaml
index dd8ea090881..8d3ceba68e3 100644
--- a/packaging/examples/metrics/prometheus-install/strimzi-pod-monitor.yaml
+++ b/packaging/examples/metrics/prometheus-install/strimzi-pod-monitor.yaml
@@ -60,7 +60,7 @@ spec:
     matchExpressions:
       - key: "strimzi.io/kind"
         operator: In
-        values: ["Kafka", "KafkaConnect", "KafkaMirrorMaker", "KafkaMirrorMaker2"]
+        values: ["Kafka", "KafkaConnect", "KafkaMirrorMaker2"]
   namespaceSelector:
     matchNames:
       - myproject
diff --git a/packaging/examples/mirror-maker/kafka-mirror-maker-tls.yaml b/packaging/examples/mirror-maker/kafka-mirror-maker-tls.yaml
deleted file mode 100644
index 21b54d602ed..00000000000
--- a/packaging/examples/mirror-maker/kafka-mirror-maker-tls.yaml
+++ /dev/null
@@ -1,21 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: my-mirror-maker
-spec:
-  version: 3.9.0
-  replicas: 1
-  consumer:
-    bootstrapServers: cluster-a-kafka-bootstrap:9093 # Source cluster
-    groupId: cluster-a-group-id
-    tls:
-      trustedCertificates:
-        - secretName: cluster-a-cluster-ca-cert
-          pattern: "*.crt"
-  producer:
-    bootstrapServers: cluster-b-kafka-bootstrap:9093 # Target cluster
-    tls:
-      trustedCertificates:
-        - secretName: cluster-b-cluster-ca-cert
-          pattern: "*.crt"
-  include: ".*"
diff --git a/packaging/examples/mirror-maker/kafka-mirror-maker.yaml b/packaging/examples/mirror-maker/kafka-mirror-maker.yaml
deleted file mode 100644
index 83997636d9f..00000000000
--- a/packaging/examples/mirror-maker/kafka-mirror-maker.yaml
+++ /dev/null
@@ -1,13 +0,0 @@
-apiVersion: kafka.strimzi.io/v1beta2
-kind: KafkaMirrorMaker
-metadata:
-  name: my-mirror-maker
-spec:
-  version: 3.9.0
-  replicas: 1
-  consumer:
-    bootstrapServers: cluster-a-kafka-bootstrap:9092 # Source cluster
-    groupId: cluster-a-group-id
-  producer:
-    bootstrapServers: cluster-b-kafka-bootstrap:9092 # Target cluster
-  include: ".*"
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/README.md b/packaging/helm-charts/helm3/strimzi-kafka-operator/README.md
index a3e42ecae73..725bf3ae89b 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/README.md
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/README.md
@@ -136,12 +136,6 @@ the documentation for more details.
 | `kafkaConnect.image.tagPrefix`              | Override default Kafka Connect image tag prefix                                 | `nil`                        |
 | `kafkaConnect.image.tag`                    | Override default Kafka Connect image tag and ignore suffix                      | `nil`                        |
 | `kafkaConnect.image.digest`                 | Override Kafka Connect image tag with digest                                    | `nil`                        |
-| `kafkaMirrorMaker.image.registry`           | Override default Kafka Mirror Maker image registry                              | `nil`                        |
-| `kafkaMirrorMaker.image.repository`         | Override default Kafka Mirror Maker image repository                            | `nil`                        |
-| `kafkaMirrorMaker.image.name`               | Kafka Mirror Maker image name                                                   | `kafka`                      |
-| `kafkaMirrorMaker.image.tagPrefix`          | Override default Kafka Mirror Maker image tag prefix                            | `nil`                        |
-| `kafkaMirrorMaker.image.tag`                | Override default Kafka Mirror Maker image tag and ignore suffix                 | `nil`                        |
-| `kafkaMirrorMaker.image.digest`             | Override Kafka Mirror Maker image tag with digest                               | `nil`                        |
 | `cruiseControl.image.registry`              | Override default Cruise Control image registry                                  | `nil`                        |
 | `cruiseControl.image.repository`            | Override default Cruise Control image repository                                | `nil`                        |
 | `cruiseControl.image.name`                  | Cruise Control image name                                                       | `kafka`                      |
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/crds/045-Crd-kafkamirrormaker.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/crds/045-Crd-kafkamirrormaker.yaml
deleted file mode 100644
index 1e6d6ce4457..00000000000
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/crds/045-Crd-kafkamirrormaker.yaml
+++ /dev/null
@@ -1,1578 +0,0 @@
-apiVersion: apiextensions.k8s.io/v1
-kind: CustomResourceDefinition
-metadata:
-  name: kafkamirrormakers.kafka.strimzi.io
-  labels:
-    app: strimzi
-    strimzi.io/crd-install: "true"
-    component: kafkamirrormakers.kafka.strimzi.io-crd
-spec:
-  group: kafka.strimzi.io
-  names:
-    kind: KafkaMirrorMaker
-    listKind: KafkaMirrorMakerList
-    singular: kafkamirrormaker
-    plural: kafkamirrormakers
-    shortNames:
-      - kmm
-    categories:
-      - strimzi
-  scope: Namespaced
-  conversion:
-    strategy: None
-  versions:
-    - name: v1beta2
-      served: true
-      storage: true
-      subresources:
-        status: {}
-        scale:
-          specReplicasPath: .spec.replicas
-          statusReplicasPath: .status.replicas
-          labelSelectorPath: .status.labelSelector
-      additionalPrinterColumns:
-        - name: Desired replicas
-          description: The desired number of Kafka MirrorMaker replicas
-          jsonPath: .spec.replicas
-          type: integer
-        - name: Consumer Bootstrap Servers
-          description: The boostrap servers for the consumer
-          jsonPath: .spec.consumer.bootstrapServers
-          type: string
-          priority: 1
-        - name: Producer Bootstrap Servers
-          description: The boostrap servers for the producer
-          jsonPath: .spec.producer.bootstrapServers
-          type: string
-          priority: 1
-        - name: Ready
-          description: The state of the custom resource
-          jsonPath: ".status.conditions[?(@.type==\"Ready\")].status"
-          type: string
-      schema:
-        openAPIV3Schema:
-          type: object
-          properties:
-            apiVersion:
-              type: string
-              description: "APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources"
-            kind:
-              type: string
-              description: "Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"
-            metadata:
-              type: object
-            spec:
-              type: object
-              properties:
-                version:
-                  type: string
-                  description: The Kafka MirrorMaker version. Defaults to the latest version. Consult the documentation to understand the process required to upgrade or downgrade the version.
-                replicas:
-                  type: integer
-                  minimum: 0
-                  description: The number of pods in the `Deployment`.
-                image:
-                  type: string
-                  description: "The container image used for Kafka MirrorMaker pods. If no image name is explicitly specified, it is determined based on the `spec.version` configuration. The image names are specifically mapped to corresponding versions in the Cluster Operator configuration."
-                consumer:
-                  type: object
-                  properties:
-                    numStreams:
-                      type: integer
-                      minimum: 1
-                      description: Specifies the number of consumer stream threads to create.
-                    offsetCommitInterval:
-                      type: integer
-                      description: Specifies the offset auto-commit interval in ms. Default value is 60000.
-                    bootstrapServers:
-                      type: string
-                      description: A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-                    groupId:
-                      type: string
-                      description: A unique string that identifies the consumer group this consumer belongs to.
-                    authentication:
-                      type: object
-                      properties:
-                        accessToken:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
-                        accessTokenIsJwt:
-                          type: boolean
-                          description: Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
-                        accessTokenLocation:
-                          type: string
-                          description: Path to the token file containing an access token to be used for authentication.
-                        audience:
-                          type: string
-                          description: "OAuth audience to use when authenticating against the authorization server. Some authorization servers require the audience to be explicitly set. The possible values depend on how the authorization server is configured. By default, `audience` is not specified when performing the token endpoint request."
-                        certificateAndKey:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the Secret.
-                            key:
-                              type: string
-                              description: The name of the private key in the Secret.
-                          required:
-                            - secretName
-                            - certificate
-                            - key
-                          description: Reference to the `Secret` which holds the certificate and private key pair.
-                        clientAssertion:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes secret containing the client assertion which was manually configured for the client.
-                        clientAssertionLocation:
-                          type: string
-                          description: Path to the file containing the client assertion to be used for authentication.
-                        clientAssertionType:
-                          type: string
-                          description: "The client assertion type. If not set, and either `clientAssertion` or `clientAssertionLocation` is configured, this value defaults to `urn:ietf:params:oauth:client-assertion-type:jwt-bearer`."
-                        clientId:
-                          type: string
-                          description: OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                        clientSecret:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                        connectTimeoutSeconds:
-                          type: integer
-                          description: "The connect timeout in seconds when connecting to authorization server. If not set, the effective connect timeout is 60 seconds."
-                        disableTlsHostnameVerification:
-                          type: boolean
-                          description: Enable or disable TLS hostname verification. Default value is `false`.
-                        enableMetrics:
-                          type: boolean
-                          description: Enable or disable OAuth metrics. Default value is `false`.
-                        httpRetries:
-                          type: integer
-                          description: "The maximum number of retries to attempt if an initial HTTP request fails. If not set, the default is to not attempt any retries."
-                        httpRetryPauseMs:
-                          type: integer
-                          description: "The pause to take before retrying a failed HTTP request. If not set, the default is to not pause at all but to immediately repeat a request."
-                        includeAcceptHeader:
-                          type: boolean
-                          description: Whether the Accept header should be set in requests to the authorization servers. The default value is `true`.
-                        maxTokenExpirySeconds:
-                          type: integer
-                          description: Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
-                        passwordSecret:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the password.
-                            password:
-                              type: string
-                              description: The name of the key in the Secret under which the password is stored.
-                          required:
-                            - secretName
-                            - password
-                          description: Reference to the `Secret` which holds the password.
-                        readTimeoutSeconds:
-                          type: integer
-                          description: "The read timeout in seconds when connecting to authorization server. If not set, the effective read timeout is 60 seconds."
-                        refreshToken:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
-                        saslExtensions:
-                          additionalProperties:
-                            type: string
-                          type: object
-                          description: SASL extensions parameters.
-                        scope:
-                          type: string
-                          description: OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
-                        tlsTrustedCertificates:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              secretName:
-                                type: string
-                                description: The name of the Secret containing the certificate.
-                              certificate:
-                                type: string
-                                description: The name of the file certificate in the secret.
-                              pattern:
-                                type: string
-                                description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                            oneOf:
-                              - properties:
-                                  certificate: {}
-                                required:
-                                  - certificate
-                              - properties:
-                                  pattern: {}
-                                required:
-                                  - pattern
-                            required:
-                              - secretName
-                          description: Trusted certificates for TLS connection to the OAuth server.
-                        tokenEndpointUri:
-                          type: string
-                          description: Authorization server token endpoint URI.
-                        type:
-                          type: string
-                          enum:
-                            - tls
-                            - scram-sha-256
-                            - scram-sha-512
-                            - plain
-                            - oauth
-                          description: "Authentication type. Currently the supported types are `tls`, `scram-sha-256`, `scram-sha-512`, `plain`, and 'oauth'. `scram-sha-256` and `scram-sha-512` types use SASL SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication, respectively. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections."
-                        username:
-                          type: string
-                          description: Username used for the authentication.
-                      required:
-                        - type
-                      description: Authentication configuration for connecting to the cluster.
-                    tls:
-                      type: object
-                      properties:
-                        trustedCertificates:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              secretName:
-                                type: string
-                                description: The name of the Secret containing the certificate.
-                              certificate:
-                                type: string
-                                description: The name of the file certificate in the secret.
-                              pattern:
-                                type: string
-                                description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                            oneOf:
-                              - properties:
-                                  certificate: {}
-                                required:
-                                  - certificate
-                              - properties:
-                                  pattern: {}
-                                required:
-                                  - pattern
-                            required:
-                              - secretName
-                          description: Trusted certificates for TLS connection.
-                      description: TLS configuration for connecting MirrorMaker to the cluster.
-                    config:
-                      x-kubernetes-preserve-unknown-fields: true
-                      type: object
-                      description: "The MirrorMaker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols)."
-                  required:
-                    - bootstrapServers
-                    - groupId
-                  description: Configuration of source cluster.
-                producer:
-                  type: object
-                  properties:
-                    bootstrapServers:
-                      type: string
-                      description: A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-                    abortOnSendFailure:
-                      type: boolean
-                      description: Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.
-                    authentication:
-                      type: object
-                      properties:
-                        accessToken:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
-                        accessTokenIsJwt:
-                          type: boolean
-                          description: Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
-                        accessTokenLocation:
-                          type: string
-                          description: Path to the token file containing an access token to be used for authentication.
-                        audience:
-                          type: string
-                          description: "OAuth audience to use when authenticating against the authorization server. Some authorization servers require the audience to be explicitly set. The possible values depend on how the authorization server is configured. By default, `audience` is not specified when performing the token endpoint request."
-                        certificateAndKey:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the Secret.
-                            key:
-                              type: string
-                              description: The name of the private key in the Secret.
-                          required:
-                            - secretName
-                            - certificate
-                            - key
-                          description: Reference to the `Secret` which holds the certificate and private key pair.
-                        clientAssertion:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes secret containing the client assertion which was manually configured for the client.
-                        clientAssertionLocation:
-                          type: string
-                          description: Path to the file containing the client assertion to be used for authentication.
-                        clientAssertionType:
-                          type: string
-                          description: "The client assertion type. If not set, and either `clientAssertion` or `clientAssertionLocation` is configured, this value defaults to `urn:ietf:params:oauth:client-assertion-type:jwt-bearer`."
-                        clientId:
-                          type: string
-                          description: OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                        clientSecret:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                        connectTimeoutSeconds:
-                          type: integer
-                          description: "The connect timeout in seconds when connecting to authorization server. If not set, the effective connect timeout is 60 seconds."
-                        disableTlsHostnameVerification:
-                          type: boolean
-                          description: Enable or disable TLS hostname verification. Default value is `false`.
-                        enableMetrics:
-                          type: boolean
-                          description: Enable or disable OAuth metrics. Default value is `false`.
-                        httpRetries:
-                          type: integer
-                          description: "The maximum number of retries to attempt if an initial HTTP request fails. If not set, the default is to not attempt any retries."
-                        httpRetryPauseMs:
-                          type: integer
-                          description: "The pause to take before retrying a failed HTTP request. If not set, the default is to not pause at all but to immediately repeat a request."
-                        includeAcceptHeader:
-                          type: boolean
-                          description: Whether the Accept header should be set in requests to the authorization servers. The default value is `true`.
-                        maxTokenExpirySeconds:
-                          type: integer
-                          description: Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
-                        passwordSecret:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the password.
-                            password:
-                              type: string
-                              description: The name of the key in the Secret under which the password is stored.
-                          required:
-                            - secretName
-                            - password
-                          description: Reference to the `Secret` which holds the password.
-                        readTimeoutSeconds:
-                          type: integer
-                          description: "The read timeout in seconds when connecting to authorization server. If not set, the effective read timeout is 60 seconds."
-                        refreshToken:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                              description: The key under which the secret value is stored in the Kubernetes Secret.
-                            secretName:
-                              type: string
-                              description: The name of the Kubernetes Secret containing the secret value.
-                          required:
-                            - key
-                            - secretName
-                          description: Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
-                        saslExtensions:
-                          additionalProperties:
-                            type: string
-                          type: object
-                          description: SASL extensions parameters.
-                        scope:
-                          type: string
-                          description: OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
-                        tlsTrustedCertificates:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              secretName:
-                                type: string
-                                description: The name of the Secret containing the certificate.
-                              certificate:
-                                type: string
-                                description: The name of the file certificate in the secret.
-                              pattern:
-                                type: string
-                                description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                            oneOf:
-                              - properties:
-                                  certificate: {}
-                                required:
-                                  - certificate
-                              - properties:
-                                  pattern: {}
-                                required:
-                                  - pattern
-                            required:
-                              - secretName
-                          description: Trusted certificates for TLS connection to the OAuth server.
-                        tokenEndpointUri:
-                          type: string
-                          description: Authorization server token endpoint URI.
-                        type:
-                          type: string
-                          enum:
-                            - tls
-                            - scram-sha-256
-                            - scram-sha-512
-                            - plain
-                            - oauth
-                          description: "Authentication type. Currently the supported types are `tls`, `scram-sha-256`, `scram-sha-512`, `plain`, and 'oauth'. `scram-sha-256` and `scram-sha-512` types use SASL SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication, respectively. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections."
-                        username:
-                          type: string
-                          description: Username used for the authentication.
-                      required:
-                        - type
-                      description: Authentication configuration for connecting to the cluster.
-                    config:
-                      x-kubernetes-preserve-unknown-fields: true
-                      type: object
-                      description: "The MirrorMaker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols)."
-                    tls:
-                      type: object
-                      properties:
-                        trustedCertificates:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              secretName:
-                                type: string
-                                description: The name of the Secret containing the certificate.
-                              certificate:
-                                type: string
-                                description: The name of the file certificate in the secret.
-                              pattern:
-                                type: string
-                                description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                            oneOf:
-                              - properties:
-                                  certificate: {}
-                                required:
-                                  - certificate
-                              - properties:
-                                  pattern: {}
-                                required:
-                                  - pattern
-                            required:
-                              - secretName
-                          description: Trusted certificates for TLS connection.
-                      description: TLS configuration for connecting MirrorMaker to the cluster.
-                  required:
-                    - bootstrapServers
-                  description: Configuration of target cluster.
-                resources:
-                  type: object
-                  properties:
-                    claims:
-                      type: array
-                      items:
-                        type: object
-                        properties:
-                          name:
-                            type: string
-                    limits:
-                      additionalProperties:
-                        anyOf:
-                          - type: integer
-                          - type: string
-                        pattern: "^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$"
-                        x-kubernetes-int-or-string: true
-                      type: object
-                    requests:
-                      additionalProperties:
-                        anyOf:
-                          - type: integer
-                          - type: string
-                        pattern: "^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$"
-                        x-kubernetes-int-or-string: true
-                      type: object
-                  description: CPU and memory resources to reserve.
-                whitelist:
-                  type: string
-                  description: "List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas."
-                include:
-                  type: string
-                  description: "List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas."
-                jvmOptions:
-                  type: object
-                  properties:
-                    "-XX":
-                      additionalProperties:
-                        type: string
-                      type: object
-                      description: A map of -XX options to the JVM.
-                    "-Xmx":
-                      type: string
-                      pattern: "^[0-9]+[mMgG]?$"
-                      description: -Xmx option to to the JVM.
-                    "-Xms":
-                      type: string
-                      pattern: "^[0-9]+[mMgG]?$"
-                      description: -Xms option to to the JVM.
-                    gcLoggingEnabled:
-                      type: boolean
-                      description: Specifies whether the Garbage Collection logging is enabled. The default is false.
-                    javaSystemProperties:
-                      type: array
-                      items:
-                        type: object
-                        properties:
-                          name:
-                            type: string
-                            description: The system property name.
-                          value:
-                            type: string
-                            description: The system property value.
-                      description: A map of additional system properties which will be passed using the `-D` option to the JVM.
-                  description: JVM Options for pods.
-                logging:
-                  type: object
-                  properties:
-                    loggers:
-                      additionalProperties:
-                        type: string
-                      type: object
-                      description: A Map from logger name to logger level.
-                    type:
-                      type: string
-                      enum:
-                        - inline
-                        - external
-                      description: "Logging type, must be either 'inline' or 'external'."
-                    valueFrom:
-                      type: object
-                      properties:
-                        configMapKeyRef:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                            name:
-                              type: string
-                            optional:
-                              type: boolean
-                          description: Reference to the key in the ConfigMap containing the configuration.
-                      description: '`ConfigMap` entry where the logging configuration is stored. '
-                  required:
-                    - type
-                  description: Logging configuration for MirrorMaker.
-                metricsConfig:
-                  type: object
-                  properties:
-                    type:
-                      type: string
-                      enum:
-                        - jmxPrometheusExporter
-                      description: Metrics type. Only 'jmxPrometheusExporter' supported currently.
-                    valueFrom:
-                      type: object
-                      properties:
-                        configMapKeyRef:
-                          type: object
-                          properties:
-                            key:
-                              type: string
-                            name:
-                              type: string
-                            optional:
-                              type: boolean
-                          description: Reference to the key in the ConfigMap containing the configuration.
-                      description: 'ConfigMap entry where the Prometheus JMX Exporter configuration is stored. '
-                  required:
-                    - type
-                    - valueFrom
-                  description: Metrics configuration.
-                tracing:
-                  type: object
-                  properties:
-                    type:
-                      type: string
-                      enum:
-                        - jaeger
-                        - opentelemetry
-                      description: "Type of the tracing used. Currently the only supported type is `opentelemetry` for OpenTelemetry tracing. As of Strimzi 0.37.0, `jaeger` type is not supported anymore and this option is ignored."
-                  required:
-                    - type
-                  description: The configuration of tracing in Kafka MirrorMaker.
-                template:
-                  type: object
-                  properties:
-                    deployment:
-                      type: object
-                      properties:
-                        metadata:
-                          type: object
-                          properties:
-                            labels:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Labels added to the Kubernetes resource.
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Annotations added to the Kubernetes resource.
-                          description: Metadata applied to the resource.
-                        deploymentStrategy:
-                          type: string
-                          enum:
-                            - RollingUpdate
-                            - Recreate
-                          description: Pod replacement strategy for deployment configuration changes. Valid values are `RollingUpdate` and `Recreate`. Defaults to `RollingUpdate`.
-                      description: Template for Kafka MirrorMaker `Deployment`.
-                    pod:
-                      type: object
-                      properties:
-                        metadata:
-                          type: object
-                          properties:
-                            labels:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Labels added to the Kubernetes resource.
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Annotations added to the Kubernetes resource.
-                          description: Metadata applied to the resource.
-                        imagePullSecrets:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              name:
-                                type: string
-                          description: "List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored."
-                        securityContext:
-                          type: object
-                          properties:
-                            appArmorProfile:
-                              type: object
-                              properties:
-                                localhostProfile:
-                                  type: string
-                                type:
-                                  type: string
-                            fsGroup:
-                              type: integer
-                            fsGroupChangePolicy:
-                              type: string
-                            runAsGroup:
-                              type: integer
-                            runAsNonRoot:
-                              type: boolean
-                            runAsUser:
-                              type: integer
-                            seLinuxOptions:
-                              type: object
-                              properties:
-                                level:
-                                  type: string
-                                role:
-                                  type: string
-                                type:
-                                  type: string
-                                user:
-                                  type: string
-                            seccompProfile:
-                              type: object
-                              properties:
-                                localhostProfile:
-                                  type: string
-                                type:
-                                  type: string
-                            supplementalGroups:
-                              type: array
-                              items:
-                                type: integer
-                            sysctls:
-                              type: array
-                              items:
-                                type: object
-                                properties:
-                                  name:
-                                    type: string
-                                  value:
-                                    type: string
-                            windowsOptions:
-                              type: object
-                              properties:
-                                gmsaCredentialSpec:
-                                  type: string
-                                gmsaCredentialSpecName:
-                                  type: string
-                                hostProcess:
-                                  type: boolean
-                                runAsUserName:
-                                  type: string
-                          description: Configures pod-level security attributes and common container settings.
-                        terminationGracePeriodSeconds:
-                          type: integer
-                          minimum: 0
-                          description: "The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds."
-                        affinity:
-                          type: object
-                          properties:
-                            nodeAffinity:
-                              type: object
-                              properties:
-                                preferredDuringSchedulingIgnoredDuringExecution:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      preference:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchFields:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                      weight:
-                                        type: integer
-                                requiredDuringSchedulingIgnoredDuringExecution:
-                                  type: object
-                                  properties:
-                                    nodeSelectorTerms:
-                                      type: array
-                                      items:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchFields:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                            podAffinity:
-                              type: object
-                              properties:
-                                preferredDuringSchedulingIgnoredDuringExecution:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      podAffinityTerm:
-                                        type: object
-                                        properties:
-                                          labelSelector:
-                                            type: object
-                                            properties:
-                                              matchExpressions:
-                                                type: array
-                                                items:
-                                                  type: object
-                                                  properties:
-                                                    key:
-                                                      type: string
-                                                    operator:
-                                                      type: string
-                                                    values:
-                                                      type: array
-                                                      items:
-                                                        type: string
-                                              matchLabels:
-                                                additionalProperties:
-                                                  type: string
-                                                type: object
-                                          matchLabelKeys:
-                                            type: array
-                                            items:
-                                              type: string
-                                          mismatchLabelKeys:
-                                            type: array
-                                            items:
-                                              type: string
-                                          namespaceSelector:
-                                            type: object
-                                            properties:
-                                              matchExpressions:
-                                                type: array
-                                                items:
-                                                  type: object
-                                                  properties:
-                                                    key:
-                                                      type: string
-                                                    operator:
-                                                      type: string
-                                                    values:
-                                                      type: array
-                                                      items:
-                                                        type: string
-                                              matchLabels:
-                                                additionalProperties:
-                                                  type: string
-                                                type: object
-                                          namespaces:
-                                            type: array
-                                            items:
-                                              type: string
-                                          topologyKey:
-                                            type: string
-                                      weight:
-                                        type: integer
-                                requiredDuringSchedulingIgnoredDuringExecution:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      labelSelector:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchLabels:
-                                            additionalProperties:
-                                              type: string
-                                            type: object
-                                      matchLabelKeys:
-                                        type: array
-                                        items:
-                                          type: string
-                                      mismatchLabelKeys:
-                                        type: array
-                                        items:
-                                          type: string
-                                      namespaceSelector:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchLabels:
-                                            additionalProperties:
-                                              type: string
-                                            type: object
-                                      namespaces:
-                                        type: array
-                                        items:
-                                          type: string
-                                      topologyKey:
-                                        type: string
-                            podAntiAffinity:
-                              type: object
-                              properties:
-                                preferredDuringSchedulingIgnoredDuringExecution:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      podAffinityTerm:
-                                        type: object
-                                        properties:
-                                          labelSelector:
-                                            type: object
-                                            properties:
-                                              matchExpressions:
-                                                type: array
-                                                items:
-                                                  type: object
-                                                  properties:
-                                                    key:
-                                                      type: string
-                                                    operator:
-                                                      type: string
-                                                    values:
-                                                      type: array
-                                                      items:
-                                                        type: string
-                                              matchLabels:
-                                                additionalProperties:
-                                                  type: string
-                                                type: object
-                                          matchLabelKeys:
-                                            type: array
-                                            items:
-                                              type: string
-                                          mismatchLabelKeys:
-                                            type: array
-                                            items:
-                                              type: string
-                                          namespaceSelector:
-                                            type: object
-                                            properties:
-                                              matchExpressions:
-                                                type: array
-                                                items:
-                                                  type: object
-                                                  properties:
-                                                    key:
-                                                      type: string
-                                                    operator:
-                                                      type: string
-                                                    values:
-                                                      type: array
-                                                      items:
-                                                        type: string
-                                              matchLabels:
-                                                additionalProperties:
-                                                  type: string
-                                                type: object
-                                          namespaces:
-                                            type: array
-                                            items:
-                                              type: string
-                                          topologyKey:
-                                            type: string
-                                      weight:
-                                        type: integer
-                                requiredDuringSchedulingIgnoredDuringExecution:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      labelSelector:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchLabels:
-                                            additionalProperties:
-                                              type: string
-                                            type: object
-                                      matchLabelKeys:
-                                        type: array
-                                        items:
-                                          type: string
-                                      mismatchLabelKeys:
-                                        type: array
-                                        items:
-                                          type: string
-                                      namespaceSelector:
-                                        type: object
-                                        properties:
-                                          matchExpressions:
-                                            type: array
-                                            items:
-                                              type: object
-                                              properties:
-                                                key:
-                                                  type: string
-                                                operator:
-                                                  type: string
-                                                values:
-                                                  type: array
-                                                  items:
-                                                    type: string
-                                          matchLabels:
-                                            additionalProperties:
-                                              type: string
-                                            type: object
-                                      namespaces:
-                                        type: array
-                                        items:
-                                          type: string
-                                      topologyKey:
-                                        type: string
-                          description: The pod's affinity rules.
-                        tolerations:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              effect:
-                                type: string
-                              key:
-                                type: string
-                              operator:
-                                type: string
-                              tolerationSeconds:
-                                type: integer
-                              value:
-                                type: string
-                          description: The pod's tolerations.
-                        topologySpreadConstraints:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              labelSelector:
-                                type: object
-                                properties:
-                                  matchExpressions:
-                                    type: array
-                                    items:
-                                      type: object
-                                      properties:
-                                        key:
-                                          type: string
-                                        operator:
-                                          type: string
-                                        values:
-                                          type: array
-                                          items:
-                                            type: string
-                                  matchLabels:
-                                    additionalProperties:
-                                      type: string
-                                    type: object
-                              matchLabelKeys:
-                                type: array
-                                items:
-                                  type: string
-                              maxSkew:
-                                type: integer
-                              minDomains:
-                                type: integer
-                              nodeAffinityPolicy:
-                                type: string
-                              nodeTaintsPolicy:
-                                type: string
-                              topologyKey:
-                                type: string
-                              whenUnsatisfiable:
-                                type: string
-                          description: The pod's topology spread constraints.
-                        priorityClassName:
-                          type: string
-                          description: 'The name of the priority class used to assign priority to the pods. '
-                        schedulerName:
-                          type: string
-                          description: "The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used."
-                        hostAliases:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              hostnames:
-                                type: array
-                                items:
-                                  type: string
-                              ip:
-                                type: string
-                          description: The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the Pod's hosts file if specified.
-                        enableServiceLinks:
-                          type: boolean
-                          description: Indicates whether information about services should be injected into Pod's environment variables.
-                        tmpDirSizeLimit:
-                          type: string
-                          pattern: "^([0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$"
-                          description: "Defines the total amount of pod memory allocated for the temporary `EmptyDir` volume `/tmp`. Specify the allocation in memory units, for example, `100Mi` for 100 mebibytes. Default value is `5Mi`. The `/tmp` volume is backed by pod memory, not disk storage, so avoid setting a high value as it consumes pod memory resources."
-                        volumes:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              name:
-                                type: string
-                                description: Name to use for the volume. Required.
-                              secret:
-                                type: object
-                                properties:
-                                  defaultMode:
-                                    type: integer
-                                  items:
-                                    type: array
-                                    items:
-                                      type: object
-                                      properties:
-                                        key:
-                                          type: string
-                                        mode:
-                                          type: integer
-                                        path:
-                                          type: string
-                                  optional:
-                                    type: boolean
-                                  secretName:
-                                    type: string
-                                description: Secret to use populate the volume.
-                              configMap:
-                                type: object
-                                properties:
-                                  defaultMode:
-                                    type: integer
-                                  items:
-                                    type: array
-                                    items:
-                                      type: object
-                                      properties:
-                                        key:
-                                          type: string
-                                        mode:
-                                          type: integer
-                                        path:
-                                          type: string
-                                  name:
-                                    type: string
-                                  optional:
-                                    type: boolean
-                                description: ConfigMap to use to populate the volume.
-                              emptyDir:
-                                type: object
-                                properties:
-                                  medium:
-                                    type: string
-                                  sizeLimit:
-                                    type: object
-                                    properties:
-                                      amount:
-                                        type: string
-                                      format:
-                                        type: string
-                                description: EmptyDir to use to populate the volume.
-                              persistentVolumeClaim:
-                                type: object
-                                properties:
-                                  claimName:
-                                    type: string
-                                  readOnly:
-                                    type: boolean
-                                description: PersistentVolumeClaim object to use to populate the volume.
-                              csi:
-                                type: object
-                                properties:
-                                  driver:
-                                    type: string
-                                  fsType:
-                                    type: string
-                                  nodePublishSecretRef:
-                                    type: object
-                                    properties:
-                                      name:
-                                        type: string
-                                  readOnly:
-                                    type: boolean
-                                  volumeAttributes:
-                                    additionalProperties:
-                                      type: string
-                                    type: object
-                                description: CSIVolumeSource object to use to populate the volume.
-                            oneOf:
-                              - properties:
-                                  secret: {}
-                                  configMap: {}
-                                  emptyDir: {}
-                                  persistentVolumeClaim: {}
-                                  csi: {}
-                          description: Additional volumes that can be mounted to the pod.
-                      description: Template for Kafka MirrorMaker `Pods`.
-                    podDisruptionBudget:
-                      type: object
-                      properties:
-                        metadata:
-                          type: object
-                          properties:
-                            labels:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Labels added to the Kubernetes resource.
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Annotations added to the Kubernetes resource.
-                          description: Metadata to apply to the `PodDisruptionBudgetTemplate` resource.
-                        maxUnavailable:
-                          type: integer
-                          minimum: 0
-                          description: "Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1."
-                      description: Template for Kafka MirrorMaker `PodDisruptionBudget`.
-                    mirrorMakerContainer:
-                      type: object
-                      properties:
-                        env:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              name:
-                                type: string
-                                description: The environment variable key.
-                              value:
-                                type: string
-                                description: The environment variable value.
-                              valueFrom:
-                                type: object
-                                properties:
-                                  secretKeyRef:
-                                    type: object
-                                    properties:
-                                      key:
-                                        type: string
-                                      name:
-                                        type: string
-                                      optional:
-                                        type: boolean
-                                    description: Reference to a key in a secret.
-                                  configMapKeyRef:
-                                    type: object
-                                    properties:
-                                      key:
-                                        type: string
-                                      name:
-                                        type: string
-                                      optional:
-                                        type: boolean
-                                    description: Reference to a key in a config map.
-                                oneOf:
-                                  - properties:
-                                      secretKeyRef: {}
-                                    required:
-                                      - secretKeyRef
-                                  - properties:
-                                      configMapKeyRef: {}
-                                    required:
-                                      - configMapKeyRef
-                                description: Reference to the secret or config map property to which the environment variable is set.
-                            oneOf:
-                              - properties:
-                                  value: {}
-                                required:
-                                  - value
-                              - properties:
-                                  valueFrom: {}
-                                required:
-                                  - valueFrom
-                          description: Environment variables which should be applied to the container.
-                        securityContext:
-                          type: object
-                          properties:
-                            allowPrivilegeEscalation:
-                              type: boolean
-                            appArmorProfile:
-                              type: object
-                              properties:
-                                localhostProfile:
-                                  type: string
-                                type:
-                                  type: string
-                            capabilities:
-                              type: object
-                              properties:
-                                add:
-                                  type: array
-                                  items:
-                                    type: string
-                                drop:
-                                  type: array
-                                  items:
-                                    type: string
-                            privileged:
-                              type: boolean
-                            procMount:
-                              type: string
-                            readOnlyRootFilesystem:
-                              type: boolean
-                            runAsGroup:
-                              type: integer
-                            runAsNonRoot:
-                              type: boolean
-                            runAsUser:
-                              type: integer
-                            seLinuxOptions:
-                              type: object
-                              properties:
-                                level:
-                                  type: string
-                                role:
-                                  type: string
-                                type:
-                                  type: string
-                                user:
-                                  type: string
-                            seccompProfile:
-                              type: object
-                              properties:
-                                localhostProfile:
-                                  type: string
-                                type:
-                                  type: string
-                            windowsOptions:
-                              type: object
-                              properties:
-                                gmsaCredentialSpec:
-                                  type: string
-                                gmsaCredentialSpecName:
-                                  type: string
-                                hostProcess:
-                                  type: boolean
-                                runAsUserName:
-                                  type: string
-                          description: Security context for the container.
-                        volumeMounts:
-                          type: array
-                          items:
-                            type: object
-                            properties:
-                              mountPath:
-                                type: string
-                              mountPropagation:
-                                type: string
-                              name:
-                                type: string
-                              readOnly:
-                                type: boolean
-                              recursiveReadOnly:
-                                type: string
-                              subPath:
-                                type: string
-                              subPathExpr:
-                                type: string
-                          description: Additional volume mounts which should be applied to the container.
-                      description: Template for Kafka MirrorMaker container.
-                    serviceAccount:
-                      type: object
-                      properties:
-                        metadata:
-                          type: object
-                          properties:
-                            labels:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Labels added to the Kubernetes resource.
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              type: object
-                              description: Annotations added to the Kubernetes resource.
-                          description: Metadata applied to the resource.
-                      description: Template for the Kafka MirrorMaker service account.
-                  description: "Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated."
-                livenessProbe:
-                  type: object
-                  properties:
-                    initialDelaySeconds:
-                      type: integer
-                      minimum: 0
-                      description: The initial delay before first the health is first checked. Default to 15 seconds. Minimum value is 0.
-                    timeoutSeconds:
-                      type: integer
-                      minimum: 1
-                      description: The timeout for each attempted health check. Default to 5 seconds. Minimum value is 1.
-                    periodSeconds:
-                      type: integer
-                      minimum: 1
-                      description: How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
-                    successThreshold:
-                      type: integer
-                      minimum: 1
-                      description: Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
-                    failureThreshold:
-                      type: integer
-                      minimum: 1
-                      description: Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
-                  description: Pod liveness checking.
-                readinessProbe:
-                  type: object
-                  properties:
-                    initialDelaySeconds:
-                      type: integer
-                      minimum: 0
-                      description: The initial delay before first the health is first checked. Default to 15 seconds. Minimum value is 0.
-                    timeoutSeconds:
-                      type: integer
-                      minimum: 1
-                      description: The timeout for each attempted health check. Default to 5 seconds. Minimum value is 1.
-                    periodSeconds:
-                      type: integer
-                      minimum: 1
-                      description: How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
-                    successThreshold:
-                      type: integer
-                      minimum: 1
-                      description: Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
-                    failureThreshold:
-                      type: integer
-                      minimum: 1
-                      description: Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
-                  description: Pod readiness checking.
-              oneOf:
-                - properties:
-                    include: {}
-                  required:
-                    - include
-                - properties:
-                    whitelist: {}
-                  required:
-                    - whitelist
-              required:
-                - replicas
-                - consumer
-                - producer
-              description: The specification of Kafka MirrorMaker.
-            status:
-              type: object
-              properties:
-                conditions:
-                  type: array
-                  items:
-                    type: object
-                    properties:
-                      type:
-                        type: string
-                        description: "The unique identifier of a condition, used to distinguish between other conditions in the resource."
-                      status:
-                        type: string
-                        description: "The status of the condition, either True, False or Unknown."
-                      lastTransitionTime:
-                        type: string
-                        description: "Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone."
-                      reason:
-                        type: string
-                        description: The reason for the condition's last transition (a single word in CamelCase).
-                      message:
-                        type: string
-                        description: Human-readable message indicating details about the condition's last transition.
-                  description: List of status conditions.
-                observedGeneration:
-                  type: integer
-                  description: The generation of the CRD that was last reconciled by the operator.
-                labelSelector:
-                  type: string
-                  description: Label selector for pods providing this resource.
-                replicas:
-                  type: integer
-                  description: The current number of pods being used to provide this resource.
-              description: The status of Kafka MirrorMaker.
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/files/grafana-dashboards/strimzi-operators.json b/packaging/helm-charts/helm3/strimzi-kafka-operator/files/grafana-dashboards/strimzi-operators.json
index 8b3a05af086..317156b2178 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/files/grafana-dashboards/strimzi-operators.json
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/files/grafana-dashboards/strimzi-operators.json
@@ -493,13 +493,13 @@
       "targets": [
         {
           "datasource": "${DS_PROMETHEUS}",
-          "expr": "sum(strimzi_resources{kind=\"KafkaMirrorMaker\"})",
+          "expr": "sum(strimzi_resources{kind=\"KafkaNodePool\"})",
           "format": "time_series",
           "intervalFactor": 1,
           "refId": "A"
         }
       ],
-      "title": "Mirror Maker CRs",
+      "title": "Node Pool CRs",
       "type": "stat"
     },
     {
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml
index 0f70ff1312f..a65854f6402 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml
@@ -30,7 +30,6 @@ rules:
   - kafkanodepools
   - kafkaconnects
   - kafkaconnectors
-  - kafkamirrormakers
   - kafkabridges
   - kafkamirrormaker2s
   - kafkarebalances
@@ -49,7 +48,6 @@ rules:
   - kafkanodepools/status
   - kafkaconnects/status
   - kafkaconnectors/status
-  - kafkamirrormakers/status
   - kafkabridges/status
   - kafkamirrormaker2s/status
   - kafkarebalances/status
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/070-ClusterRole-strimzi-admin.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/070-ClusterRole-strimzi-admin.yaml
index 32e48d8c6e8..c86547197c0 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/070-ClusterRole-strimzi-admin.yaml
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/070-ClusterRole-strimzi-admin.yaml
@@ -21,8 +21,6 @@ rules:
       - kafkanodepools/scale
       - kafkaconnects
       - kafkaconnects/scale
-      - kafkamirrormakers
-      - kafkamirrormakers/scale
       - kafkausers
       - kafkatopics
       - kafkabridges
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/080-ClusterRole-strimzi-view.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/080-ClusterRole-strimzi-view.yaml
index b29a20ee678..7f850f80789 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/080-ClusterRole-strimzi-view.yaml
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/080-ClusterRole-strimzi-view.yaml
@@ -18,7 +18,6 @@ rules:
       - kafkas
       - kafkanodepools
       - kafkaconnects
-      - kafkamirrormakers
       - kafkausers
       - kafkatopics
       - kafkabridges
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/_kafka_image_map.tpl b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/_kafka_image_map.tpl
index c1ff9e62b88..8460c9be7fd 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/_kafka_image_map.tpl
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/templates/_kafka_image_map.tpl
@@ -19,11 +19,6 @@
                 3.8.0={{ template "strimzi.image" (merge . (dict "key" "kafkaConnect" "tagSuffix" "-kafka-3.8.0")) }}
                 3.8.1={{ template "strimzi.image" (merge . (dict "key" "kafkaConnect" "tagSuffix" "-kafka-3.8.1")) }}
                 3.9.0={{ template "strimzi.image" (merge . (dict "key" "kafkaConnect" "tagSuffix" "-kafka-3.9.0")) }}
-            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
-              value: |                 
-                3.8.0={{ template "strimzi.image" (merge . (dict "key" "kafkaMirrorMaker" "tagSuffix" "-kafka-3.8.0")) }}
-                3.8.1={{ template "strimzi.image" (merge . (dict "key" "kafkaMirrorMaker" "tagSuffix" "-kafka-3.8.1")) }}
-                3.9.0={{ template "strimzi.image" (merge . (dict "key" "kafkaMirrorMaker" "tagSuffix" "-kafka-3.9.0")) }}
             - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
               value: |                 
                 3.8.0={{ template "strimzi.image" (merge . (dict "key" "kafkaMirrorMaker2" "tagSuffix" "-kafka-3.8.0")) }}
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/tests/operator_deployment_test.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/tests/operator_deployment_test.yaml
index d6326c620ce..942a37f4ed3 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/tests/operator_deployment_test.yaml
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/tests/operator_deployment_test.yaml
@@ -122,9 +122,6 @@ tests:
           value: STRIMZI_KAFKA_CONNECT_IMAGES
       - equal:
           path: spec.template.spec.containers[0].env[7].name
-          value: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
-      - equal:
-          path: spec.template.spec.containers[0].env[8].name
           value: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
       - matchRegex:
           path: spec.template.spec.containers[0].env[3].value
@@ -141,9 +138,6 @@ tests:
       - matchRegex:
           path: spec.template.spec.containers[0].env[7].value
           pattern: '[0-9]+\.[0-9]+\.[0-9]+=quay.io/strimzi/kafka:(latest|[0-9]+\.[0-9]+\.[0-9]+)-kafka-[0-9]+\.[0-9]+\.[0-9]+'
-      - matchRegex:
-          path: spec.template.spec.containers[0].env[8].value
-          pattern: '[0-9]+\.[0-9]+\.[0-9]+=quay.io/strimzi/kafka:(latest|[0-9]+\.[0-9]+\.[0-9]+)-kafka-[0-9]+\.[0-9]+\.[0-9]+'
 
   - it: should construct custom kafka images from specified image registry if provided
     set:
@@ -172,10 +166,10 @@ tests:
           path: spec.template.spec.imagePullSecrets[0].name
           value: test-secret
       - equal:
-          path: spec.template.spec.containers[0].env[16].name
+          path: spec.template.spec.containers[0].env[15].name
           value: STRIMZI_IMAGE_PULL_SECRETS
       - equal:
-          path: spec.template.spec.containers[0].env[16].value
+          path: spec.template.spec.containers[0].env[15].value
           value: test-secret
 
   - it: should set IMAGE_PULL_SECRETS as comma separated list if provided as array
@@ -194,10 +188,10 @@ tests:
           path: spec.template.spec.imagePullSecrets[1].name
           value: test-secret2
       - equal:
-          path: spec.template.spec.containers[0].env[16].name
+          path: spec.template.spec.containers[0].env[15].name
           value: STRIMZI_IMAGE_PULL_SECRETS
       - equal:
-          path: spec.template.spec.containers[0].env[16].value
+          path: spec.template.spec.containers[0].env[15].value
           value: test-secret,test-secret2
 
   - it: should fail if imagePullSecrets is not correctly formatted
diff --git a/packaging/helm-charts/helm3/strimzi-kafka-operator/values.yaml b/packaging/helm-charts/helm3/strimzi-kafka-operator/values.yaml
index ddce1767499..aa9cdcf991b 100644
--- a/packaging/helm-charts/helm3/strimzi-kafka-operator/values.yaml
+++ b/packaging/helm-charts/helm3/strimzi-kafka-operator/values.yaml
@@ -115,12 +115,6 @@ kafkaInit:
     repository: ""
     name: operator
     tag: ""
-kafkaMirrorMaker:
-  image:
-    registry: ""
-    repository: ""
-    name: kafka
-    tagPrefix: ""
 kafkaBridge:
   image:
     registry: ""
diff --git a/packaging/helm-charts/kafka-version-tpl.sh b/packaging/helm-charts/kafka-version-tpl.sh
index 338e58310ee..a8c844a7613 100755
--- a/packaging/helm-charts/kafka-version-tpl.sh
+++ b/packaging/helm-charts/kafka-version-tpl.sh
@@ -25,19 +25,14 @@ do
 ${version}={{ template \"strimzi.image\" (merge . (dict \"key\" \"kafka\" \"tagSuffix\" \"-kafka-${version}\")) }}"
     kafka_connect_versions="${kafka_connect_versions}
 ${version}={{ template \"strimzi.image\" (merge . (dict \"key\" \"kafkaConnect\" \"tagSuffix\" \"-kafka-${version}\")) }}"
-    kafka_mirror_maker_versions="${kafka_mirror_maker_versions}
-${version}={{ template \"strimzi.image\" (merge . (dict \"key\" \"kafkaMirrorMaker\" \"tagSuffix\" \"-kafka-${version}\")) }}"
     kafka_exporter_versions="${kafka_exporter_versions}
 ${version}={{ template \"strimzi.image\" (merge . (dict \"key\" \"kafkaExporter\" \"tagSuffix\" \"-kafka-${version}\")) }}"
-    if [[ ${version_does_not_support[${version}]} != *"kafkaMirrorMaker2"* ]] ; then
-      kafka_mirror_maker_2_versions="${kafka_mirror_maker_2_versions}
+    kafka_mirror_maker_2_versions="${kafka_mirror_maker_2_versions}
 ${version}={{ template \"strimzi.image\" (merge . (dict \"key\" \"kafkaMirrorMaker2\" \"tagSuffix\" \"-kafka-${version}\")) }}"
-    fi
 done
 
 kafka_versions=$(echo "$kafka_versions" | sed 's/^/                /g')
 kafka_connect_versions=$(echo "$kafka_connect_versions" | sed 's/^/                /g')
-kafka_mirror_maker_versions=$(echo "$kafka_mirror_maker_versions" | sed 's/^/                /g')
 kafka_exporter_versions=$(echo "$kafka_exporter_versions" | sed 's/^/                /g')
 kafka_mirror_maker_2_versions=$(echo "$kafka_mirror_maker_2_versions" | sed 's/^/                /g')
 
@@ -57,8 +52,6 @@ cat >"$out" <<EOF
               value: | ${kafka_versions}
             - name: STRIMZI_KAFKA_CONNECT_IMAGES
               value: | ${kafka_connect_versions}
-            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
-              value: | ${kafka_mirror_maker_versions}
             - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
               value: | ${kafka_mirror_maker_2_versions}
 {{- end -}}
diff --git a/packaging/install/Makefile b/packaging/install/Makefile
index c6a6bbe41e2..4cae501a5aa 100644
--- a/packaging/install/Makefile
+++ b/packaging/install/Makefile
@@ -13,7 +13,6 @@ crd_install:
 	$(CP) ./cluster-operator/042-Crd-strimzipodset.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/042-Crd-strimzipodset.yaml
 	$(CP) ./cluster-operator/043-Crd-kafkatopic.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/043-Crd-kafkatopic.yaml
 	$(CP) ./cluster-operator/044-Crd-kafkauser.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/044-Crd-kafkauser.yaml
-	$(CP) ./cluster-operator/045-Crd-kafkamirrormaker.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/045-Crd-kafkamirrormaker.yaml
 	$(CP) ./cluster-operator/046-Crd-kafkabridge.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/046-Crd-kafkabridge.yaml
 	$(CP) ./cluster-operator/047-Crd-kafkaconnector.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/047-Crd-kafkaconnector.yaml
 	$(CP) ./cluster-operator/048-Crd-kafkamirrormaker2.yaml ../helm-charts/helm3/strimzi-kafka-operator/crds/048-Crd-kafkamirrormaker2.yaml
@@ -24,7 +23,6 @@ crd_install:
 	yq eval -i '.metadata.labels.component="stirmzipodsets.core.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/042-Crd-strimzipodset.yaml
 	yq eval -i '.metadata.labels.component="kafkatopics.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/043-Crd-kafkatopic.yaml
 	yq eval -i '.metadata.labels.component="kafkausers.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/044-Crd-kafkauser.yaml
-	yq eval -i '.metadata.labels.component="kafkamirrormakers.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/045-Crd-kafkamirrormaker.yaml
 	yq eval -i '.metadata.labels.component="kafkabridges.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/046-Crd-kafkabridge.yaml
 	yq eval -i '.metadata.labels.component="kafkaconnectors.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/047-Crd-kafkaconnector.yaml
 	yq eval -i '.metadata.labels.component="kafkamirrormaker2.kafka.strimzi.io-crd"' ../helm-charts/helm3/strimzi-kafka-operator/crds/048-Crd-kafkamirrormaker2.yaml
diff --git a/packaging/install/cluster-operator/023-ClusterRole-strimzi-cluster-operator-role.yaml b/packaging/install/cluster-operator/023-ClusterRole-strimzi-cluster-operator-role.yaml
index 1e6c8774663..478d4b08d68 100644
--- a/packaging/install/cluster-operator/023-ClusterRole-strimzi-cluster-operator-role.yaml
+++ b/packaging/install/cluster-operator/023-ClusterRole-strimzi-cluster-operator-role.yaml
@@ -25,7 +25,6 @@ rules:
       - kafkanodepools
       - kafkaconnects
       - kafkaconnectors
-      - kafkamirrormakers
       - kafkabridges
       - kafkamirrormaker2s
       - kafkarebalances
@@ -44,7 +43,6 @@ rules:
       - kafkanodepools/status
       - kafkaconnects/status
       - kafkaconnectors/status
-      - kafkamirrormakers/status
       - kafkabridges/status
       - kafkamirrormaker2s/status
       - kafkarebalances/status
diff --git a/packaging/install/cluster-operator/045-Crd-kafkamirrormaker.yaml b/packaging/install/cluster-operator/045-Crd-kafkamirrormaker.yaml
deleted file mode 100644
index e5380d3c912..00000000000
--- a/packaging/install/cluster-operator/045-Crd-kafkamirrormaker.yaml
+++ /dev/null
@@ -1,1577 +0,0 @@
-apiVersion: apiextensions.k8s.io/v1
-kind: CustomResourceDefinition
-metadata:
-  name: kafkamirrormakers.kafka.strimzi.io
-  labels:
-    app: strimzi
-    strimzi.io/crd-install: "true"
-spec:
-  group: kafka.strimzi.io
-  names:
-    kind: KafkaMirrorMaker
-    listKind: KafkaMirrorMakerList
-    singular: kafkamirrormaker
-    plural: kafkamirrormakers
-    shortNames:
-    - kmm
-    categories:
-    - strimzi
-  scope: Namespaced
-  conversion:
-    strategy: None
-  versions:
-  - name: v1beta2
-    served: true
-    storage: true
-    subresources:
-      status: {}
-      scale:
-        specReplicasPath: .spec.replicas
-        statusReplicasPath: .status.replicas
-        labelSelectorPath: .status.labelSelector
-    additionalPrinterColumns:
-    - name: Desired replicas
-      description: The desired number of Kafka MirrorMaker replicas
-      jsonPath: .spec.replicas
-      type: integer
-    - name: Consumer Bootstrap Servers
-      description: The boostrap servers for the consumer
-      jsonPath: .spec.consumer.bootstrapServers
-      type: string
-      priority: 1
-    - name: Producer Bootstrap Servers
-      description: The boostrap servers for the producer
-      jsonPath: .spec.producer.bootstrapServers
-      type: string
-      priority: 1
-    - name: Ready
-      description: The state of the custom resource
-      jsonPath: ".status.conditions[?(@.type==\"Ready\")].status"
-      type: string
-    schema:
-      openAPIV3Schema:
-        type: object
-        properties:
-          apiVersion:
-            type: string
-            description: "APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources"
-          kind:
-            type: string
-            description: "Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"
-          metadata:
-            type: object
-          spec:
-            type: object
-            properties:
-              version:
-                type: string
-                description: The Kafka MirrorMaker version. Defaults to the latest version. Consult the documentation to understand the process required to upgrade or downgrade the version.
-              replicas:
-                type: integer
-                minimum: 0
-                description: The number of pods in the `Deployment`.
-              image:
-                type: string
-                description: "The container image used for Kafka MirrorMaker pods. If no image name is explicitly specified, it is determined based on the `spec.version` configuration. The image names are specifically mapped to corresponding versions in the Cluster Operator configuration."
-              consumer:
-                type: object
-                properties:
-                  numStreams:
-                    type: integer
-                    minimum: 1
-                    description: Specifies the number of consumer stream threads to create.
-                  offsetCommitInterval:
-                    type: integer
-                    description: Specifies the offset auto-commit interval in ms. Default value is 60000.
-                  bootstrapServers:
-                    type: string
-                    description: A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-                  groupId:
-                    type: string
-                    description: A unique string that identifies the consumer group this consumer belongs to.
-                  authentication:
-                    type: object
-                    properties:
-                      accessToken:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
-                      accessTokenIsJwt:
-                        type: boolean
-                        description: Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
-                      accessTokenLocation:
-                        type: string
-                        description: Path to the token file containing an access token to be used for authentication.
-                      audience:
-                        type: string
-                        description: "OAuth audience to use when authenticating against the authorization server. Some authorization servers require the audience to be explicitly set. The possible values depend on how the authorization server is configured. By default, `audience` is not specified when performing the token endpoint request."
-                      certificateAndKey:
-                        type: object
-                        properties:
-                          secretName:
-                            type: string
-                            description: The name of the Secret containing the certificate.
-                          certificate:
-                            type: string
-                            description: The name of the file certificate in the Secret.
-                          key:
-                            type: string
-                            description: The name of the private key in the Secret.
-                        required:
-                        - secretName
-                        - certificate
-                        - key
-                        description: Reference to the `Secret` which holds the certificate and private key pair.
-                      clientAssertion:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes secret containing the client assertion which was manually configured for the client.
-                      clientAssertionLocation:
-                        type: string
-                        description: Path to the file containing the client assertion to be used for authentication.
-                      clientAssertionType:
-                        type: string
-                        description: "The client assertion type. If not set, and either `clientAssertion` or `clientAssertionLocation` is configured, this value defaults to `urn:ietf:params:oauth:client-assertion-type:jwt-bearer`."
-                      clientId:
-                        type: string
-                        description: OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                      clientSecret:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                      connectTimeoutSeconds:
-                        type: integer
-                        description: "The connect timeout in seconds when connecting to authorization server. If not set, the effective connect timeout is 60 seconds."
-                      disableTlsHostnameVerification:
-                        type: boolean
-                        description: Enable or disable TLS hostname verification. Default value is `false`.
-                      enableMetrics:
-                        type: boolean
-                        description: Enable or disable OAuth metrics. Default value is `false`.
-                      httpRetries:
-                        type: integer
-                        description: "The maximum number of retries to attempt if an initial HTTP request fails. If not set, the default is to not attempt any retries."
-                      httpRetryPauseMs:
-                        type: integer
-                        description: "The pause to take before retrying a failed HTTP request. If not set, the default is to not pause at all but to immediately repeat a request."
-                      includeAcceptHeader:
-                        type: boolean
-                        description: Whether the Accept header should be set in requests to the authorization servers. The default value is `true`.
-                      maxTokenExpirySeconds:
-                        type: integer
-                        description: Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
-                      passwordSecret:
-                        type: object
-                        properties:
-                          secretName:
-                            type: string
-                            description: The name of the Secret containing the password.
-                          password:
-                            type: string
-                            description: The name of the key in the Secret under which the password is stored.
-                        required:
-                        - secretName
-                        - password
-                        description: Reference to the `Secret` which holds the password.
-                      readTimeoutSeconds:
-                        type: integer
-                        description: "The read timeout in seconds when connecting to authorization server. If not set, the effective read timeout is 60 seconds."
-                      refreshToken:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
-                      saslExtensions:
-                        additionalProperties:
-                          type: string
-                        type: object
-                        description: SASL extensions parameters.
-                      scope:
-                        type: string
-                        description: OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
-                      tlsTrustedCertificates:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the secret.
-                            pattern:
-                              type: string
-                              description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                          oneOf:
-                          - properties:
-                              certificate: {}
-                            required:
-                            - certificate
-                          - properties:
-                              pattern: {}
-                            required:
-                            - pattern
-                          required:
-                          - secretName
-                        description: Trusted certificates for TLS connection to the OAuth server.
-                      tokenEndpointUri:
-                        type: string
-                        description: Authorization server token endpoint URI.
-                      type:
-                        type: string
-                        enum:
-                        - tls
-                        - scram-sha-256
-                        - scram-sha-512
-                        - plain
-                        - oauth
-                        description: "Authentication type. Currently the supported types are `tls`, `scram-sha-256`, `scram-sha-512`, `plain`, and 'oauth'. `scram-sha-256` and `scram-sha-512` types use SASL SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication, respectively. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections."
-                      username:
-                        type: string
-                        description: Username used for the authentication.
-                    required:
-                    - type
-                    description: Authentication configuration for connecting to the cluster.
-                  tls:
-                    type: object
-                    properties:
-                      trustedCertificates:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the secret.
-                            pattern:
-                              type: string
-                              description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                          oneOf:
-                          - properties:
-                              certificate: {}
-                            required:
-                            - certificate
-                          - properties:
-                              pattern: {}
-                            required:
-                            - pattern
-                          required:
-                          - secretName
-                        description: Trusted certificates for TLS connection.
-                    description: TLS configuration for connecting MirrorMaker to the cluster.
-                  config:
-                    x-kubernetes-preserve-unknown-fields: true
-                    type: object
-                    description: "The MirrorMaker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols)."
-                required:
-                - bootstrapServers
-                - groupId
-                description: Configuration of source cluster.
-              producer:
-                type: object
-                properties:
-                  bootstrapServers:
-                    type: string
-                    description: A list of host:port pairs for establishing the initial connection to the Kafka cluster.
-                  abortOnSendFailure:
-                    type: boolean
-                    description: Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.
-                  authentication:
-                    type: object
-                    properties:
-                      accessToken:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
-                      accessTokenIsJwt:
-                        type: boolean
-                        description: Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
-                      accessTokenLocation:
-                        type: string
-                        description: Path to the token file containing an access token to be used for authentication.
-                      audience:
-                        type: string
-                        description: "OAuth audience to use when authenticating against the authorization server. Some authorization servers require the audience to be explicitly set. The possible values depend on how the authorization server is configured. By default, `audience` is not specified when performing the token endpoint request."
-                      certificateAndKey:
-                        type: object
-                        properties:
-                          secretName:
-                            type: string
-                            description: The name of the Secret containing the certificate.
-                          certificate:
-                            type: string
-                            description: The name of the file certificate in the Secret.
-                          key:
-                            type: string
-                            description: The name of the private key in the Secret.
-                        required:
-                        - secretName
-                        - certificate
-                        - key
-                        description: Reference to the `Secret` which holds the certificate and private key pair.
-                      clientAssertion:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes secret containing the client assertion which was manually configured for the client.
-                      clientAssertionLocation:
-                        type: string
-                        description: Path to the file containing the client assertion to be used for authentication.
-                      clientAssertionType:
-                        type: string
-                        description: "The client assertion type. If not set, and either `clientAssertion` or `clientAssertionLocation` is configured, this value defaults to `urn:ietf:params:oauth:client-assertion-type:jwt-bearer`."
-                      clientId:
-                        type: string
-                        description: OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                      clientSecret:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
-                      connectTimeoutSeconds:
-                        type: integer
-                        description: "The connect timeout in seconds when connecting to authorization server. If not set, the effective connect timeout is 60 seconds."
-                      disableTlsHostnameVerification:
-                        type: boolean
-                        description: Enable or disable TLS hostname verification. Default value is `false`.
-                      enableMetrics:
-                        type: boolean
-                        description: Enable or disable OAuth metrics. Default value is `false`.
-                      httpRetries:
-                        type: integer
-                        description: "The maximum number of retries to attempt if an initial HTTP request fails. If not set, the default is to not attempt any retries."
-                      httpRetryPauseMs:
-                        type: integer
-                        description: "The pause to take before retrying a failed HTTP request. If not set, the default is to not pause at all but to immediately repeat a request."
-                      includeAcceptHeader:
-                        type: boolean
-                        description: Whether the Accept header should be set in requests to the authorization servers. The default value is `true`.
-                      maxTokenExpirySeconds:
-                        type: integer
-                        description: Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
-                      passwordSecret:
-                        type: object
-                        properties:
-                          secretName:
-                            type: string
-                            description: The name of the Secret containing the password.
-                          password:
-                            type: string
-                            description: The name of the key in the Secret under which the password is stored.
-                        required:
-                        - secretName
-                        - password
-                        description: Reference to the `Secret` which holds the password.
-                      readTimeoutSeconds:
-                        type: integer
-                        description: "The read timeout in seconds when connecting to authorization server. If not set, the effective read timeout is 60 seconds."
-                      refreshToken:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                            description: The key under which the secret value is stored in the Kubernetes Secret.
-                          secretName:
-                            type: string
-                            description: The name of the Kubernetes Secret containing the secret value.
-                        required:
-                        - key
-                        - secretName
-                        description: Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
-                      saslExtensions:
-                        additionalProperties:
-                          type: string
-                        type: object
-                        description: SASL extensions parameters.
-                      scope:
-                        type: string
-                        description: OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
-                      tlsTrustedCertificates:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the secret.
-                            pattern:
-                              type: string
-                              description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                          oneOf:
-                          - properties:
-                              certificate: {}
-                            required:
-                            - certificate
-                          - properties:
-                              pattern: {}
-                            required:
-                            - pattern
-                          required:
-                          - secretName
-                        description: Trusted certificates for TLS connection to the OAuth server.
-                      tokenEndpointUri:
-                        type: string
-                        description: Authorization server token endpoint URI.
-                      type:
-                        type: string
-                        enum:
-                        - tls
-                        - scram-sha-256
-                        - scram-sha-512
-                        - plain
-                        - oauth
-                        description: "Authentication type. Currently the supported types are `tls`, `scram-sha-256`, `scram-sha-512`, `plain`, and 'oauth'. `scram-sha-256` and `scram-sha-512` types use SASL SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication, respectively. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections."
-                      username:
-                        type: string
-                        description: Username used for the authentication.
-                    required:
-                    - type
-                    description: Authentication configuration for connecting to the cluster.
-                  config:
-                    x-kubernetes-preserve-unknown-fields: true
-                    type: object
-                    description: "The MirrorMaker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols)."
-                  tls:
-                    type: object
-                    properties:
-                      trustedCertificates:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            secretName:
-                              type: string
-                              description: The name of the Secret containing the certificate.
-                            certificate:
-                              type: string
-                              description: The name of the file certificate in the secret.
-                            pattern:
-                              type: string
-                              description: "Pattern for the certificate files in the secret. Use the link:https://en.wikipedia.org/wiki/Glob_(programming)[_glob syntax_] for the pattern. All files in the secret that match the pattern are used."
-                          oneOf:
-                          - properties:
-                              certificate: {}
-                            required:
-                            - certificate
-                          - properties:
-                              pattern: {}
-                            required:
-                            - pattern
-                          required:
-                          - secretName
-                        description: Trusted certificates for TLS connection.
-                    description: TLS configuration for connecting MirrorMaker to the cluster.
-                required:
-                - bootstrapServers
-                description: Configuration of target cluster.
-              resources:
-                type: object
-                properties:
-                  claims:
-                    type: array
-                    items:
-                      type: object
-                      properties:
-                        name:
-                          type: string
-                  limits:
-                    additionalProperties:
-                      anyOf:
-                      - type: integer
-                      - type: string
-                      pattern: "^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$"
-                      x-kubernetes-int-or-string: true
-                    type: object
-                  requests:
-                    additionalProperties:
-                      anyOf:
-                      - type: integer
-                      - type: string
-                      pattern: "^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$"
-                      x-kubernetes-int-or-string: true
-                    type: object
-                description: CPU and memory resources to reserve.
-              whitelist:
-                type: string
-                description: "List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas."
-              include:
-                type: string
-                description: "List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the expression `A\\|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. You can also specify multiple regular expressions separated by commas."
-              jvmOptions:
-                type: object
-                properties:
-                  "-XX":
-                    additionalProperties:
-                      type: string
-                    type: object
-                    description: A map of -XX options to the JVM.
-                  "-Xmx":
-                    type: string
-                    pattern: "^[0-9]+[mMgG]?$"
-                    description: -Xmx option to to the JVM.
-                  "-Xms":
-                    type: string
-                    pattern: "^[0-9]+[mMgG]?$"
-                    description: -Xms option to to the JVM.
-                  gcLoggingEnabled:
-                    type: boolean
-                    description: Specifies whether the Garbage Collection logging is enabled. The default is false.
-                  javaSystemProperties:
-                    type: array
-                    items:
-                      type: object
-                      properties:
-                        name:
-                          type: string
-                          description: The system property name.
-                        value:
-                          type: string
-                          description: The system property value.
-                    description: A map of additional system properties which will be passed using the `-D` option to the JVM.
-                description: JVM Options for pods.
-              logging:
-                type: object
-                properties:
-                  loggers:
-                    additionalProperties:
-                      type: string
-                    type: object
-                    description: A Map from logger name to logger level.
-                  type:
-                    type: string
-                    enum:
-                    - inline
-                    - external
-                    description: "Logging type, must be either 'inline' or 'external'."
-                  valueFrom:
-                    type: object
-                    properties:
-                      configMapKeyRef:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                          name:
-                            type: string
-                          optional:
-                            type: boolean
-                        description: Reference to the key in the ConfigMap containing the configuration.
-                    description: '`ConfigMap` entry where the logging configuration is stored. '
-                required:
-                - type
-                description: Logging configuration for MirrorMaker.
-              metricsConfig:
-                type: object
-                properties:
-                  type:
-                    type: string
-                    enum:
-                    - jmxPrometheusExporter
-                    description: Metrics type. Only 'jmxPrometheusExporter' supported currently.
-                  valueFrom:
-                    type: object
-                    properties:
-                      configMapKeyRef:
-                        type: object
-                        properties:
-                          key:
-                            type: string
-                          name:
-                            type: string
-                          optional:
-                            type: boolean
-                        description: Reference to the key in the ConfigMap containing the configuration.
-                    description: 'ConfigMap entry where the Prometheus JMX Exporter configuration is stored. '
-                required:
-                - type
-                - valueFrom
-                description: Metrics configuration.
-              tracing:
-                type: object
-                properties:
-                  type:
-                    type: string
-                    enum:
-                    - jaeger
-                    - opentelemetry
-                    description: "Type of the tracing used. Currently the only supported type is `opentelemetry` for OpenTelemetry tracing. As of Strimzi 0.37.0, `jaeger` type is not supported anymore and this option is ignored."
-                required:
-                - type
-                description: The configuration of tracing in Kafka MirrorMaker.
-              template:
-                type: object
-                properties:
-                  deployment:
-                    type: object
-                    properties:
-                      metadata:
-                        type: object
-                        properties:
-                          labels:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Labels added to the Kubernetes resource.
-                          annotations:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Annotations added to the Kubernetes resource.
-                        description: Metadata applied to the resource.
-                      deploymentStrategy:
-                        type: string
-                        enum:
-                        - RollingUpdate
-                        - Recreate
-                        description: Pod replacement strategy for deployment configuration changes. Valid values are `RollingUpdate` and `Recreate`. Defaults to `RollingUpdate`.
-                    description: Template for Kafka MirrorMaker `Deployment`.
-                  pod:
-                    type: object
-                    properties:
-                      metadata:
-                        type: object
-                        properties:
-                          labels:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Labels added to the Kubernetes resource.
-                          annotations:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Annotations added to the Kubernetes resource.
-                        description: Metadata applied to the resource.
-                      imagePullSecrets:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            name:
-                              type: string
-                        description: "List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored."
-                      securityContext:
-                        type: object
-                        properties:
-                          appArmorProfile:
-                            type: object
-                            properties:
-                              localhostProfile:
-                                type: string
-                              type:
-                                type: string
-                          fsGroup:
-                            type: integer
-                          fsGroupChangePolicy:
-                            type: string
-                          runAsGroup:
-                            type: integer
-                          runAsNonRoot:
-                            type: boolean
-                          runAsUser:
-                            type: integer
-                          seLinuxOptions:
-                            type: object
-                            properties:
-                              level:
-                                type: string
-                              role:
-                                type: string
-                              type:
-                                type: string
-                              user:
-                                type: string
-                          seccompProfile:
-                            type: object
-                            properties:
-                              localhostProfile:
-                                type: string
-                              type:
-                                type: string
-                          supplementalGroups:
-                            type: array
-                            items:
-                              type: integer
-                          sysctls:
-                            type: array
-                            items:
-                              type: object
-                              properties:
-                                name:
-                                  type: string
-                                value:
-                                  type: string
-                          windowsOptions:
-                            type: object
-                            properties:
-                              gmsaCredentialSpec:
-                                type: string
-                              gmsaCredentialSpecName:
-                                type: string
-                              hostProcess:
-                                type: boolean
-                              runAsUserName:
-                                type: string
-                        description: Configures pod-level security attributes and common container settings.
-                      terminationGracePeriodSeconds:
-                        type: integer
-                        minimum: 0
-                        description: "The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds."
-                      affinity:
-                        type: object
-                        properties:
-                          nodeAffinity:
-                            type: object
-                            properties:
-                              preferredDuringSchedulingIgnoredDuringExecution:
-                                type: array
-                                items:
-                                  type: object
-                                  properties:
-                                    preference:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchFields:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                    weight:
-                                      type: integer
-                              requiredDuringSchedulingIgnoredDuringExecution:
-                                type: object
-                                properties:
-                                  nodeSelectorTerms:
-                                    type: array
-                                    items:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchFields:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                          podAffinity:
-                            type: object
-                            properties:
-                              preferredDuringSchedulingIgnoredDuringExecution:
-                                type: array
-                                items:
-                                  type: object
-                                  properties:
-                                    podAffinityTerm:
-                                      type: object
-                                      properties:
-                                        labelSelector:
-                                          type: object
-                                          properties:
-                                            matchExpressions:
-                                              type: array
-                                              items:
-                                                type: object
-                                                properties:
-                                                  key:
-                                                    type: string
-                                                  operator:
-                                                    type: string
-                                                  values:
-                                                    type: array
-                                                    items:
-                                                      type: string
-                                            matchLabels:
-                                              additionalProperties:
-                                                type: string
-                                              type: object
-                                        matchLabelKeys:
-                                          type: array
-                                          items:
-                                            type: string
-                                        mismatchLabelKeys:
-                                          type: array
-                                          items:
-                                            type: string
-                                        namespaceSelector:
-                                          type: object
-                                          properties:
-                                            matchExpressions:
-                                              type: array
-                                              items:
-                                                type: object
-                                                properties:
-                                                  key:
-                                                    type: string
-                                                  operator:
-                                                    type: string
-                                                  values:
-                                                    type: array
-                                                    items:
-                                                      type: string
-                                            matchLabels:
-                                              additionalProperties:
-                                                type: string
-                                              type: object
-                                        namespaces:
-                                          type: array
-                                          items:
-                                            type: string
-                                        topologyKey:
-                                          type: string
-                                    weight:
-                                      type: integer
-                              requiredDuringSchedulingIgnoredDuringExecution:
-                                type: array
-                                items:
-                                  type: object
-                                  properties:
-                                    labelSelector:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchLabels:
-                                          additionalProperties:
-                                            type: string
-                                          type: object
-                                    matchLabelKeys:
-                                      type: array
-                                      items:
-                                        type: string
-                                    mismatchLabelKeys:
-                                      type: array
-                                      items:
-                                        type: string
-                                    namespaceSelector:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchLabels:
-                                          additionalProperties:
-                                            type: string
-                                          type: object
-                                    namespaces:
-                                      type: array
-                                      items:
-                                        type: string
-                                    topologyKey:
-                                      type: string
-                          podAntiAffinity:
-                            type: object
-                            properties:
-                              preferredDuringSchedulingIgnoredDuringExecution:
-                                type: array
-                                items:
-                                  type: object
-                                  properties:
-                                    podAffinityTerm:
-                                      type: object
-                                      properties:
-                                        labelSelector:
-                                          type: object
-                                          properties:
-                                            matchExpressions:
-                                              type: array
-                                              items:
-                                                type: object
-                                                properties:
-                                                  key:
-                                                    type: string
-                                                  operator:
-                                                    type: string
-                                                  values:
-                                                    type: array
-                                                    items:
-                                                      type: string
-                                            matchLabels:
-                                              additionalProperties:
-                                                type: string
-                                              type: object
-                                        matchLabelKeys:
-                                          type: array
-                                          items:
-                                            type: string
-                                        mismatchLabelKeys:
-                                          type: array
-                                          items:
-                                            type: string
-                                        namespaceSelector:
-                                          type: object
-                                          properties:
-                                            matchExpressions:
-                                              type: array
-                                              items:
-                                                type: object
-                                                properties:
-                                                  key:
-                                                    type: string
-                                                  operator:
-                                                    type: string
-                                                  values:
-                                                    type: array
-                                                    items:
-                                                      type: string
-                                            matchLabels:
-                                              additionalProperties:
-                                                type: string
-                                              type: object
-                                        namespaces:
-                                          type: array
-                                          items:
-                                            type: string
-                                        topologyKey:
-                                          type: string
-                                    weight:
-                                      type: integer
-                              requiredDuringSchedulingIgnoredDuringExecution:
-                                type: array
-                                items:
-                                  type: object
-                                  properties:
-                                    labelSelector:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchLabels:
-                                          additionalProperties:
-                                            type: string
-                                          type: object
-                                    matchLabelKeys:
-                                      type: array
-                                      items:
-                                        type: string
-                                    mismatchLabelKeys:
-                                      type: array
-                                      items:
-                                        type: string
-                                    namespaceSelector:
-                                      type: object
-                                      properties:
-                                        matchExpressions:
-                                          type: array
-                                          items:
-                                            type: object
-                                            properties:
-                                              key:
-                                                type: string
-                                              operator:
-                                                type: string
-                                              values:
-                                                type: array
-                                                items:
-                                                  type: string
-                                        matchLabels:
-                                          additionalProperties:
-                                            type: string
-                                          type: object
-                                    namespaces:
-                                      type: array
-                                      items:
-                                        type: string
-                                    topologyKey:
-                                      type: string
-                        description: The pod's affinity rules.
-                      tolerations:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            effect:
-                              type: string
-                            key:
-                              type: string
-                            operator:
-                              type: string
-                            tolerationSeconds:
-                              type: integer
-                            value:
-                              type: string
-                        description: The pod's tolerations.
-                      topologySpreadConstraints:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            labelSelector:
-                              type: object
-                              properties:
-                                matchExpressions:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      key:
-                                        type: string
-                                      operator:
-                                        type: string
-                                      values:
-                                        type: array
-                                        items:
-                                          type: string
-                                matchLabels:
-                                  additionalProperties:
-                                    type: string
-                                  type: object
-                            matchLabelKeys:
-                              type: array
-                              items:
-                                type: string
-                            maxSkew:
-                              type: integer
-                            minDomains:
-                              type: integer
-                            nodeAffinityPolicy:
-                              type: string
-                            nodeTaintsPolicy:
-                              type: string
-                            topologyKey:
-                              type: string
-                            whenUnsatisfiable:
-                              type: string
-                        description: The pod's topology spread constraints.
-                      priorityClassName:
-                        type: string
-                        description: 'The name of the priority class used to assign priority to the pods. '
-                      schedulerName:
-                        type: string
-                        description: "The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used."
-                      hostAliases:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            hostnames:
-                              type: array
-                              items:
-                                type: string
-                            ip:
-                              type: string
-                        description: The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the Pod's hosts file if specified.
-                      enableServiceLinks:
-                        type: boolean
-                        description: Indicates whether information about services should be injected into Pod's environment variables.
-                      tmpDirSizeLimit:
-                        type: string
-                        pattern: "^([0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$"
-                        description: "Defines the total amount of pod memory allocated for the temporary `EmptyDir` volume `/tmp`. Specify the allocation in memory units, for example, `100Mi` for 100 mebibytes. Default value is `5Mi`. The `/tmp` volume is backed by pod memory, not disk storage, so avoid setting a high value as it consumes pod memory resources."
-                      volumes:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            name:
-                              type: string
-                              description: Name to use for the volume. Required.
-                            secret:
-                              type: object
-                              properties:
-                                defaultMode:
-                                  type: integer
-                                items:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      key:
-                                        type: string
-                                      mode:
-                                        type: integer
-                                      path:
-                                        type: string
-                                optional:
-                                  type: boolean
-                                secretName:
-                                  type: string
-                              description: Secret to use populate the volume.
-                            configMap:
-                              type: object
-                              properties:
-                                defaultMode:
-                                  type: integer
-                                items:
-                                  type: array
-                                  items:
-                                    type: object
-                                    properties:
-                                      key:
-                                        type: string
-                                      mode:
-                                        type: integer
-                                      path:
-                                        type: string
-                                name:
-                                  type: string
-                                optional:
-                                  type: boolean
-                              description: ConfigMap to use to populate the volume.
-                            emptyDir:
-                              type: object
-                              properties:
-                                medium:
-                                  type: string
-                                sizeLimit:
-                                  type: object
-                                  properties:
-                                    amount:
-                                      type: string
-                                    format:
-                                      type: string
-                              description: EmptyDir to use to populate the volume.
-                            persistentVolumeClaim:
-                              type: object
-                              properties:
-                                claimName:
-                                  type: string
-                                readOnly:
-                                  type: boolean
-                              description: PersistentVolumeClaim object to use to populate the volume.
-                            csi:
-                              type: object
-                              properties:
-                                driver:
-                                  type: string
-                                fsType:
-                                  type: string
-                                nodePublishSecretRef:
-                                  type: object
-                                  properties:
-                                    name:
-                                      type: string
-                                readOnly:
-                                  type: boolean
-                                volumeAttributes:
-                                  additionalProperties:
-                                    type: string
-                                  type: object
-                              description: CSIVolumeSource object to use to populate the volume.
-                          oneOf:
-                          - properties:
-                              secret: {}
-                              configMap: {}
-                              emptyDir: {}
-                              persistentVolumeClaim: {}
-                              csi: {}
-                        description: Additional volumes that can be mounted to the pod.
-                    description: Template for Kafka MirrorMaker `Pods`.
-                  podDisruptionBudget:
-                    type: object
-                    properties:
-                      metadata:
-                        type: object
-                        properties:
-                          labels:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Labels added to the Kubernetes resource.
-                          annotations:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Annotations added to the Kubernetes resource.
-                        description: Metadata to apply to the `PodDisruptionBudgetTemplate` resource.
-                      maxUnavailable:
-                        type: integer
-                        minimum: 0
-                        description: "Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1."
-                    description: Template for Kafka MirrorMaker `PodDisruptionBudget`.
-                  mirrorMakerContainer:
-                    type: object
-                    properties:
-                      env:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            name:
-                              type: string
-                              description: The environment variable key.
-                            value:
-                              type: string
-                              description: The environment variable value.
-                            valueFrom:
-                              type: object
-                              properties:
-                                secretKeyRef:
-                                  type: object
-                                  properties:
-                                    key:
-                                      type: string
-                                    name:
-                                      type: string
-                                    optional:
-                                      type: boolean
-                                  description: Reference to a key in a secret.
-                                configMapKeyRef:
-                                  type: object
-                                  properties:
-                                    key:
-                                      type: string
-                                    name:
-                                      type: string
-                                    optional:
-                                      type: boolean
-                                  description: Reference to a key in a config map.
-                              oneOf:
-                              - properties:
-                                  secretKeyRef: {}
-                                required:
-                                - secretKeyRef
-                              - properties:
-                                  configMapKeyRef: {}
-                                required:
-                                - configMapKeyRef
-                              description: Reference to the secret or config map property to which the environment variable is set.
-                          oneOf:
-                          - properties:
-                              value: {}
-                            required:
-                            - value
-                          - properties:
-                              valueFrom: {}
-                            required:
-                            - valueFrom
-                        description: Environment variables which should be applied to the container.
-                      securityContext:
-                        type: object
-                        properties:
-                          allowPrivilegeEscalation:
-                            type: boolean
-                          appArmorProfile:
-                            type: object
-                            properties:
-                              localhostProfile:
-                                type: string
-                              type:
-                                type: string
-                          capabilities:
-                            type: object
-                            properties:
-                              add:
-                                type: array
-                                items:
-                                  type: string
-                              drop:
-                                type: array
-                                items:
-                                  type: string
-                          privileged:
-                            type: boolean
-                          procMount:
-                            type: string
-                          readOnlyRootFilesystem:
-                            type: boolean
-                          runAsGroup:
-                            type: integer
-                          runAsNonRoot:
-                            type: boolean
-                          runAsUser:
-                            type: integer
-                          seLinuxOptions:
-                            type: object
-                            properties:
-                              level:
-                                type: string
-                              role:
-                                type: string
-                              type:
-                                type: string
-                              user:
-                                type: string
-                          seccompProfile:
-                            type: object
-                            properties:
-                              localhostProfile:
-                                type: string
-                              type:
-                                type: string
-                          windowsOptions:
-                            type: object
-                            properties:
-                              gmsaCredentialSpec:
-                                type: string
-                              gmsaCredentialSpecName:
-                                type: string
-                              hostProcess:
-                                type: boolean
-                              runAsUserName:
-                                type: string
-                        description: Security context for the container.
-                      volumeMounts:
-                        type: array
-                        items:
-                          type: object
-                          properties:
-                            mountPath:
-                              type: string
-                            mountPropagation:
-                              type: string
-                            name:
-                              type: string
-                            readOnly:
-                              type: boolean
-                            recursiveReadOnly:
-                              type: string
-                            subPath:
-                              type: string
-                            subPathExpr:
-                              type: string
-                        description: Additional volume mounts which should be applied to the container.
-                    description: Template for Kafka MirrorMaker container.
-                  serviceAccount:
-                    type: object
-                    properties:
-                      metadata:
-                        type: object
-                        properties:
-                          labels:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Labels added to the Kubernetes resource.
-                          annotations:
-                            additionalProperties:
-                              type: string
-                            type: object
-                            description: Annotations added to the Kubernetes resource.
-                        description: Metadata applied to the resource.
-                    description: Template for the Kafka MirrorMaker service account.
-                description: "Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated."
-              livenessProbe:
-                type: object
-                properties:
-                  initialDelaySeconds:
-                    type: integer
-                    minimum: 0
-                    description: The initial delay before first the health is first checked. Default to 15 seconds. Minimum value is 0.
-                  timeoutSeconds:
-                    type: integer
-                    minimum: 1
-                    description: The timeout for each attempted health check. Default to 5 seconds. Minimum value is 1.
-                  periodSeconds:
-                    type: integer
-                    minimum: 1
-                    description: How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
-                  successThreshold:
-                    type: integer
-                    minimum: 1
-                    description: Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
-                  failureThreshold:
-                    type: integer
-                    minimum: 1
-                    description: Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
-                description: Pod liveness checking.
-              readinessProbe:
-                type: object
-                properties:
-                  initialDelaySeconds:
-                    type: integer
-                    minimum: 0
-                    description: The initial delay before first the health is first checked. Default to 15 seconds. Minimum value is 0.
-                  timeoutSeconds:
-                    type: integer
-                    minimum: 1
-                    description: The timeout for each attempted health check. Default to 5 seconds. Minimum value is 1.
-                  periodSeconds:
-                    type: integer
-                    minimum: 1
-                    description: How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
-                  successThreshold:
-                    type: integer
-                    minimum: 1
-                    description: Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
-                  failureThreshold:
-                    type: integer
-                    minimum: 1
-                    description: Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
-                description: Pod readiness checking.
-            oneOf:
-            - properties:
-                include: {}
-              required:
-              - include
-            - properties:
-                whitelist: {}
-              required:
-              - whitelist
-            required:
-            - replicas
-            - consumer
-            - producer
-            description: The specification of Kafka MirrorMaker.
-          status:
-            type: object
-            properties:
-              conditions:
-                type: array
-                items:
-                  type: object
-                  properties:
-                    type:
-                      type: string
-                      description: "The unique identifier of a condition, used to distinguish between other conditions in the resource."
-                    status:
-                      type: string
-                      description: "The status of the condition, either True, False or Unknown."
-                    lastTransitionTime:
-                      type: string
-                      description: "Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone."
-                    reason:
-                      type: string
-                      description: The reason for the condition's last transition (a single word in CamelCase).
-                    message:
-                      type: string
-                      description: Human-readable message indicating details about the condition's last transition.
-                description: List of status conditions.
-              observedGeneration:
-                type: integer
-                description: The generation of the CRD that was last reconciled by the operator.
-              labelSelector:
-                type: string
-                description: Label selector for pods providing this resource.
-              replicas:
-                type: integer
-                description: The current number of pods being used to provide this resource.
-            description: The status of Kafka MirrorMaker.
diff --git a/packaging/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml b/packaging/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml
index 1559494af32..737774679ff 100644
--- a/packaging/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml
+++ b/packaging/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml
@@ -61,11 +61,6 @@ spec:
                 3.8.0=quay.io/strimzi/kafka:latest-kafka-3.8.0
                 3.8.1=quay.io/strimzi/kafka:latest-kafka-3.8.1
                 3.9.0=quay.io/strimzi/kafka:latest-kafka-3.9.0
-            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
-              value: |
-                3.8.0=quay.io/strimzi/kafka:latest-kafka-3.8.0
-                3.8.1=quay.io/strimzi/kafka:latest-kafka-3.8.1
-                3.9.0=quay.io/strimzi/kafka:latest-kafka-3.9.0
             - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
               value: |
                 3.8.0=quay.io/strimzi/kafka:latest-kafka-3.8.0
diff --git a/packaging/install/strimzi-admin/010-ClusterRole-strimzi-admin.yaml b/packaging/install/strimzi-admin/010-ClusterRole-strimzi-admin.yaml
index 85f92eff115..263a377c9b1 100644
--- a/packaging/install/strimzi-admin/010-ClusterRole-strimzi-admin.yaml
+++ b/packaging/install/strimzi-admin/010-ClusterRole-strimzi-admin.yaml
@@ -14,7 +14,6 @@ rules:
   - kafkas
   - kafkanodepools
   - kafkaconnects
-  - kafkamirrormakers
   - kafkausers
   - kafkatopics
   - kafkabridges
@@ -34,7 +33,6 @@ rules:
   resources:
   - kafkanodepools/scale
   - kafkaconnects/scale
-  - kafkamirrormakers/scale
   - kafkabridges/scale
   - kafkaconnectors/scale
   - kafkamirrormaker2s/scale
diff --git a/packaging/install/strimzi-admin/020-ClusterRole-strimzi-view.yaml b/packaging/install/strimzi-admin/020-ClusterRole-strimzi-view.yaml
index f0a5ef875a6..dca6ff35d20 100644
--- a/packaging/install/strimzi-admin/020-ClusterRole-strimzi-view.yaml
+++ b/packaging/install/strimzi-admin/020-ClusterRole-strimzi-view.yaml
@@ -13,7 +13,6 @@ rules:
   - kafkas
   - kafkanodepools
   - kafkaconnects
-  - kafkamirrormakers
   - kafkausers
   - kafkatopics
   - kafkabridges
diff --git a/pom.xml b/pom.xml
index 0d1e1d684fc..165a7dba55d 100644
--- a/pom.xml
+++ b/pom.xml
@@ -188,7 +188,6 @@
 
     <modules>
         <module>kafka-agent</module>
-        <module>mirror-maker-agent</module>
         <module>tracing-agent</module>
         <module>test</module>
         <module>crd-annotations</module>
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java b/systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
index eabf146aff2..cc4b5fca848 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
@@ -14,7 +14,7 @@
  */
 public interface TestConstants {
     long TIMEOUT_FOR_RESOURCE_RECOVERY = Duration.ofMinutes(6).toMillis();
-    long TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS = Duration.ofMinutes(7).toMillis();
+    long TIMEOUT_FOR_MIRROR_MAKER_2_COPY_MESSAGES_BETWEEN_BROKERS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_LOG = Duration.ofMinutes(2).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_READINESS = Duration.ofSeconds(1).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_DELETION = Duration.ofSeconds(5).toMillis();
@@ -208,7 +208,6 @@ public interface TestConstants {
     String PATH_TO_KAFKA_CRUISE_CONTROL_METRICS_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/metrics/kafka-cruise-control-metrics.yaml";
     String PATH_TO_KAFKA_TOPIC_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/topic/kafka-topic.yaml";
     String PATH_TO_KAFKA_CONNECTOR_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/connect/source-connector.yaml";
-    String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/mirror-maker/kafka-mirror-maker.yaml";
     String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/mirror-maker/kafka-mirror-maker-2.yaml";
     String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/metrics/kafka-mirror-maker-2-metrics.yaml";
 
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/TestTags.java b/systemtest/src/main/java/io/strimzi/systemtest/TestTags.java
index d3c25197879..828ce3f515f 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/TestTags.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/TestTags.java
@@ -106,11 +106,6 @@ public interface TestTags {
      */
     String CONNECT = "connect";
 
-    /**
-     * Tag for tests which deploys KafkaMirrorMaker resource
-     */
-    String MIRROR_MAKER = "mirrormaker";
-
     /**
      * Tag for tests which deploys KafkaMirrorMaker2 resource
      */
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/logs/TestLogCollector.java b/systemtest/src/main/java/io/strimzi/systemtest/logs/TestLogCollector.java
index 840cf99eb3c..1433696786d 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/logs/TestLogCollector.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/logs/TestLogCollector.java
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.model.connect.KafkaConnect;
 import io.strimzi.api.kafka.model.connector.KafkaConnector;
 import io.strimzi.api.kafka.model.kafka.Kafka;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.nodepool.KafkaNodePool;
 import io.strimzi.api.kafka.model.rebalance.KafkaRebalance;
@@ -133,7 +132,6 @@ public TestLogCollector() {
      *
      * @return  {@link LogCollector} configured with default configuration for the tests
      */
-    @SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
     private LogCollector defaultLogCollector() {
         List<String> resources = new ArrayList<>(List.of(
             TestConstants.SECRET.toLowerCase(Locale.ROOT),
@@ -144,7 +142,6 @@ private LogCollector defaultLogCollector() {
             KafkaConnect.RESOURCE_SINGULAR,
             KafkaConnector.RESOURCE_SINGULAR,
             KafkaBridge.RESOURCE_SINGULAR,
-            KafkaMirrorMaker.RESOURCE_SINGULAR,
             KafkaMirrorMaker2.RESOURCE_SINGULAR,
             KafkaRebalance.RESOURCE_SINGULAR,
             KafkaTopic.RESOURCE_SINGULAR,
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/resources/ComponentType.java b/systemtest/src/main/java/io/strimzi/systemtest/resources/ComponentType.java
deleted file mode 100644
index d73f1923d05..00000000000
--- a/systemtest/src/main/java/io/strimzi/systemtest/resources/ComponentType.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.systemtest.resources;
-
-public enum ComponentType {
-    Kafka,
-    KafkaBridge,
-    KafkaConnect,
-    KafkaMirrorMaker,
-    KafkaMirrorMaker2,
-    CruiseControl,
-    Zookeeper,
-    KafkaExporter,
-    UserOperator,
-    TopicOperator,
-    ClusterOperator,
-}
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java b/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
index 0422c69a443..2b4eb3176db 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
@@ -35,7 +35,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMaker2Resource;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaNodePoolResource;
 import io.strimzi.systemtest.resources.crd.KafkaRebalanceResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -138,7 +137,6 @@ public static ExtensionContext getTestContext() {
         new KafkaConnectorResource(),
         new KafkaConnectResource(),
         new KafkaMirrorMaker2Resource(),
-        new KafkaMirrorMakerResource(),
         new KafkaRebalanceResource(),
         new KafkaResource(),
         new KafkaTopicResource(),
@@ -327,7 +325,7 @@ public final <T extends HasMetadata> boolean waitResourceCondition(T resource, R
 
     /**
      * Auxiliary method for copying {@link TestConstants#TEST_SUITE_NAME_LABEL} and {@link TestConstants#TEST_CASE_NAME_LABEL} labels
-     * into PodTemplate ensuring that in case of failure {@link io.strimzi.systemtest.logs.LogCollector} will collect all
+     * into PodTemplate ensuring that in case of failure {@link io.strimzi.systemtest.logs.TestLogCollector} will collect all
      * related Pods, which corespondents to such Controller (i.e., Job, Deployment)
      *
      * @param resource controller resource from which we copy test suite or test case labels
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java b/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
index 52782c7cd82..e279b6330b8 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
@@ -8,7 +8,6 @@
 import io.strimzi.api.kafka.model.connect.KafkaConnect;
 import io.strimzi.api.kafka.model.connector.KafkaConnector;
 import io.strimzi.api.kafka.model.kafka.Kafka;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.podset.StrimziPodSet;
 import io.strimzi.api.kafka.model.rebalance.KafkaRebalanceState;
@@ -21,8 +20,6 @@ public static long getTimeoutForResourceReadiness() {
         return getTimeoutForResourceReadiness("default");
     }
 
-    // Deprecation is suppressed because of KafkaMirrorMaker
-    @SuppressWarnings("deprecation")
     public static long getTimeoutForResourceReadiness(String kind) {
         long timeout;
 
@@ -35,7 +32,6 @@ public static long getTimeoutForResourceReadiness(String kind) {
             case TestConstants.DEPLOYMENT_CONFIG:
                 timeout = Duration.ofMinutes(10).toMillis();
                 break;
-            case KafkaMirrorMaker.RESOURCE_KIND:
             case KafkaBridge.RESOURCE_KIND:
             case TestConstants.STATEFUL_SET:
             case StrimziPodSet.RESOURCE_KIND:
@@ -81,8 +77,6 @@ public static long getTimeoutForResourceDeletion() {
         return getTimeoutForResourceDeletion("default");
     }
 
-    // Deprecation is suppressed because of KafkaMirrorMaker
-    @SuppressWarnings("deprecation")
     public static long getTimeoutForResourceDeletion(String kind) {
         long timeout;
 
@@ -90,7 +84,6 @@ public static long getTimeoutForResourceDeletion(String kind) {
             case Kafka.RESOURCE_KIND:
             case KafkaConnect.RESOURCE_KIND:
             case KafkaMirrorMaker2.RESOURCE_KIND:
-            case KafkaMirrorMaker.RESOURCE_KIND:
             case KafkaBridge.RESOURCE_KIND:
             case TestConstants.STATEFUL_SET:
             case TestConstants.POD:
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java b/systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
deleted file mode 100644
index c7bd54af4b3..00000000000
--- a/systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.systemtest.resources.crd;
-
-import io.fabric8.kubernetes.api.model.DeletionPropagation;
-import io.fabric8.kubernetes.api.model.LabelSelector;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
-import io.fabric8.kubernetes.client.dsl.MixedOperation;
-import io.fabric8.kubernetes.client.dsl.Resource;
-import io.strimzi.api.kafka.Crds;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerList;
-import io.strimzi.operator.common.model.Labels;
-import io.strimzi.systemtest.enums.CustomResourceStatus;
-import io.strimzi.systemtest.resources.ResourceManager;
-import io.strimzi.systemtest.resources.ResourceType;
-
-import java.util.function.Consumer;
-
-// Deprecation is suppressed because of KafkaMirrorMaker
-@SuppressWarnings("deprecation")
-public class KafkaMirrorMakerResource implements ResourceType<KafkaMirrorMaker> {
-
-    @Override
-    public String getKind() {
-        return KafkaMirrorMaker.RESOURCE_KIND;
-    }
-    @Override
-    public KafkaMirrorMaker get(String namespace, String name) {
-        return kafkaMirrorMakerClient().inNamespace(namespace).withName(name).get();
-    }
-    @Override
-    public void create(KafkaMirrorMaker resource) {
-        kafkaMirrorMakerClient().inNamespace(resource.getMetadata().getNamespace()).resource(resource).create();
-    }
-    @Override
-    public void delete(KafkaMirrorMaker resource) {
-        kafkaMirrorMakerClient().inNamespace(resource.getMetadata().getNamespace()).withName(
-            resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
-    }
-
-    @Override
-    public void update(KafkaMirrorMaker resource) {
-        kafkaMirrorMakerClient().inNamespace(resource.getMetadata().getNamespace()).resource(resource).update();
-    }
-
-    @Override
-    public boolean waitForReadiness(KafkaMirrorMaker resource) {
-        return ResourceManager.waitForResourceStatus(kafkaMirrorMakerClient(), resource, CustomResourceStatus.Ready);
-    }
-
-    public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>> kafkaMirrorMakerClient() {
-        return Crds.mirrorMakerOperation(ResourceManager.kubeClient().getClient());
-    }
-
-    public static void replaceMirrorMakerResourceInSpecificNamespace(String namespaceName, String resourceName, Consumer<KafkaMirrorMaker> editor) {
-        ResourceManager.replaceCrdResource(namespaceName, KafkaMirrorMaker.class, KafkaMirrorMakerList.class, resourceName, editor);
-    }
-
-    public static LabelSelector getLabelSelector(String clusterName, String componentName) {
-        java.util.Map<String, String> matchLabels = new java.util.HashMap<>();
-        matchLabels.put(Labels.STRIMZI_CLUSTER_LABEL, clusterName);
-        matchLabels.put(Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND);
-        matchLabels.put(Labels.STRIMZI_NAME_LABEL, componentName);
-
-        return new LabelSelectorBuilder()
-            .withMatchLabels(matchLabels)
-            .build();
-    }
-}
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMakerTemplates.java b/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMakerTemplates.java
deleted file mode 100644
index 3f18eb1d059..00000000000
--- a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMakerTemplates.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.systemtest.templates.crd;
-
-import io.fabric8.kubernetes.api.model.Quantity;
-import io.fabric8.kubernetes.api.model.ResourceRequirementsBuilder;
-import io.strimzi.api.kafka.model.kafka.KafkaResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerBuilder;
-import io.strimzi.systemtest.Environment;
-import org.apache.kafka.clients.consumer.ConsumerConfig;
-import org.apache.kafka.clients.producer.ProducerConfig;
-
-// Deprecation is suppressed because of KafkaMirrorMaker
-@SuppressWarnings("deprecation")
-public class KafkaMirrorMakerTemplates {
-
-    private KafkaMirrorMakerTemplates() {}
-
-    public static KafkaMirrorMakerBuilder kafkaMirrorMaker(
-        String namespaceName,
-        String kafkaMirrorMaker1Name,
-        String sourceBootstrapServer,
-        String targetBootstrapServer,
-        String groupId,
-        int mirrorMakerReplicas,
-        boolean tlsListener
-    ) {
-        return defaultKafkaMirrorMaker(namespaceName, kafkaMirrorMaker1Name, sourceBootstrapServer, targetBootstrapServer, groupId, mirrorMakerReplicas, tlsListener);
-    }
-
-    private static KafkaMirrorMakerBuilder defaultKafkaMirrorMaker(
-        String namespaceName,
-        String kafkaMirrorMaker1Name,
-        String sourceBootstrapServer,
-        String targetBootstrapServer,
-        String groupId,
-        int kafkaMirrorMakerReplicas,
-        boolean tlsListener
-    ) {
-        KafkaMirrorMakerBuilder kmmb = new KafkaMirrorMakerBuilder()
-            .withNewMetadata()
-                .withName(kafkaMirrorMaker1Name)
-                .withNamespace(namespaceName)
-            .endMetadata()
-            .editSpec()
-                .withVersion(Environment.ST_KAFKA_VERSION)
-                .withNewConsumer()
-                    .withBootstrapServers(tlsListener ? KafkaResources.tlsBootstrapAddress(sourceBootstrapServer) : KafkaResources.plainBootstrapAddress(sourceBootstrapServer))
-                    .withGroupId(groupId)
-                    .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
-                .endConsumer()
-                .withNewProducer()
-                    .withBootstrapServers(tlsListener ? KafkaResources.tlsBootstrapAddress(targetBootstrapServer) : KafkaResources.plainBootstrapAddress(targetBootstrapServer))
-                    .addToConfig(ProducerConfig.ACKS_CONFIG, "all")
-                .endProducer()
-                .withReplicas(kafkaMirrorMakerReplicas)
-                .withInclude(".*")
-                .withNewInlineLogging()
-                    .addToLoggers("mirrormaker.root.logger", "DEBUG")
-                .endInlineLogging()
-            .endSpec();
-
-        if (!Environment.isSharedMemory()) {
-            kmmb.editSpec().withResources(new ResourceRequirementsBuilder()
-                // we use such values, because on environments where it is limited to 7Gi, we are unable to deploy
-                // Cluster Operator, two Kafka clusters and MirrorMaker/2. Such situation may result in an OOM problem.
-                // Using 1Gi is too much and on the other hand 512Mi is causing OOM problem at the start.
-                .addToLimits("memory", new Quantity("784Mi"))
-                .addToRequests("memory", new Quantity("784Mi"))
-                .build());
-        }
-
-        return kmmb;
-
-    }
-}
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaNodePoolTemplates.java b/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaNodePoolTemplates.java
index f2f87eae131..e1746fc2c1a 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaNodePoolTemplates.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaNodePoolTemplates.java
@@ -46,7 +46,7 @@ public static KafkaNodePoolBuilder defaultKafkaNodePool(String namespaceName, St
                 kafkaNodePoolBuilder
                     .editSpec()
                         // we use such values, because on environments where it is limited to 7Gi, we are unable to deploy
-                        // Cluster Operator, two Kafka clusters and MirrorMaker/2. Such situation may result in an OOM problem.
+                        // Cluster Operator, two Kafka clusters and MirrorMaker 2. Such situation may result in an OOM problem.
                         // For Kafka using 784Mi is too much and on the other hand 256Mi is causing OOM problem at the start.
                         .withResources(new ResourceRequirementsBuilder()
                             .addToLimits("memory", new Quantity("512Mi"))
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java b/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
index d4b2e71771d..95e7fcc30ef 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
@@ -413,7 +413,7 @@ private static void setMemoryRequestsAndLimitsIfNeeded(KafkaBuilder kafkaBuilder
                 kafkaBuilder.editSpec()
                         .editKafka()
                             // we use such values, because on environments where it is limited to 7Gi, we are unable to deploy
-                            // Cluster Operator, two Kafka clusters and MirrorMaker/2. Such situation may result in an OOM problem.
+                            // Cluster Operator, two Kafka clusters and MirrorMaker 2. Such situation may result in an OOM problem.
                             // For Kafka using 784Mi is too much and on the other hand 256Mi is causing OOM problem at the start.
                             .withResources(new ResourceRequirementsBuilder()
                                 .addToLimits("memory", new Quantity("512Mi"))
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java b/systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java
index 5eb7f0c4e5c..178e2ebb620 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java
@@ -13,7 +13,6 @@ public interface TracingConstants {
     String JAEGER_PRODUCER_SERVICE = "hello-world-producer";
     String JAEGER_CONSUMER_SERVICE = "hello-world-consumer";
     String JAEGER_KAFKA_STREAMS_SERVICE = "hello-world-streams";
-    String JAEGER_MIRROR_MAKER_SERVICE = "my-mirror-maker";
     String JAEGER_MIRROR_MAKER2_SERVICE = "my-mirror-maker2";
     String JAEGER_KAFKA_CONNECT_SERVICE = "my-connect";
     String JAEGER_KAFKA_BRIDGE_SERVICE = "my-kafka-bridge";
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/VerificationUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/VerificationUtils.java
index 6c2ca866cdb..ecf0905c1d9 100644
--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/VerificationUtils.java
+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/VerificationUtils.java
@@ -15,7 +15,6 @@
 import io.strimzi.api.kafka.model.connect.KafkaConnectResources;
 import io.strimzi.api.kafka.model.kafka.Kafka;
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Environment;
@@ -260,7 +259,6 @@ public static void verifyPodsLabels(String namespaceName, String podNamePrefix,
      * @param clusterName Name of the cluster linked with configmaps
      * @param additionalClusterName Name of the second cluster - used mainly for source + target cluster verification
      */
-    @SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
     public static void verifyConfigMapsLabels(String namespaceName, String clusterName, String additionalClusterName) {
         LOGGER.info("Verifying labels for Config maps");
 
@@ -270,9 +268,6 @@ public static void verifyConfigMapsLabels(String namespaceName, String clusterNa
                 if (cm.getMetadata().getName().equals(clusterName.concat("-connect-config"))) {
                     assertThat(cm.getMetadata().getLabels().get("app"), is(nullValue()));
                     assertThat(cm.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(KafkaConnect.RESOURCE_KIND));
-                } else if (cm.getMetadata().getName().contains("-mirror-maker-config")) {
-                    assertThat(cm.getMetadata().getLabels().get("app"), is(nullValue()));
-                    assertThat(cm.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(KafkaMirrorMaker.RESOURCE_KIND));
                 } else if (cm.getMetadata().getName().contains("-mirrormaker2-config")) {
                     assertThat(cm.getMetadata().getLabels().get("app"), is(nullValue()));
                     assertThat(cm.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(KafkaMirrorMaker2.RESOURCE_KIND));
@@ -312,7 +307,6 @@ public static void verifyServiceLabels(String namespaceName, String serviceName,
      * @param namespaceName Namespace name where service accounts are located
      * @param clusterName Name of the cluster linked with service accounts
      */
-    @SuppressWarnings("deprecation") // Kafka Mirror Maker is deprecated
     public static void verifyServiceAccountsLabels(String namespaceName, String clusterName) {
         LOGGER.info("Verifying labels for Service Accounts");
 
@@ -331,9 +325,6 @@ public static void verifyServiceAccountsLabels(String namespaceName, String clus
                 if (sa.getMetadata().getName().equals(clusterName.concat("-connect"))) {
                     assertThat(sa.getMetadata().getLabels().get("app"), is(nullValue()));
                     assertThat(sa.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(KafkaConnect.RESOURCE_KIND));
-                } else if (sa.getMetadata().getName().equals(clusterName.concat("-mirror-maker"))) {
-                    assertThat(sa.getMetadata().getLabels().get("app"), is(nullValue()));
-                    assertThat(sa.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(KafkaMirrorMaker.RESOURCE_KIND));
                 } else {
                     assertThat(sa.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(Kafka.RESOURCE_KIND));
                 }
diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMakerUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMakerUtils.java
deleted file mode 100644
index ea8e6935217..00000000000
--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMakerUtils.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.systemtest.utils.kafkaUtils;
-
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.systemtest.resources.ResourceManager;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
-
-import static io.strimzi.systemtest.enums.CustomResourceStatus.NotReady;
-import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
-
-public class KafkaMirrorMakerUtils {
-
-    private KafkaMirrorMakerUtils() {}
-
-    /**
-     * Wait until KafkaMirrorMaker status is in desired state
-     * @param namespaceName Namespace where MirrorMaker resource is located
-     * @param clusterName name of KafkaMirrorMaker cluster
-     * @param state desired state - like Ready
-     */
-    // Deprecation is suppressed because of KafkaMirrorMaker
-    @SuppressWarnings("deprecation")
-    public static boolean waitForKafkaMirrorMakerStatus(String namespaceName, String clusterName, Enum<?>  state) {
-        KafkaMirrorMaker kafkaMirrorMaker = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(namespaceName).withName(clusterName).get();
-        return ResourceManager.waitForResourceStatus(KafkaMirrorMakerResource.kafkaMirrorMakerClient(), kafkaMirrorMaker, state);
-    }
-
-    public static boolean waitForKafkaMirrorMakerReady(String namespaceName, String clusterName) {
-        return waitForKafkaMirrorMakerStatus(namespaceName, clusterName, Ready);
-    }
-
-    public static boolean waitForKafkaMirrorMakerNotReady(final String namespaceName, String clusterName) {
-        return waitForKafkaMirrorMakerStatus(namespaceName, clusterName, NotReady);
-    }
-}
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java b/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
index 4bce9bc141c..dc580b36714 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
@@ -174,7 +174,7 @@ void setUp() {
 
         resourceManager.createResourceWithWait(scramShaUser);
 
-        // Initialize PasswordSecret to set this as PasswordSecret in MirrorMaker spec
+        // Initialize PasswordSecret to set this as PasswordSecret in Bridge spec
         PasswordSecretSource passwordSecret = new PasswordSecretSource();
         passwordSecret.setSecretName(suiteTestStorage.getUsername());
         passwordSecret.setPassword("password");
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java b/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
index 682fccd40d9..afef803e662 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
@@ -148,7 +148,7 @@ void testTlsScramShaAuthWithWeirdUsername() {
         // Create weird named user with . and more than 64 chars -> SCRAM-SHA
         final String weirdUserName = "jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi";
 
-        // Initialize PasswordSecret to set this as PasswordSecret in MirrorMaker spec
+        // Initialize PasswordSecret to set this as PasswordSecret in Bridge spec
         final PasswordSecretSource passwordSecret = new PasswordSecretSource();
         passwordSecret.setSecretName(weirdUserName);
         passwordSecret.setPassword("password");
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java b/systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
index 5373e1272ed..9b4f9ef7b3f 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
@@ -908,7 +908,7 @@ void testCustomAndUpdatedValues() {
                 is(not("test.value"))
         );
 
-        LOGGER.info("Updating values in MirrorMaker container");
+        LOGGER.info("Updating values in Connect container");
 
         KafkaConnectResource.replaceKafkaConnectResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(), kc -> {
             kc.getSpec().getTemplate().getConnectContainer().setEnv(StUtils.createContainerEnvVarsFromMap(envVarUpdated));
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java b/systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
index 8ab038137f2..6bec7948f71 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
@@ -15,7 +15,6 @@
 import io.strimzi.api.kafka.model.connect.KafkaConnectResources;
 import io.strimzi.api.kafka.model.kafka.Kafka;
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2Resources;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
@@ -28,7 +27,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMaker2Resource;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaNodePoolResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.StrimziPodSetResource;
@@ -36,7 +34,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -69,7 +66,6 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CRUISE_CONTROL;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
@@ -143,7 +139,7 @@ class LogSettingST extends AbstractST {
         }
     };
 
-    private static final Map<String, String> MIRROR_MAKER_LOGGERS = new HashMap<>() {
+    private static final Map<String, String> MIRROR_MAKER_2_LOGGERS = new HashMap<>() {
         {
             put("mirrormaker.root.logger", TRACE);
             put("test.mirrormaker.logger.level", TRACE);
@@ -293,43 +289,11 @@ void testConnectLogSetting() {
 
         LOGGER.info("Checking if Connect has log level set properly");
         assertThat("KafkaConnect's log level is set properly", checkLoggersLevel(Environment.TEST_SUITE_NAMESPACE, CONNECT_LOGGERS, connectMap), is(true));
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getKafkaConnectSelector(), connectDepName, true);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getKafkaConnectSelector(), true);
 
         KafkaConnectResource.replaceKafkaConnectResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), kc -> kc.getSpec().setJvmOptions(JVM_OPTIONS));
         StUtils.waitTillStrimziPodSetOrDeploymentRolled(Environment.TEST_SUITE_NAMESPACE, connectDepName, 1, connectPods, testStorage.getKafkaConnectSelector());
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getKafkaConnectSelector(), connectDepName, false);
-
-        kubectlGetStrimziUntilOperationIsSuccessful(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
-        checkContainersHaveProcessOneAsTini(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
-    }
-
-    @ParallelTest
-    @Tag(MIRROR_MAKER)
-    void testMirrorMakerLogSetting() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), LOG_SETTING_CLUSTER_NAME, GC_LOGGING_SET_NAME, "my-group", 1, false)
-            .editSpec()
-                .withNewInlineLogging()
-                    .withLoggers(MIRROR_MAKER_LOGGERS)
-                .endInlineLogging()
-                .withNewJvmOptions()
-                    .withGcLoggingEnabled(true)
-                .endJvmOptions()
-            .endSpec()
-            .build());
-
-        String mmDepName = KafkaMirrorMakerResources.componentName(testStorage.getClusterName());
-        Map<String, String> mmPods = DeploymentUtils.depSnapshot(Environment.TEST_SUITE_NAMESPACE, mmDepName);
-        String mirrorMakerMap = KafkaMirrorMakerResources.metricsAndLogConfigMapName(testStorage.getClusterName());
-
-        LOGGER.info("Checking if MirrorMaker has log level set properly");
-        assertThat("KafkaMirrorMaker's log level is set properly", checkLoggersLevel(Environment.TEST_SUITE_NAMESPACE, MIRROR_MAKER_LOGGERS, mirrorMakerMap), is(true));
-        checkGcLoggingDeployments(Environment.TEST_SUITE_NAMESPACE, mmDepName, true);
-
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), mm -> mm.getSpec().setJvmOptions(JVM_OPTIONS));
-        DeploymentUtils.waitTillDepHasRolled(Environment.TEST_SUITE_NAMESPACE, mmDepName, 1, mmPods);
-        checkGcLoggingDeployments(Environment.TEST_SUITE_NAMESPACE, mmDepName, false);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getKafkaConnectSelector(), false);
 
         kubectlGetStrimziUntilOperationIsSuccessful(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
         checkContainersHaveProcessOneAsTini(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
@@ -343,7 +307,7 @@ void testMirrorMaker2LogSetting() {
         resourceManager.createResourceWithWait(KafkaMirrorMaker2Templates.kafkaMirrorMaker2(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), GC_LOGGING_SET_NAME, LOG_SETTING_CLUSTER_NAME, 1, false)
             .editSpec()
                 .withNewInlineLogging()
-                    .withLoggers(MIRROR_MAKER_LOGGERS)
+                    .withLoggers(MIRROR_MAKER_2_LOGGERS)
                 .endInlineLogging()
                 .withNewJvmOptions()
                     .withGcLoggingEnabled(true)
@@ -356,14 +320,14 @@ void testMirrorMaker2LogSetting() {
         final Map<String, String> mm2Pods = PodUtils.podSnapshot(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector());
 
         LOGGER.info("Checking if MirrorMaker2 has log level set properly");
-        assertThat("KafkaMirrorMaker2's log level is set properly", checkLoggersLevel(Environment.TEST_SUITE_NAMESPACE, MIRROR_MAKER_LOGGERS, mirrorMakerMap), is(true));
+        assertThat("KafkaMirrorMaker2's log level is set properly", checkLoggersLevel(Environment.TEST_SUITE_NAMESPACE, MIRROR_MAKER_2_LOGGERS, mirrorMakerMap), is(true));
         this.checkGcLoggingPods(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector(), true);
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector(), mm2DepName, true);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector(), true);
 
         KafkaMirrorMaker2Resource.replaceKafkaMirrorMaker2ResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), mm2 -> mm2.getSpec().setJvmOptions(JVM_OPTIONS));
         StUtils.waitTillStrimziPodSetOrDeploymentRolled(Environment.TEST_SUITE_NAMESPACE, mm2DepName, 1, mm2Pods, testStorage.getMM2Selector());
 
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector(), mm2DepName,  false);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, testStorage.getMM2Selector(), false);
 
         kubectlGetStrimziUntilOperationIsSuccessful(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
         checkContainersHaveProcessOneAsTini(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
@@ -393,12 +357,12 @@ void testBridgeLogSetting() {
         LOGGER.info("Checking if Bridge has log level set properly");
         assertThat("Bridge's log level is set properly", checkLoggersLevel(Environment.TEST_SUITE_NAMESPACE, BRIDGE_LOGGERS, bridgeMap), is(true));
 
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, labelSelector, bridgeDepName, true);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, labelSelector, true);
 
         KafkaBridgeResource.replaceBridgeResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName(), bridge -> bridge.getSpec().setJvmOptions(JVM_OPTIONS));
         DeploymentUtils.waitTillDepHasRolled(Environment.TEST_SUITE_NAMESPACE, bridgeDepName, 1, bridgePods);
 
-        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, labelSelector, bridgeDepName, false);
+        this.checkGcLogging(Environment.TEST_SUITE_NAMESPACE, labelSelector, false);
 
         kubectlGetStrimziUntilOperationIsSuccessful(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
         checkContainersHaveProcessOneAsTini(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
@@ -497,19 +461,10 @@ private synchronized Boolean checkGcLoggingDeployments(String namespaceName, Str
         return checkEnvVarValue(container);
     }
 
-    private synchronized void checkGcLogging(final String namespaceName, final LabelSelector selector,
-                                                final String deploymentName, boolean exceptedValue) {
+    private synchronized void checkGcLogging(final String namespaceName, final LabelSelector selector, boolean exceptedValue) {
         this.checkGcLoggingPods(namespaceName, selector, exceptedValue);
     }
 
-    private synchronized void checkGcLoggingDeployments(String namespaceName, String deploymentName, boolean expectedValue) {
-        LOGGER.info("Checking deployment: {}", deploymentName);
-        Container container = kubeClient(namespaceName).getDeployment(namespaceName, deploymentName).getSpec().getTemplate().getSpec().getContainers().get(0);
-        LOGGER.info("Checking container with name: {}", container.getName());
-
-        assertThat(checkEnvVarValue(container), is(expectedValue));
-    }
-
     private synchronized void checkGcLoggingPods(String namespaceName, LabelSelector selector, boolean expectedValue) {
         LOGGER.info("Checking Pods with selector: {}", selector);
         List<Pod> pods = kubeClient(namespaceName).getClient().pods().inNamespace(namespaceName).withLabelSelector(selector).list().getItems();
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java b/systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
index bee2fe8eee6..ec836453582 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
@@ -20,7 +20,6 @@
 import io.strimzi.api.kafka.model.kafka.Kafka;
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
 import io.strimzi.api.kafka.model.kafka.exporter.KafkaExporterResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.podset.StrimziPodSet;
 import io.strimzi.api.kafka.model.rebalance.KafkaRebalance;
@@ -389,7 +388,7 @@ void testKafkaExporterDifferentSetting() throws InterruptedException, ExecutionE
      *     - Metric is available with expected value
      *  2. - Check that collected metrics contain data about Kafka resource
      *     - Metric is available with expected value
-     *  3. - Check that collected metrics don't contain data about KafkaMirrorMaker and KafkaRebalance resource
+     *  3. - Check that collected metrics don't contain data about KafkaRebalance resource
      *     - Metric is not exposed
      *
      * @usecase
@@ -411,10 +410,6 @@ void testClusterOperatorMetrics() {
         assertCoMetricResourceState(namespaceFirst, Kafka.RESOURCE_KIND, kafkaClusterFirstName, clusterOperatorCollector, 1, "none");
         assertCoMetricResourceState(namespaceSecond, Kafka.RESOURCE_KIND, kafkaClusterSecondName, clusterOperatorCollector, 1, "none");
 
-        assertCoMetricResourcesNullOrZero(namespaceFirst, KafkaMirrorMaker.RESOURCE_KIND, clusterOperatorCollector);
-        assertCoMetricResourcesNullOrZero(namespaceSecond, KafkaMirrorMaker.RESOURCE_KIND, clusterOperatorCollector);
-        assertCoMetricResourceStateNotExists(kafkaClusterFirstName, KafkaMirrorMaker.RESOURCE_KIND, namespaceFirst, clusterOperatorCollector);
-
         assertCoMetricResourcesNullOrZero(namespaceFirst, KafkaRebalance.RESOURCE_KIND, clusterOperatorCollector);
         assertCoMetricResourcesNullOrZero(namespaceSecond, KafkaRebalance.RESOURCE_KIND, clusterOperatorCollector);
         assertCoMetricResourceStateNotExists(kafkaClusterFirstName, KafkaRebalance.RESOURCE_KIND, namespaceFirst, clusterOperatorCollector);
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java b/systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
deleted file mode 100644
index ad10ddc2d43..00000000000
--- a/systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
+++ /dev/null
@@ -1,712 +0,0 @@
-/*
- * Copyright Strimzi authors.
- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
- */
-package io.strimzi.systemtest.mirrormaker;
-
-import io.fabric8.kubernetes.api.model.Quantity;
-import io.fabric8.kubernetes.api.model.ResourceRequirementsBuilder;
-import io.strimzi.api.kafka.model.common.CertSecretSource;
-import io.strimzi.api.kafka.model.common.PasswordSecretSource;
-import io.strimzi.api.kafka.model.common.template.DeploymentStrategy;
-import io.strimzi.api.kafka.model.kafka.KafkaResources;
-import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
-import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerAuthenticationScramSha512;
-import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerAuthenticationTls;
-import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerStatus;
-import io.strimzi.operator.common.model.Labels;
-import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.TestConstants;
-import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
-import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
-import io.strimzi.systemtest.resources.NodePoolsConverter;
-import io.strimzi.systemtest.resources.ResourceManager;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
-import io.strimzi.systemtest.storage.TestStorage;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaUserTemplates;
-import io.strimzi.systemtest.utils.ClientUtils;
-import io.strimzi.systemtest.utils.StUtils;
-import io.strimzi.systemtest.utils.VerificationUtils;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
-import org.hamcrest.CoreMatchers;
-import org.hamcrest.Matchers;
-import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Tag;
-
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-
-import static io.strimzi.systemtest.TestTags.COMPONENT_SCALING;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
-import static io.strimzi.systemtest.TestTags.REGRESSION;
-import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
-import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
-import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
-import static org.hamcrest.CoreMatchers.containsString;
-import static org.hamcrest.CoreMatchers.not;
-import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.is;
-import static org.junit.jupiter.api.Assertions.assertTrue;
-
-@Tag(REGRESSION)
-@Tag(MIRROR_MAKER)
-public class MirrorMakerST extends AbstractST {
-
-    private static final Logger LOGGER = LogManager.getLogger(MirrorMakerST.class);
-
-    @ParallelNamespaceTest
-    void testMirrorMaker() {
-        TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        Map<String, String> jvmOptionsXX = new HashMap<>();
-        jvmOptionsXX.put("UseG1GC", "true");
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(testStorage.getNamespaceName(), testStorage.getTopicName(), testStorage.getSourceClusterName()).build());
-
-        final KafkaClients sourceClients = ClientUtils.getInstantPlainClients(testStorage, KafkaResources.plainBootstrapAddress(testStorage.getSourceClusterName()));
-        resourceManager.createResourceWithWait(sourceClients.producerStrimzi(), sourceClients.consumerStrimzi());
-        ClientUtils.waitForInstantClientSuccess(testStorage);
-
-        // Deploy MirrorMaker
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-            .withResources(new ResourceRequirementsBuilder()
-                    .addToLimits("memory", new Quantity("400M"))
-                    .addToLimits("cpu", new Quantity("2"))
-                    .addToRequests("memory", new Quantity("300M"))
-                    .addToRequests("cpu", new Quantity("1"))
-                    .build())
-            .withNewJvmOptions()
-                .withXmx("200m")
-                .withXms("200m")
-                .withXx(jvmOptionsXX)
-            .endJvmOptions()
-            .endSpec()
-            .build());
-
-        VerificationUtils.verifyPodsLabels(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResource.getLabelSelector(testStorage.getClusterName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName())));
-
-        VerificationUtils.verifyConfigMapsLabels(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName());
-        VerificationUtils.verifyServiceAccountsLabels(testStorage.getNamespaceName(), testStorage.getSourceClusterName());
-
-        String mmDepName = KafkaMirrorMakerResources.componentName(testStorage.getClusterName());
-        String mirrorMakerPodName = kubeClient(testStorage.getNamespaceName()).listPodsByPrefixInName(mmDepName).get(0).getMetadata().getName();
-        String kafkaMirrorMakerLogs = kubeClient(testStorage.getNamespaceName()).logs(mirrorMakerPodName);
-
-        assertThat(kafkaMirrorMakerLogs,
-            not(containsString("keytool error: java.io.FileNotFoundException: /opt/kafka/consumer-oauth-certs/**/* (No such file or directory)")));
-
-        String podName = kubeClient(testStorage.getNamespaceName()).listPodsByNamespace(testStorage.getNamespaceName(), testStorage.getClusterName()).stream().filter(n -> n.getMetadata().getName().startsWith(KafkaMirrorMakerResources.componentName(testStorage.getClusterName()))).findFirst().orElseThrow().getMetadata().getName();
-        VerificationUtils.assertPodResourceRequests(testStorage.getNamespaceName(), podName, mmDepName,
-                "400M", "2", "300M", "1");
-        VerificationUtils.assertJvmOptions(testStorage.getNamespaceName(), podName, KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-                "-Xmx200m", "-Xms200m", "-XX:+UseG1GC");
-
-        final KafkaClients targetClients = ClientUtils.getInstantPlainClients(testStorage, KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()));
-        resourceManager.createResourceWithWait(targetClients.consumerStrimzi());
-        ClientUtils.waitForInstantConsumerClientSuccess(testStorage);
-    }
-
-    /**
-     * Test mirroring messages by MirrorMaker over tls transport using mutual tls auth
-     */
-    @ParallelNamespaceTest
-    @SuppressWarnings({"checkstyle:MethodLength"})
-    void testMirrorMakerTlsAuthenticated() {
-        TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-
-        // Deploy source kafka with tls listener and mutual tls auth
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                            .withName(TestConstants.TLS_LISTENER_DEFAULT_NAME)
-                            .withPort(9093)
-                            .withType(KafkaListenerType.INTERNAL)
-                            .withTls(true)
-                            .withAuth(new KafkaListenerAuthenticationTls())
-                            .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-
-        // Deploy target kafka with tls listener and mutual tls auth
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                            .withName(TestConstants.TLS_LISTENER_DEFAULT_NAME)
-                            .withPort(9093)
-                            .withType(KafkaListenerType.INTERNAL)
-                            .withTls(true)
-                            .withAuth(new KafkaListenerAuthenticationTls())
-                            .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(
-            KafkaTopicTemplates.topic(testStorage.getNamespaceName(), testStorage.getTopicName(), testStorage.getSourceClusterName()).build(),
-            KafkaUserTemplates.tlsUser(testStorage.getNamespaceName(), testStorage.getSourceUsername(), testStorage.getSourceClusterName()).build(),
-            KafkaUserTemplates.tlsUser(testStorage.getNamespaceName(), testStorage.getTargetUsername(), testStorage.getTargetClusterName()).build()
-        );
-
-        // Initialize CertSecretSource with certificate and secret names for consumer
-        CertSecretSource certSecretSource = new CertSecretSource();
-        certSecretSource.setCertificate("ca.crt");
-        certSecretSource.setSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getSourceClusterName()));
-
-        // Initialize CertSecretSource with certificate and secret names for producer
-        CertSecretSource certSecretTarget = new CertSecretSource();
-        certSecretTarget.setCertificate("ca.crt");
-        certSecretTarget.setSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getTargetClusterName()));
-
-        final KafkaClients sourceClients = ClientUtils.getInstantTlsClientBuilder(testStorage, KafkaResources.tlsBootstrapAddress(testStorage.getSourceClusterName()))
-            .withUsername(testStorage.getSourceUsername())
-            .build();
-        resourceManager.createResourceWithWait(sourceClients.producerTlsStrimzi(testStorage.getSourceClusterName()), sourceClients.consumerTlsStrimzi(testStorage.getSourceClusterName()));
-        ClientUtils.waitForInstantClientSuccess(testStorage);
-
-        // Deploy MirrorMaker with tls listener and mutual tls auth
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, true)
-            .editSpec()
-                .editConsumer()
-                    .withNewTls()
-                        .withTrustedCertificates(certSecretSource)
-                    .endTls()
-                    .withNewKafkaClientAuthenticationTls()
-                        .withNewCertificateAndKey()
-                            .withSecretName(testStorage.getSourceUsername())
-                            .withCertificate("user.crt")
-                            .withKey("user.key")
-                        .endCertificateAndKey()
-                    .endKafkaClientAuthenticationTls()
-                .endConsumer()
-                .editProducer()
-                    .withNewTls()
-                        .withTrustedCertificates(certSecretTarget)
-                    .endTls()
-                    .withNewKafkaClientAuthenticationTls()
-                        .withNewCertificateAndKey()
-                            .withSecretName(testStorage.getTargetUsername())
-                            .withCertificate("user.crt")
-                            .withKey("user.key")
-                        .endCertificateAndKey()
-                    .endKafkaClientAuthenticationTls()
-                .endProducer()
-            .endSpec()
-            .build());
-
-        final KafkaClients targetClients = ClientUtils.getInstantTlsClientBuilder(testStorage, KafkaResources.tlsBootstrapAddress(testStorage.getTargetClusterName()))
-            .withUsername(testStorage.getTargetUsername())
-            .build();
-        resourceManager.createResourceWithWait(targetClients.consumerTlsStrimzi(testStorage.getTargetClusterName()));
-        ClientUtils.waitForInstantConsumerClientSuccess(testStorage);
-    }
-
-    /**
-     * Test mirroring messages by MirrorMaker over tls transport using scram-sha auth
-     */
-    @ParallelNamespaceTest
-    @SuppressWarnings("checkstyle:methodlength")
-    void testMirrorMakerTlsScramSha() {
-        TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-
-        // Deploy source kafka with tls listener and SCRAM-SHA authentication
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                            .withName(TestConstants.TLS_LISTENER_DEFAULT_NAME)
-                            .withPort(9093)
-                            .withType(KafkaListenerType.INTERNAL)
-                            .withTls(true)
-                            .withAuth(new KafkaListenerAuthenticationScramSha512())
-                            .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-
-        // Deploy target kafka with tls listener and SCRAM-SHA authentication
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                            .withName(TestConstants.TLS_LISTENER_DEFAULT_NAME)
-                            .withPort(9093)
-                            .withType(KafkaListenerType.INTERNAL)
-                            .withTls(true)
-                            .withAuth(new KafkaListenerAuthenticationScramSha512())
-                            .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        // Deploy topic
-        resourceManager.createResourceWithWait(
-            KafkaTopicTemplates.topic(testStorage.getNamespaceName(), testStorage.getTopicName(), testStorage.getSourceClusterName()).build(),
-            KafkaUserTemplates.scramShaUser(testStorage.getNamespaceName(), testStorage.getSourceUsername(), testStorage.getSourceClusterName()).build(),
-            KafkaUserTemplates.scramShaUser(testStorage.getNamespaceName(), testStorage.getTargetUsername(), testStorage.getTargetClusterName()).build()
-        );
-
-        // Initialize PasswordSecretSource to set this as PasswordSecret in MirrorMaker spec
-        PasswordSecretSource passwordSecretSource = new PasswordSecretSource();
-        passwordSecretSource.setSecretName(testStorage.getSourceUsername());
-        passwordSecretSource.setPassword("password");
-
-        // Initialize PasswordSecretSource to set this as PasswordSecret in MirrorMaker spec
-        PasswordSecretSource passwordSecretTarget = new PasswordSecretSource();
-        passwordSecretTarget.setSecretName(testStorage.getTargetUsername());
-        passwordSecretTarget.setPassword("password");
-
-        // Initialize CertSecretSource with certificate and secret names for consumer
-        CertSecretSource certSecretSource = new CertSecretSource();
-        certSecretSource.setCertificate("ca.crt");
-        certSecretSource.setSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getSourceClusterName()));
-
-        // Initialize CertSecretSource with certificate and secret names for producer
-        CertSecretSource certSecretTarget = new CertSecretSource();
-        certSecretTarget.setCertificate("ca.crt");
-        certSecretTarget.setSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getTargetClusterName()));
-
-        final KafkaClients sourceClients = ClientUtils.getInstantTlsClientBuilder(testStorage, KafkaResources.tlsBootstrapAddress(testStorage.getSourceClusterName()))
-            .withUsername(testStorage.getSourceUsername())
-            .withTopicName(testStorage.getTopicName())
-            .build();
-        resourceManager.createResourceWithWait(sourceClients.producerScramShaTlsStrimzi(testStorage.getSourceClusterName()), sourceClients.consumerScramShaTlsStrimzi(testStorage.getSourceClusterName()));
-        ClientUtils.waitForInstantClientSuccess(testStorage);
-
-        // Deploy MirrorMaker with TLS and ScramSha512
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, true)
-            .editSpec()
-                .editConsumer()
-                    .withNewKafkaClientAuthenticationScramSha512()
-                        .withUsername(testStorage.getSourceUsername())
-                        .withPasswordSecret(passwordSecretSource)
-                    .endKafkaClientAuthenticationScramSha512()
-                    .withNewTls()
-                        .withTrustedCertificates(certSecretSource)
-                    .endTls()
-                .endConsumer()
-                .editProducer()
-                    .withNewKafkaClientAuthenticationScramSha512()
-                        .withUsername(testStorage.getTargetUsername())
-                        .withPasswordSecret(passwordSecretTarget)
-                    .endKafkaClientAuthenticationScramSha512()
-                    .withNewTls()
-                        .withTrustedCertificates(certSecretTarget)
-                    .endTls()
-                .endProducer()
-            .endSpec()
-            .build());
-
-        final KafkaClients targetClients = ClientUtils.getInstantTlsClientBuilder(testStorage, KafkaResources.tlsBootstrapAddress(testStorage.getTargetClusterName()))
-            .withUsername(testStorage.getTargetUsername())
-            .build();
-        resourceManager.createResourceWithWait(targetClients.consumerScramShaTlsStrimzi(testStorage.getTargetClusterName()));
-        ClientUtils.waitForInstantConsumerClientSuccess(testStorage);
-    }
-
-    @ParallelNamespaceTest
-    void testIncludeList() {
-        TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        String topicName = "included-topic";
-        String topicNotIncluded = "not-included-topic";
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPool(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPool(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-
-        resourceManager.createResourceWithWait(
-            KafkaTopicTemplates.topic(testStorage.getSourceClusterName(), topicName, testStorage.getNamespaceName()).build(),
-            KafkaTopicTemplates.topic(testStorage.getSourceClusterName(), topicNotIncluded, testStorage.getNamespaceName()).build()
-        );
-
-        KafkaClients sourceClients = ClientUtils.getInstantPlainClientBuilder(testStorage, KafkaResources.plainBootstrapAddress(testStorage.getSourceClusterName()))
-            .withTopicName(topicName)
-            .build();
-
-        resourceManager.createResourceWithWait(sourceClients.producerStrimzi(), sourceClients.consumerStrimzi());
-        ClientUtils.waitForInstantClientSuccess(testStorage);
-
-        sourceClients = new KafkaClientsBuilder(sourceClients)
-            .withTopicName(topicNotIncluded)
-            .build();
-
-        resourceManager.createResourceWithWait(sourceClients.producerStrimzi(), sourceClients.consumerStrimzi());
-        ClientUtils.waitForInstantClientSuccess(testStorage);
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-                .withInclude(topicName)
-            .endSpec()
-            .build());
-
-        KafkaClients targetClients = ClientUtils.getInstantPlainClientBuilder(testStorage, KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-            .withTopicName(topicName)
-            .build();
-
-        resourceManager.createResourceWithWait(targetClients.consumerStrimzi());
-        ClientUtils.waitForInstantConsumerClientSuccess(testStorage);
-
-        targetClients = new KafkaClientsBuilder(targetClients)
-            .withTopicName(topicNotIncluded)
-            .build();
-
-        LOGGER.info("Becuase {} is not included, we should not receive any message", topicNotIncluded);
-        resourceManager.createResourceWithWait(targetClients.consumerStrimzi());
-        ClientUtils.waitForInstantConsumerClientTimeout(testStorage);
-    }
-
-    @ParallelNamespaceTest
-    void testCustomAndUpdatedValues() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getBrokerPoolName(), testStorage.getClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getControllerPoolName(), testStorage.getClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getClusterName(), 1, 1).build());
-
-        String usedVariable = "KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER";
-
-        LinkedHashMap<String, String> envVarGeneral = new LinkedHashMap<>();
-        envVarGeneral.put("TEST_ENV_1", "test.env.one");
-        envVarGeneral.put("TEST_ENV_2", "test.env.two");
-        envVarGeneral.put(usedVariable, "test.value");
-
-        LinkedHashMap<String, String> envVarUpdated = new LinkedHashMap<>();
-        envVarUpdated.put("TEST_ENV_2", "updated.test.env.two");
-        envVarUpdated.put("TEST_ENV_3", "test.env.three");
-
-        Map<String, Object> producerConfig = new HashMap<>();
-        producerConfig.put("acks", "all");
-
-        Map<String, Object> updatedProducerConfig = new HashMap<>();
-        updatedProducerConfig.put("acks", "0");
-
-        Map<String, Object> consumerConfig = new HashMap<>();
-        consumerConfig.put("auto.offset.reset", "latest");
-
-        Map<String, Object> updatedConsumerConfig = new HashMap<>();
-        updatedConsumerConfig.put("auto.offset.reset", "earliest");
-
-        int initialDelaySeconds = 30;
-        int timeoutSeconds = 10;
-        int updatedInitialDelaySeconds = 31;
-        int updatedTimeoutSeconds = 11;
-        int periodSeconds = 10;
-        int successThreshold = 1;
-        int failureThreshold = 3;
-        int updatedPeriodSeconds = 5;
-        int updatedFailureThreshold = 1;
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getClusterName(), testStorage.getClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-                .editProducer()
-                    .withConfig(producerConfig)
-                .endProducer()
-                .editConsumer()
-                    .withConfig(consumerConfig)
-                .endConsumer()
-                .withNewTemplate()
-                    .withNewMirrorMakerContainer()
-                        .withEnv(StUtils.createContainerEnvVarsFromMap(envVarGeneral))
-                    .endMirrorMakerContainer()
-                .endTemplate()
-                .withNewReadinessProbe()
-                    .withInitialDelaySeconds(initialDelaySeconds)
-                    .withTimeoutSeconds(timeoutSeconds)
-                    .withPeriodSeconds(periodSeconds)
-                    .withSuccessThreshold(successThreshold)
-                    .withFailureThreshold(failureThreshold)
-                .endReadinessProbe()
-                .withNewLivenessProbe()
-                    .withInitialDelaySeconds(initialDelaySeconds)
-                    .withTimeoutSeconds(timeoutSeconds)
-                    .withPeriodSeconds(periodSeconds)
-                    .withSuccessThreshold(successThreshold)
-                    .withFailureThreshold(failureThreshold)
-                .endLivenessProbe()
-            .endSpec()
-            .build());
-
-        Map<String, String> mirrorMakerSnapshot = DeploymentUtils.depSnapshot(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()));
-
-        // Remove variable which is already in use
-        envVarGeneral.remove(usedVariable);
-        LOGGER.info("Verifying values before update");
-        VerificationUtils.verifyReadinessAndLivenessProbes(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), initialDelaySeconds, timeoutSeconds, periodSeconds,
-            successThreshold, failureThreshold);
-        VerificationUtils.verifyContainerEnvVariables(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), envVarGeneral);
-        VerificationUtils.verifyComponentConfiguration(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), "KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER", producerConfig);
-        VerificationUtils.verifyComponentConfiguration(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), "KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER", consumerConfig);
-
-        LOGGER.info("Check if actual env variable {} has different value than {}", usedVariable, "test.value");
-        assertThat(StUtils.checkEnvVarInPod(testStorage.getNamespaceName(), kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL,
-            KafkaMirrorMaker.RESOURCE_KIND).get(0).getMetadata().getName(), usedVariable), CoreMatchers.is(not("test.value")));
-
-        LOGGER.info("Updating values in MirrorMaker container");
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(), kmm -> {
-            kmm.getSpec().getTemplate().getMirrorMakerContainer().setEnv(StUtils.createContainerEnvVarsFromMap(envVarUpdated));
-            kmm.getSpec().getProducer().setConfig(updatedProducerConfig);
-            kmm.getSpec().getConsumer().setConfig(updatedConsumerConfig);
-            kmm.getSpec().getLivenessProbe().setInitialDelaySeconds(updatedInitialDelaySeconds);
-            kmm.getSpec().getReadinessProbe().setInitialDelaySeconds(updatedInitialDelaySeconds);
-            kmm.getSpec().getLivenessProbe().setTimeoutSeconds(updatedTimeoutSeconds);
-            kmm.getSpec().getReadinessProbe().setTimeoutSeconds(updatedTimeoutSeconds);
-            kmm.getSpec().getLivenessProbe().setPeriodSeconds(updatedPeriodSeconds);
-            kmm.getSpec().getReadinessProbe().setPeriodSeconds(updatedPeriodSeconds);
-            kmm.getSpec().getLivenessProbe().setFailureThreshold(updatedFailureThreshold);
-            kmm.getSpec().getReadinessProbe().setFailureThreshold(updatedFailureThreshold);
-        });
-
-        DeploymentUtils.waitTillDepHasRolled(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), 1, mirrorMakerSnapshot);
-
-        LOGGER.info("Verifying values after update");
-        VerificationUtils.verifyReadinessAndLivenessProbes(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), updatedInitialDelaySeconds, updatedTimeoutSeconds,
-                updatedPeriodSeconds, successThreshold, updatedFailureThreshold);
-        VerificationUtils.verifyContainerEnvVariables(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), envVarUpdated);
-        VerificationUtils.verifyComponentConfiguration(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), "KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER", updatedProducerConfig);
-        VerificationUtils.verifyComponentConfiguration(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()),
-            KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), "KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER", updatedConsumerConfig);
-    }
-
-    @ParallelNamespaceTest
-    @Tag(COMPONENT_SCALING)
-    void testScaleMirrorMakerUpAndDownToZero() {
-        TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPool(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPool(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getTargetClusterName(), testStorage.getSourceClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false).build());
-
-        int scaleTo = 2;
-        long mmObsGen = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus().getObservedGeneration();
-        String mmDepName = KafkaMirrorMakerResources.componentName(testStorage.getClusterName());
-        String mmGenName = kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND).get(0).getMetadata().getGenerateName();
-
-        LOGGER.info("-------> Scaling KafkaMirrorMaker up <-------");
-
-        LOGGER.info("Scaling subresource replicas to {}", scaleTo);
-        cmdKubeClient().namespace(testStorage.getNamespaceName()).scaleByName(KafkaMirrorMaker.RESOURCE_KIND, testStorage.getClusterName(), scaleTo);
-        DeploymentUtils.waitForDeploymentAndPodsReady(testStorage.getNamespaceName(), KafkaMirrorMakerResources.componentName(testStorage.getClusterName()), scaleTo);
-
-        LOGGER.info("Check if replicas is set to {}, naming prefix should be same and observed generation higher", scaleTo);
-
-        StUtils.waitUntilSupplierIsSatisfied("KafkaMirrorMaker expected size (status, replicas, pod count)",
-            () -> kubeClient().listPodNames(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND).size() == scaleTo &&
-            KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getSpec().getReplicas() == scaleTo &&
-            KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus().getReplicas() == scaleTo);
-
-        /*
-        observed generation should be higher than before scaling -> after change of spec and successful reconciliation,
-        the observed generation is increased
-        */
-        long actualObsGen = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus().getObservedGeneration();
-        assertTrue(mmObsGen < actualObsGen);
-
-        List<String> mmPods = kubeClient().listPodNames(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND);
-
-        for (String pod : mmPods) {
-            assertTrue(pod.contains(mmGenName));
-        }
-
-        mmObsGen = actualObsGen;
-
-        LOGGER.info("-------> Scaling KafkaMirrorMaker down <-------");
-
-        LOGGER.info("Scaling MirrorMaker to zero");
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(), mm -> mm.getSpec().setReplicas(0));
-
-        PodUtils.waitForPodsReady(testStorage.getNamespaceName(), kubeClient().getDeploymentSelectors(testStorage.getNamespaceName(), mmDepName), 0, true);
-
-        mmPods = kubeClient().listPodNames(testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND);
-        assertThat(mmPods.size(), is(0));
-
-        // Needed for using it in lambda
-        long finalMmObsGen = mmObsGen;
-        StUtils.waitUntilSupplierIsSatisfied("ObservedGeneration of MM is higher than (check test log for more info)" + finalMmObsGen,
-            () -> {
-                long observedGeneration = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus().getObservedGeneration();
-                boolean isHigherThan = observedGeneration > finalMmObsGen;
-                if (!isHigherThan) {
-                    LOGGER.info("Expected ObservedGeneration: {}, actual ObservedGeneration: {}. Waiting for next round of validation", finalMmObsGen, observedGeneration);
-                }
-                return isHigherThan;
-            });
-
-        KafkaMirrorMakerStatus mmStatus = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus();
-        assertThat(mmStatus.getConditions().get(0).getType(), is(Ready.toString()));
-    }
-
-    @ParallelNamespaceTest
-    void testConfigureDeploymentStrategy() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getTargetClusterName(), testStorage.getSourceClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-                .editOrNewTemplate()
-                    .editOrNewDeployment()
-                        .withDeploymentStrategy(DeploymentStrategy.RECREATE)
-                    .endDeployment()
-                .endTemplate()
-            .endSpec()
-            .build());
-
-        String mmDepName = KafkaMirrorMakerResources.componentName(testStorage.getClusterName());
-
-        LOGGER.info("Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd");
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(),
-            mm -> mm.getMetadata().setLabels(Collections.singletonMap("some", "label")));
-        DeploymentUtils.waitForDeploymentAndPodsReady(testStorage.getNamespaceName(), mmDepName, 1);
-
-        KafkaMirrorMaker kmm = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get();
-
-        LOGGER.info("Checking that observed gen. is still on 1 (recreation) and new label is present");
-        assertThat(kmm.getStatus().getObservedGeneration(), is(1L));
-        assertThat(kmm.getMetadata().getLabels().toString(), Matchers.containsString("some=label"));
-        assertThat(kmm.getSpec().getTemplate().getDeployment().getDeploymentStrategy(), is(DeploymentStrategy.RECREATE));
-
-        LOGGER.info("Changing Deployment strategy to {}", DeploymentStrategy.ROLLING_UPDATE);
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(),
-            mm -> mm.getSpec().getTemplate().getDeployment().setDeploymentStrategy(DeploymentStrategy.ROLLING_UPDATE));
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(testStorage.getNamespaceName(), testStorage.getClusterName());
-
-        LOGGER.info("Adding another label to MirrorMaker resource, Pods should be rolled");
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(), mm -> mm.getMetadata().getLabels().put("another", "label"));
-        DeploymentUtils.waitForDeploymentAndPodsReady(testStorage.getNamespaceName(), mmDepName, 1);
-
-        LOGGER.info("Checking that observed gen. higher (rolling update) and label is changed");
-        StUtils.waitUntilSupplierIsSatisfied("KafkaMirrorMaker observed generation and labels",
-            () -> {
-                final KafkaMirrorMaker kMM = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get();
-
-                return kMM.getStatus().getObservedGeneration() == 2L &&
-                        kMM.getMetadata().getLabels().toString().contains("another=label") &&
-                        kMM.getSpec().getTemplate().getDeployment().getDeploymentStrategy().equals(DeploymentStrategy.ROLLING_UPDATE);
-            }
-        );
-    }
-
-    @BeforeAll
-    void setupEnvironment() {
-        clusterOperator = clusterOperator.defaultInstallation()
-            .withOperationTimeout(TestConstants.CO_OPERATION_TIMEOUT_MEDIUM)
-            .createInstallation()
-            .runInstallation();
-    }
-}
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
index 9bc622b2612..523127b8b21 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
@@ -7,7 +7,6 @@
 import io.strimzi.api.kafka.model.bridge.KafkaBridge;
 import io.strimzi.api.kafka.model.connect.KafkaConnect;
 import io.strimzi.api.kafka.model.kafka.Kafka;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.rebalance.KafkaRebalance;
 import io.strimzi.api.kafka.model.rebalance.KafkaRebalanceState;
@@ -21,7 +20,6 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMaker2Utils;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
@@ -74,14 +72,6 @@ void doTestDeployExampleKafkaBridge() {
         KafkaBridgeUtils.waitForKafkaBridgeReady(Environment.TEST_SUITE_NAMESPACE, kafkaBridgeResource.getJsonObject("metadata").getString("name"));
     }
 
-    void doTestDeployExampleKafkaMirrorMaker() {
-        JsonObject kafkaMirrorMakerResource = OlmResource.getExampleResources().get(KafkaMirrorMaker.RESOURCE_KIND);
-        cmdKubeClient().applyContent(kafkaMirrorMakerResource.toString()
-                .replace("my-source-cluster-kafka-bootstrap", "my-cluster-kafka-bootstrap")
-                .replace("my-target-cluster-kafka-bootstrap", "my-cluster-kafka-bootstrap"));
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(Environment.TEST_SUITE_NAMESPACE, kafkaMirrorMakerResource.getJsonObject("metadata").getString("name"));
-    }
-
     void doTestDeployExampleKafkaMirrorMaker2() {
         JsonObject kafkaMirrorMaker2Resource = OlmResource.getExampleResources().get(KafkaMirrorMaker2.RESOURCE_KIND);
         cmdKubeClient().applyContent(kafkaMirrorMaker2Resource.toString()
@@ -103,7 +93,6 @@ void doTestDeployExampleKafkaRebalance() {
     void teardown() {
         cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaRebalance.RESOURCE_KIND).toString());
         cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaMirrorMaker2.RESOURCE_KIND).toString());
-        cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaMirrorMaker.RESOURCE_KIND).toString());
         cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaBridge.RESOURCE_KIND).toString());
         cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaConnect.RESOURCE_KIND).toString());
         cmdKubeClient().deleteContent(OlmResource.getExampleResources().get(KafkaTopic.RESOURCE_KIND).toString());
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceST.java b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceST.java
index 237cb1dde97..c36abb2cdfa 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceST.java
@@ -16,7 +16,6 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CRUISE_CONTROL;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.OLM;
 
@@ -58,13 +57,6 @@ void testDeployExampleKafkaBridge() {
         doTestDeployExampleKafkaBridge();
     }
 
-    @Test
-    @Order(6)
-    @Tag(MIRROR_MAKER)
-    void testDeployExampleKafkaMirrorMaker() {
-        doTestDeployExampleKafkaMirrorMaker();
-    }
-
     @Test
     @Order(7)
     @Tag(MIRROR_MAKER2)
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceST.java b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceST.java
index bc0304a52cf..ede8de0af88 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceST.java
@@ -16,7 +16,6 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CRUISE_CONTROL;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.OLM;
 
@@ -58,13 +57,6 @@ void testDeployExampleKafkaBridge() {
         doTestDeployExampleKafkaBridge();
     }
 
-    @Test
-    @Order(6)
-    @Tag(MIRROR_MAKER)
-    void testDeployExampleKafkaMirrorMaker() {
-        doTestDeployExampleKafkaMirrorMaker();
-    }
-
     @Test
     @Order(7)
     @Tag(MIRROR_MAKER2)
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java b/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
index 23298a5e3b1..35311c21bbe 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
@@ -22,7 +22,6 @@
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
 import io.strimzi.api.kafka.model.kafka.listener.ListenerStatus;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerStatus;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2Status;
@@ -42,7 +41,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMaker2Resource;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaNodePoolResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
@@ -51,17 +49,14 @@
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaUserTemplates;
-import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMaker2Utils;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
@@ -82,7 +77,6 @@
 import static io.strimzi.systemtest.TestTags.CONNECTOR_OPERATOR;
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.TestTags.EXTERNAL_CLIENTS_USED;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
@@ -189,24 +183,6 @@ void testKafkaUserStatus() {
         LOGGER.info("KafkaUser is in desired state: Ready");
     }
 
-    @ParallelTest
-    @Tag(MIRROR_MAKER)
-    void testKafkaMirrorMakerStatusWrongBootstrap() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-        String mirrorMakerName = testStorage.getClusterName() + "-mirror-maker-2";
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName, sharedTestStorage.getClusterName(), sharedTestStorage.getClusterName(), ClientUtils.generateRandomConsumerGroup(), 1, false).build());
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName);
-        assertKafkaMirrorMakerStatus(1, mirrorMakerName);
-        // Corrupt MirrorMaker Pods
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName, mm -> mm.getSpec().getConsumer().setBootstrapServers("non-exists-bootstrap"));
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerNotReady(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName);
-        // Restore MirrorMaker Pods
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName, mm -> mm.getSpec().getConsumer().setBootstrapServers(KafkaResources.plainBootstrapAddress(sharedTestStorage.getClusterName())));
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(Environment.TEST_SUITE_NAMESPACE, mirrorMakerName);
-        assertKafkaMirrorMakerStatus(3, mirrorMakerName);
-    }
-
     @ParallelTest
     @Tag(BRIDGE)
     void testKafkaBridgeStatus() {
@@ -465,11 +441,6 @@ void assertKafkaStatus(long expectedObservedGeneration, String internalAddress)
         }
     }
 
-    void assertKafkaMirrorMakerStatus(long expectedObservedGeneration, String mirrorMakerName) {
-        KafkaMirrorMakerStatus kafkaMirrorMakerStatus = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(Environment.TEST_SUITE_NAMESPACE).withName(mirrorMakerName).get().getStatus();
-        assertThat("MirrorMaker cluster status has incorrect Observed Generation", kafkaMirrorMakerStatus.getObservedGeneration(), is(expectedObservedGeneration));
-    }
-
     void assertKafkaMirrorMaker2Status(long expectedObservedGeneration, String apiUrl, String mirrorMaker2Name) {
         KafkaMirrorMaker2Status kafkaMirrorMaker2Status = KafkaMirrorMaker2Resource.kafkaMirrorMaker2Client().inNamespace(Environment.TEST_SUITE_NAMESPACE).withName(mirrorMaker2Name).get().getStatus();
         assertThat("MirrorMaker2 cluster status has incorrect Observed Generation", kafkaMirrorMaker2Status.getObservedGeneration(), is(expectedObservedGeneration));
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java
index 3b9d2fc87ab..3422474a5cd 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java
@@ -11,7 +11,6 @@
 import io.strimzi.api.kafka.model.bridge.KafkaBridge;
 import io.strimzi.api.kafka.model.connect.KafkaConnect;
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.model.Labels;
@@ -31,7 +30,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -73,7 +71,7 @@ public class PodSecurityProfilesST extends AbstractST {
      *     - Namespace is modified
      *  2. - Deploy 3 Kafka Clusters, of which 2 will serve as targets and one as a source and for other purposes
      *     - Kafka clusters are deployed
-     *  3. - Deploy all additional Operands which are to be tested, i.e., KafkaMirrorMaker KafkaMirrorMaker2 KafkaBridge KafkaConnect, KafkaConnector.
+     *  3. - Deploy all additional Operands which are to be tested, i.e., KafkaMirrorMaker2 KafkaBridge KafkaConnect, KafkaConnector.
      *     - All components are deployed targeting respective Kafka Clusters
      *  4. - Deploy producer which will produce data into Topic residing in Kafka Cluster serving as Source for KafkaMirrorMakers and is targeted by other Operands
      *     - Messages are sent into KafkaTopic
@@ -142,8 +140,6 @@ void testOperandsWithRestrictedSecurityProfile() {
                 .endSpec()
                 .build(),
             KafkaBridgeTemplates.kafkaBridge(testStorage.getNamespaceName(), testStorage.getClusterName(), KafkaResources.plainBootstrapAddress(testStorage.getClusterName()), 1).build(),
-            KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName() + "-mm1", testStorage.getClusterName(), mm1TargetClusterName, ClientUtils.generateRandomConsumerGroup(), 1, false)
-                .build(),
             KafkaMirrorMaker2Templates.kafkaMirrorMaker2(testStorage.getNamespaceName(), testStorage.getClusterName() + "-mm2", testStorage.getClusterName(), mm2TargetClusterName, 1, false)
                 .editSpec()
                     .editFirstMirror()
@@ -177,24 +173,16 @@ void testOperandsWithRestrictedSecurityProfile() {
         ClientUtils.waitForInstantClientSuccess(testStorage);
 
         // verifies that Pods and Containers have proper generated SC
-        final List<Pod> podsWithProperlyGeneratedSecurityCOntexts = PodUtils.getKafkaClusterPods(testStorage);
-        podsWithProperlyGeneratedSecurityCOntexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaBridge.RESOURCE_KIND));
-        podsWithProperlyGeneratedSecurityCOntexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND));
-        podsWithProperlyGeneratedSecurityCOntexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker2.RESOURCE_KIND));
-        podsWithProperlyGeneratedSecurityCOntexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND));
-        verifyPodAndContainerSecurityContext(podsWithProperlyGeneratedSecurityCOntexts);
+        final List<Pod> podsWithProperlyGeneratedSecurityContexts = PodUtils.getKafkaClusterPods(testStorage);
+        podsWithProperlyGeneratedSecurityContexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaBridge.RESOURCE_KIND));
+        podsWithProperlyGeneratedSecurityContexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND));
+        podsWithProperlyGeneratedSecurityContexts.addAll(kubeClient().listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker2.RESOURCE_KIND));
+        verifyPodAndContainerSecurityContext(podsWithProperlyGeneratedSecurityContexts);
 
         // verify KafkaConnect
         final String kafkaConnectPodName = kubeClient(testStorage.getNamespaceName()).listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND).get(0).getMetadata().getName();
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(testStorage.getNamespaceName(), kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, testStorage.getMessageCount());
 
-        // verify MM1, as topic name does not change, only bootstrap server is changed.
-        final KafkaClients mm1Client =  ClientUtils.getInstantPlainClientBuilder(testStorage, KafkaResources.plainBootstrapAddress(mm1TargetClusterName))
-            .withPodSecurityPolicy(PodSecurityProfile.RESTRICTED)
-            .build();
-        resourceManager.createResourceWithWait(mm1Client.consumerStrimzi());
-        ClientUtils.waitForInstantConsumerClientSuccess(testStorage);
-
         // verify MM2
         final KafkaClients mm2Client = ClientUtils.getInstantPlainClientBuilder(testStorage, KafkaResources.plainBootstrapAddress(mm2TargetClusterName))
             .withTopicName(mm2SourceMirroredTopicName)
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
index abc8efd2134..4f2dc234bb3 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
@@ -22,7 +22,6 @@
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerAuthenticationTls;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.user.acl.AclOperation;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.model.Ca;
@@ -37,12 +36,10 @@
 import io.strimzi.systemtest.resources.NodePoolsConverter;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
-import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaNodePoolResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.storage.TestStorage;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -50,7 +47,6 @@
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.RollingUpdateUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaNodePoolUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
@@ -88,7 +84,6 @@
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.TestTags.CRUISE_CONTROL;
 import static io.strimzi.systemtest.TestTags.EXTERNAL_CLIENTS_USED;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
 import static io.strimzi.systemtest.TestTags.ROLLING_UPDATE;
@@ -760,81 +755,6 @@ void testTlsHostnameVerificationWithKafkaConnect() {
         KafkaConnectUtils.waitForConnectReady(testStorage.getNamespaceName(), testStorage.getClusterName());
     }
 
-    @ParallelNamespaceTest
-    @Tag(MIRROR_MAKER)
-    void testTlsHostnameVerificationWithMirrorMaker() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-        LOGGER.info("Getting IP of the source bootstrap service for consumer");
-        String ipOfSourceBootstrapService = kubeClient(testStorage.getNamespaceName()).getService(testStorage.getNamespaceName(), KafkaResources.bootstrapServiceName(testStorage.getSourceClusterName())).getSpec().getClusterIP();
-
-        LOGGER.info("Getting IP of the target bootstrap service for producer");
-        String ipOfTargetBootstrapService = kubeClient(testStorage.getNamespaceName()).getService(testStorage.getNamespaceName(), KafkaResources.bootstrapServiceName(testStorage.getTargetClusterName())).getSpec().getClusterIP();
-
-        LOGGER.info("KafkaMirrorMaker without config {} will not connect to consumer with address {}:9093", "ssl.endpoint.identification.algorithm", ipOfSourceBootstrapService);
-        LOGGER.info("KafkaMirrorMaker without config {} will not connect to producer with address {}:9093", "ssl.endpoint.identification.algorithm", ipOfTargetBootstrapService);
-
-        resourceManager.createResourceWithoutWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(),
-            ClientUtils.generateRandomConsumerGroup(), 1, true)
-            .editSpec()
-                .editConsumer()
-                    .withNewTls()
-                        .addNewTrustedCertificate()
-                            .withSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getSourceClusterName()))
-                            .withCertificate("ca.crt")
-                        .endTrustedCertificate()
-                    .endTls()
-                    .withBootstrapServers(ipOfSourceBootstrapService + ":9093")
-                .endConsumer()
-                .editProducer()
-                    .withNewTls()
-                        .addNewTrustedCertificate()
-                            .withSecretName(KafkaResources.clusterCaCertificateSecretName(testStorage.getTargetClusterName()))
-                            .withCertificate("ca.crt")
-                        .endTrustedCertificate()
-                    .endTls()
-                    .withBootstrapServers(ipOfTargetBootstrapService + ":9093")
-                .endProducer()
-            .endSpec()
-            .build());
-
-        PodUtils.waitUntilPodIsPresent(testStorage.getNamespaceName(), testStorage.getClusterName() + "-mirror-maker");
-
-        String kafkaMirrorMakerPodName = kubeClient(testStorage.getNamespaceName()).listPods(testStorage.getNamespaceName(), testStorage.getClusterName(), Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND).get(0).getMetadata().getName();
-
-        PodUtils.waitUntilPodIsInCrashLoopBackOff(testStorage.getNamespaceName(), kafkaMirrorMakerPodName);
-
-        assertThat("CrashLoopBackOff", is(kubeClient(testStorage.getNamespaceName()).getPod(testStorage.getNamespaceName(), kafkaMirrorMakerPodName).getStatus().getContainerStatuses().get(0)
-                .getState().getWaiting().getReason()));
-
-        LOGGER.info("KafkaMirrorMaker with config {} will connect to consumer with address {}:9093", "ssl.endpoint.identification.algorithm", ipOfSourceBootstrapService);
-        LOGGER.info("KafkaMirrorMaker with config {} will connect to producer with address {}:9093", "ssl.endpoint.identification.algorithm", ipOfTargetBootstrapService);
-
-        LOGGER.info("Adding configuration {} to the MirrorMaker", "ssl.endpoint.identification.algorithm");
-        KafkaMirrorMakerResource.replaceMirrorMakerResourceInSpecificNamespace(testStorage.getNamespaceName(), testStorage.getClusterName(), mm -> {
-            mm.getSpec().getConsumer().getConfig().put("ssl.endpoint.identification.algorithm", ""); // disable hostname verification
-            mm.getSpec().getProducer().getConfig().put("ssl.endpoint.identification.algorithm", ""); // disable hostname verification
-        });
-
-        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(testStorage.getNamespaceName(), testStorage.getClusterName());
-    }
-
     @ParallelNamespaceTest
     @Tag(NODEPORT_SUPPORTED)
     @Tag(EXTERNAL_CLIENTS_USED)
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
index 12aceb3db5c..b52822494de 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
@@ -49,7 +49,6 @@ public class OauthAbstractST extends AbstractST {
     protected static final String OAUTH_CONSUMER_NAME = "oauth-consumer";
 
     protected static final String CONNECT_OAUTH_SECRET = "my-connect-oauth";
-    protected static final String MIRROR_MAKER_OAUTH_SECRET = "my-mirror-maker-oauth";
     protected static final String MIRROR_MAKER_2_OAUTH_SECRET = "my-mirror-maker-2-oauth";
     protected static final String BRIDGE_OAUTH_SECRET = "my-bridge-oauth";
     protected static final String OAUTH_KAFKA_BROKER_SECRET = "kafka-broker-secret";
@@ -62,7 +61,6 @@ public class OauthAbstractST extends AbstractST {
 
     protected static final String OAUTH_BRIDGE_CLIENT_ID = "kafka-bridge";
     protected static final String OAUTH_CONNECT_CLIENT_ID = "kafka-connect";
-    protected static final String OAUTH_MM_CLIENT_ID = "kafka-mirror-maker";
     protected static final String OAUTH_MM2_CLIENT_ID = "kafka-mirror-maker-2";
 
     // broker oauth configuration
@@ -148,7 +146,6 @@ private void createSecretsForDeployments(final String namespace) {
         SecretUtils.createSecret(namespace, OAUTH_TEAM_B_SECRET, OAUTH_KEY, "team-b-client-secret");
         SecretUtils.createSecret(namespace, OAUTH_KAFKA_BROKER_SECRET, OAUTH_KEY, "kafka-broker-secret");
         SecretUtils.createSecret(namespace, CONNECT_OAUTH_SECRET, OAUTH_KEY, "kafka-connect-secret");
-        SecretUtils.createSecret(namespace, MIRROR_MAKER_OAUTH_SECRET, OAUTH_KEY, "kafka-mirror-maker-secret");
         SecretUtils.createSecret(namespace, MIRROR_MAKER_2_OAUTH_SECRET, OAUTH_KEY, "kafka-mirror-maker-2-secret");
         SecretUtils.createSecret(namespace, BRIDGE_OAUTH_SECRET, OAUTH_KEY, "kafka-bridge-secret");
         SecretUtils.createSecret(namespace, OAUTH_CLIENT_AUDIENCE_SECRET, OAUTH_KEY, "kafka-audience-secret");
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
index cc97a2c51bf..6b40f1c6ee3 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
@@ -9,7 +9,6 @@
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpec;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpecBuilder;
@@ -29,7 +28,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -41,8 +39,6 @@
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.WaitException;
 import io.strimzi.test.k8s.KubeClusterResource;
-import org.apache.kafka.clients.consumer.ConsumerConfig;
-import org.apache.kafka.clients.producer.ProducerConfig;
 import org.apache.logging.log4j.Level;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -55,7 +51,6 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.OAUTH;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
@@ -72,138 +67,6 @@ public class OauthPasswordGrantsST extends OauthAbstractST {
     private static final String ALICE_USERNAME = "alice";
     private static final String ALICE_PASSWORD_KEY = "password";
 
-    @ParallelTest
-    @Tag(MIRROR_MAKER)
-    void testPasswordGrantsKafkaMirrorMaker() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        KafkaOauthClients oauthExampleClients = new KafkaOauthClientsBuilder()
-            .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-            .withProducerName(testStorage.getProducerName())
-            .withConsumerName(testStorage.getConsumerName())
-            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(oauthClusterName))
-            .withTopicName(testStorage.getTopicName())
-            .withMessageCount(testStorage.getMessageCount())
-            .withOauthClientId(OAUTH_CLIENT_NAME)
-            .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-            .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-            .build();
-
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(Environment.TEST_SUITE_NAMESPACE, testStorage.getTopicName(), oauthClusterName).build());
-        resourceManager.createResourceWithWait(oauthExampleClients.producerStrimziOauthPlain());
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, testStorage.getProducerName(), testStorage.getMessageCount());
-
-        resourceManager.createResourceWithWait(oauthExampleClients.consumerStrimziOauthPlain());
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, testStorage.getConsumerName(), testStorage.getMessageCount());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(Environment.TEST_SUITE_NAMESPACE, testStorage.getTargetClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                            .withName(TestConstants.PLAIN_LISTENER_DEFAULT_NAME)
-                            .withPort(9092)
-                            .withType(KafkaListenerType.INTERNAL)
-                            .withTls(false)
-                            .withNewKafkaListenerAuthenticationOAuth()
-                                .withValidIssuerUri(keycloakInstance.getValidIssuerUri())
-                                .withJwksEndpointUri(keycloakInstance.getJwksEndpointUri())
-                                .withJwksExpirySeconds(keycloakInstance.getJwksExpireSeconds())
-                                .withJwksRefreshSeconds(keycloakInstance.getJwksRefreshSeconds())
-                                .withUserNameClaim(keycloakInstance.getUserNameClaim())
-                            .endKafkaListenerAuthenticationOAuth()
-                            .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(Environment.TEST_SUITE_NAMESPACE, oauthClusterName, oauthClusterName, testStorage.getTargetClusterName(),
-                ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-                .withNewConsumer()
-                    .withBootstrapServers(KafkaResources.plainBootstrapAddress(oauthClusterName))
-                    .withGroupId(ClientUtils.generateRandomConsumerGroup())
-                    .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
-                    .withNewKafkaClientAuthenticationOAuth()
-                        .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                        .withClientId(OAUTH_MM_CLIENT_ID)
-                        .withUsername(ALICE_USERNAME)
-                        .withNewPasswordSecret()
-                            .withSecretName(ALICE_SECRET)
-                            .withPassword(ALICE_PASSWORD_KEY)
-                        .endPasswordSecret()
-                        .withNewClientSecret()
-                            .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                            .withKey(OAUTH_KEY)
-                        .endClientSecret()
-                        .withConnectTimeoutSeconds(CONNECT_TIMEOUT_S)
-                        .withReadTimeoutSeconds(READ_TIMEOUT_S)
-                    .endKafkaClientAuthenticationOAuth()
-                    .withTls(null)
-                .endConsumer()
-                .withNewProducer()
-                    .withBootstrapServers(KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-                    .withNewKafkaClientAuthenticationOAuth()
-                        .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                        .withClientId(OAUTH_MM_CLIENT_ID)
-                        .withUsername(ALICE_USERNAME)
-                        .withNewPasswordSecret()
-                            .withSecretName(ALICE_SECRET)
-                            .withPassword(ALICE_PASSWORD_KEY)
-                        .endPasswordSecret()
-                        .withNewClientSecret()
-                            .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                            .withKey(OAUTH_KEY)
-                        .endClientSecret()
-                        .withConnectTimeoutSeconds(CONNECT_TIMEOUT_S)
-                        .withReadTimeoutSeconds(READ_TIMEOUT_S)
-                    .endKafkaClientAuthenticationOAuth()
-                    .addToConfig(ProducerConfig.ACKS_CONFIG, "all")
-                    .withTls(null)
-                .endProducer()
-            .endSpec()
-            .build());
-
-        final String kafkaMirrorMakerPodName = kubeClient().listPods(Environment.TEST_SUITE_NAMESPACE, oauthClusterName, Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND).get(0).getMetadata().getName();
-        final String kafkaMirrorMakerLogs = KubeClusterResource.cmdKubeClient(Environment.TEST_SUITE_NAMESPACE).execInCurrentNamespace(Level.DEBUG, "logs", kafkaMirrorMakerPodName).out();
-        verifyOauthConfiguration(kafkaMirrorMakerLogs);
-
-        TestUtils.waitFor("MirrorMaker to copy messages from " + oauthClusterName + " to " + testStorage.getTargetClusterName(),
-            TestConstants.GLOBAL_CLIENTS_POLL, TestConstants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
-            () -> {
-                LOGGER.info("Deleting the Job");
-                JobUtils.deleteJobWithWait(Environment.TEST_SUITE_NAMESPACE, OAUTH_CONSUMER_NAME);
-
-                LOGGER.info("Creating new client with new consumer-group and also to point on {} cluster", testStorage.getTargetClusterName());
-                KafkaOauthClients kafkaOauthClientJob = new KafkaOauthClientsBuilder()
-                    .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-                    .withProducerName(testStorage.getConsumerName())
-                    .withConsumerName(OAUTH_CONSUMER_NAME)
-                    .withBootstrapAddress(KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-                    .withTopicName(testStorage.getTopicName())
-                    .withMessageCount(testStorage.getMessageCount())
-                    .withOauthClientId(OAUTH_CLIENT_NAME)
-                    .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-                    .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                    .build();
-
-                resourceManager.createResourceWithWait(kafkaOauthClientJob.consumerStrimziOauthPlain());
-
-                try {
-                    ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, OAUTH_CONSUMER_NAME, testStorage.getMessageCount());
-                    return  true;
-                } catch (WaitException e) {
-                    e.printStackTrace();
-                    return false;
-                }
-            });
-    }
-
     @ParallelTest
     @Tag(MIRROR_MAKER2)
     void testPasswordGrantsKafkaMirrorMaker2() {
@@ -313,7 +176,7 @@ void testPasswordGrantsKafkaMirrorMaker2() {
         verifyOauthConfiguration(kafkaMirrorMaker2Logs);
 
         TestUtils.waitFor("MirrorMaker2 to copy messages from " + kafkaSourceClusterName + " to " + testStorage.getTargetClusterName(),
-            Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
+            Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_2_COPY_MESSAGES_BETWEEN_BROKERS,
             () -> {
                 LOGGER.info("Deleting Job: {}/{}", Environment.TEST_SUITE_NAMESPACE, testStorage.getConsumerName());
                 JobUtils.deleteJobWithWait(Environment.TEST_SUITE_NAMESPACE, testStorage.getClusterName());
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
index f0789c6a1a8..e7b6712f0f9 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
@@ -15,7 +15,6 @@
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpec;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpecBuilder;
@@ -43,7 +42,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -58,8 +56,6 @@
 import io.strimzi.test.WaitException;
 import io.strimzi.test.k8s.KubeClusterResource;
 import io.vertx.core.cli.annotations.Description;
-import org.apache.kafka.clients.consumer.ConsumerConfig;
-import org.apache.kafka.clients.producer.ProducerConfig;
 import org.apache.logging.log4j.Level;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -76,7 +72,6 @@
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.TestTags.METRICS;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.TestTags.OAUTH;
@@ -376,146 +371,6 @@ void testProducerConsumerConnectWithOauthMetrics() {
         );
     }
 
-    @Description("As an OAuth MirrorMaker, I should be able to replicate Topic data between Kafka clusters")
-    @IsolatedTest("Using more than one Kafka cluster in one Namespace")
-    @Tag(MIRROR_MAKER)
-    @Tag(NODEPORT_SUPPORTED)
-    void testProducerConsumerMirrorMaker() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-        String producerName = OAUTH_PRODUCER_NAME + "-" + testStorage.getClusterName();
-        String consumerName = OAUTH_CONSUMER_NAME + "-" + testStorage.getClusterName();
-
-        KafkaOauthClients oauthExampleClients = new KafkaOauthClientsBuilder()
-            .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-            .withProducerName(producerName)
-            .withConsumerName(consumerName)
-            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(oauthClusterName))
-            .withTopicName(testStorage.getTopicName())
-            .withMessageCount(testStorage.getMessageCount())
-            .withOauthClientId(OAUTH_CLIENT_NAME)
-            .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-            .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-            .build();
-
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(Environment.TEST_SUITE_NAMESPACE, testStorage.getTopicName(), oauthClusterName).build());
-        resourceManager.createResourceWithWait(oauthExampleClients.producerStrimziOauthPlain());
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, producerName, testStorage.getMessageCount());
-
-        resourceManager.createResourceWithWait(oauthExampleClients.consumerStrimziOauthPlain());
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, consumerName, testStorage.getMessageCount());
-
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(Environment.TEST_SUITE_NAMESPACE, testStorage.getTargetClusterName(), 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(new GenericKafkaListenerBuilder()
-                                .withName(TestConstants.PLAIN_LISTENER_DEFAULT_NAME)
-                                .withPort(9092)
-                                .withType(KafkaListenerType.INTERNAL)
-                                .withTls(false)
-                                .withNewKafkaListenerAuthenticationOAuth()
-                                    .withValidIssuerUri(keycloakInstance.getValidIssuerUri())
-                                    .withJwksEndpointUri(keycloakInstance.getJwksEndpointUri())
-                                    .withJwksExpirySeconds(keycloakInstance.getJwksExpireSeconds())
-                                    .withJwksRefreshSeconds(keycloakInstance.getJwksRefreshSeconds())
-                                    .withUserNameClaim(keycloakInstance.getUserNameClaim())
-                                .endKafkaListenerAuthenticationOAuth()
-                                .build(),
-                            new GenericKafkaListenerBuilder()
-                                .withName(TestConstants.EXTERNAL_LISTENER_DEFAULT_NAME)
-                                .withPort(9094)
-                                .withType(KafkaListenerType.NODEPORT)
-                                .withTls(false)
-                                .withNewKafkaListenerAuthenticationOAuth()
-                                    .withValidIssuerUri(keycloakInstance.getValidIssuerUri())
-                                    .withJwksExpirySeconds(keycloakInstance.getJwksExpireSeconds())
-                                    .withJwksRefreshSeconds(keycloakInstance.getJwksRefreshSeconds())
-                                    .withJwksEndpointUri(keycloakInstance.getJwksEndpointUri())
-                                    .withUserNameClaim(keycloakInstance.getUserNameClaim())
-                                .endKafkaListenerAuthenticationOAuth()
-                                .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(Environment.TEST_SUITE_NAMESPACE, oauthClusterName, oauthClusterName, testStorage.getTargetClusterName(),
-            ClientUtils.generateRandomConsumerGroup(), 1, false)
-                .editSpec()
-                    .withNewConsumer()
-                        .withBootstrapServers(KafkaResources.plainBootstrapAddress(oauthClusterName))
-                        .withGroupId(ClientUtils.generateRandomConsumerGroup())
-                        .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
-                        .withNewKafkaClientAuthenticationOAuth()
-                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                            .withClientId("kafka-mirror-maker")
-                            .withNewClientSecret()
-                                .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                                .withKey(OAUTH_KEY)
-                            .endClientSecret()
-                            .withConnectTimeoutSeconds(CONNECT_TIMEOUT_S)
-                            .withReadTimeoutSeconds(READ_TIMEOUT_S)
-                        .endKafkaClientAuthenticationOAuth()
-                        .withTls(null)
-                    .endConsumer()
-                    .withNewProducer()
-                        .withBootstrapServers(KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-                        .withNewKafkaClientAuthenticationOAuth()
-                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                            .withClientId("kafka-mirror-maker")
-                            .withNewClientSecret()
-                                .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                                .withKey(OAUTH_KEY)
-                            .endClientSecret()
-                            .withConnectTimeoutSeconds(CONNECT_TIMEOUT_S)
-                            .withReadTimeoutSeconds(READ_TIMEOUT_S)
-                        .endKafkaClientAuthenticationOAuth()
-                        .addToConfig(ProducerConfig.ACKS_CONFIG, "all")
-                        .withTls(null)
-                    .endProducer()
-                .endSpec()
-                .build());
-
-        final String kafkaMirrorMakerPodName = kubeClient().listPods(Environment.TEST_SUITE_NAMESPACE, oauthClusterName, Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND).get(0).getMetadata().getName();
-        final String kafkaMirrorMakerLogs = KubeClusterResource.cmdKubeClient(Environment.TEST_SUITE_NAMESPACE).execInCurrentNamespace(Level.DEBUG, "logs", kafkaMirrorMakerPodName).out();
-        verifyOauthConfiguration(kafkaMirrorMakerLogs);
-
-        TestUtils.waitFor("MirrorMaker to copy messages from " + oauthClusterName + " to " + testStorage.getTargetClusterName(),
-            TestConstants.GLOBAL_CLIENTS_POLL, TestConstants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
-            () -> {
-                LOGGER.info("Deleting the Job");
-                JobUtils.deleteJobWithWait(Environment.TEST_SUITE_NAMESPACE, OAUTH_CONSUMER_NAME);
-
-                LOGGER.info("Creating new client with new consumer group and also to point on {} cluster", testStorage.getTargetClusterName());
-                KafkaOauthClients kafkaOauthClientJob = new KafkaOauthClientsBuilder()
-                    .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-                    .withProducerName(consumerName)
-                    .withConsumerName(OAUTH_CONSUMER_NAME)
-                    .withBootstrapAddress(KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-                    .withTopicName(testStorage.getTopicName())
-                    .withMessageCount(testStorage.getMessageCount())
-                    .withOauthClientId(OAUTH_CLIENT_NAME)
-                    .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-                    .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                    .build();
-
-                resourceManager.createResourceWithWait(kafkaOauthClientJob.consumerStrimziOauthPlain());
-
-                try {
-                    ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, OAUTH_CONSUMER_NAME, testStorage.getMessageCount());
-                    return  true;
-                } catch (WaitException e) {
-                    e.printStackTrace();
-                    return false;
-                }
-            });
-    }
-
     @IsolatedTest("Using more than one Kafka cluster in one Namespace")
     @Tag(MIRROR_MAKER2)
     @Tag(CONNECT_COMPONENTS)
@@ -639,7 +494,7 @@ void testProducerConsumerMirrorMaker2WithOauthMetrics() {
         verifyOauthConfiguration(kafkaMirrorMaker2Logs);
 
         TestUtils.waitFor("MirrorMaker2 to copy messages from " + kafkaSourceClusterName + " to " + testStorage.getTargetClusterName(),
-            Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
+            Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_2_COPY_MESSAGES_BETWEEN_BROKERS,
             () -> {
                 LOGGER.info("Deleting Job: {}/{}", Environment.TEST_SUITE_NAMESPACE, consumerName);
                 JobUtils.deleteJobWithWait(Environment.TEST_SUITE_NAMESPACE, consumerName);
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
index 69dcd6b2cc9..b19cf32cf8c 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.model.kafka.KafkaResources;
 import io.strimzi.api.kafka.model.kafka.listener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.kafka.listener.KafkaListenerType;
-import io.strimzi.api.kafka.model.mirrormaker.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpec;
 import io.strimzi.api.kafka.model.mirrormaker2.KafkaMirrorMaker2ClusterSpecBuilder;
@@ -35,7 +34,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -44,14 +42,11 @@
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.WaitException;
 import io.strimzi.test.k8s.KubeClusterResource;
 import io.vertx.core.cli.annotations.Description;
-import org.apache.kafka.clients.consumer.ConsumerConfig;
-import org.apache.kafka.clients.producer.ProducerConfig;
 import org.apache.logging.log4j.Level;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -65,15 +60,11 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.TestTags.OAUTH;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
-import static org.hamcrest.CoreMatchers.containsString;
-import static org.hamcrest.CoreMatchers.not;
-import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assumptions.assumeFalse;
 
 @Tag(OAUTH)
@@ -260,161 +251,6 @@ void testProducerConsumerBridge() {
         ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, producerName, testStorage.getMessageCount());
     }
 
-    @Description("As a OAuth MirrorMaker, I am able to replicate Topic data using using encrypted communication")
-    @IsolatedTest("Using more tha one Kafka cluster in one Namespace")
-    @Tag(MIRROR_MAKER)
-    @Tag(NODEPORT_SUPPORTED)
-    @Tag(ACCEPTANCE)
-    @SuppressWarnings({"checkstyle:MethodLength"})
-    void testMirrorMaker() {
-        // Nodeport needs cluster wide rights to work properly which is not possible with STRIMZI_RBAC_SCOPE=NAMESPACE
-        assumeFalse(Environment.isNamespaceRbacScope());
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-
-        String producerName = OAUTH_PRODUCER_NAME + "-" + testStorage.getClusterName();
-        String consumerName = OAUTH_CONSUMER_NAME + "-" + testStorage.getClusterName();
-
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(Environment.TEST_SUITE_NAMESPACE, testStorage.getTopicName(), oauthClusterName).build());
-
-        KafkaOauthClients oauthExampleClients = new KafkaOauthClientsBuilder()
-            .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-            .withProducerName(producerName)
-            .withConsumerName(consumerName)
-            .withBootstrapAddress(KafkaResources.tlsBootstrapAddress(oauthClusterName))
-            .withTopicName(testStorage.getTopicName())
-            .withMessageCount(testStorage.getMessageCount())
-            .withOauthClientId(OAUTH_CLIENT_NAME)
-            .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-            .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-            .build();
-
-        resourceManager.createResourceWithWait(oauthExampleClients.producerStrimziOauthTls(oauthClusterName));
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, producerName, testStorage.getMessageCount());
-
-        resourceManager.createResourceWithWait(oauthExampleClients.consumerStrimziOauthTls(oauthClusterName));
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, consumerName, testStorage.getMessageCount());
-
-        String targetKafkaCluster = oauthClusterName + "-target";
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), targetKafkaCluster, 1).build(),
-                KafkaNodePoolTemplates.controllerPoolPersistentStorage(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), targetKafkaCluster, 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(Environment.TEST_SUITE_NAMESPACE, targetKafkaCluster, 1, 1)
-            .editSpec()
-                .editKafka()
-                    .withListeners(OauthAbstractST.BUILD_OAUTH_TLS_LISTENER.apply(keycloakInstance),
-                            new GenericKafkaListenerBuilder()
-                                .withName(TestConstants.EXTERNAL_LISTENER_DEFAULT_NAME)
-                                .withPort(9094)
-                                .withType(KafkaListenerType.NODEPORT)
-                                .withTls(true)
-                                .withNewKafkaListenerAuthenticationOAuth()
-                                .withValidIssuerUri(keycloakInstance.getValidIssuerUri())
-                                .withJwksExpirySeconds(keycloakInstance.getJwksExpireSeconds())
-                                .withJwksRefreshSeconds(keycloakInstance.getJwksRefreshSeconds())
-                                .withJwksEndpointUri(keycloakInstance.getJwksEndpointUri())
-                                .withUserNameClaim(keycloakInstance.getUserNameClaim())
-                                .withTlsTrustedCertificates(
-                                    new CertSecretSourceBuilder()
-                                        .withSecretName(KeycloakInstance.KEYCLOAK_SECRET_NAME)
-                                        .withCertificate(KeycloakInstance.KEYCLOAK_SECRET_CERT)
-                                        .build())
-                                    .withDisableTlsHostnameVerification(true)
-                                .endKafkaListenerAuthenticationOAuth()
-                                .build())
-                .endKafka()
-            .endSpec()
-            .build());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(Environment.TEST_SUITE_NAMESPACE, oauthClusterName, oauthClusterName, targetKafkaCluster,
-            ClientUtils.generateRandomConsumerGroup(), 1, true)
-                .editSpec()
-                    .withNewConsumer()
-                        // this is for kafka tls connection
-                        .withNewTls()
-                            .withTrustedCertificates(new CertSecretSourceBuilder()
-                                .withCertificate("ca.crt")
-                                .withSecretName(KafkaResources.clusterCaCertificateSecretName(oauthClusterName))
-                                .build())
-                        .endTls()
-                        .withBootstrapServers(KafkaResources.tlsBootstrapAddress(oauthClusterName))
-                        .withGroupId(ClientUtils.generateRandomConsumerGroup())
-                        .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
-                        .withNewKafkaClientAuthenticationOAuth()
-                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                            .withClientId("kafka-mirror-maker")
-                            .withNewClientSecret()
-                                .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                                .withKey(OAUTH_KEY)
-                            .endClientSecret()
-                            // this is for authorization server tls connection
-                            .withTlsTrustedCertificates(new CertSecretSourceBuilder()
-                                .withSecretName(KeycloakInstance.KEYCLOAK_SECRET_NAME)
-                                .withCertificate(KeycloakInstance.KEYCLOAK_SECRET_CERT)
-                                .build())
-                            .withDisableTlsHostnameVerification(true)
-                        .endKafkaClientAuthenticationOAuth()
-                    .endConsumer()
-                    .withNewProducer()
-                        .withBootstrapServers(KafkaResources.tlsBootstrapAddress(targetKafkaCluster))
-                        // this is for kafka tls connection
-                        .withNewTls()
-                            .withTrustedCertificates(new CertSecretSourceBuilder()
-                                .withCertificate("ca.crt")
-                                .withSecretName(KafkaResources.clusterCaCertificateSecretName(targetKafkaCluster))
-                                .build())
-                        .endTls()
-                        .withNewKafkaClientAuthenticationOAuth()
-                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-                            .withClientId("kafka-mirror-maker")
-                            .withNewClientSecret()
-                                .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
-                                .withKey(OAUTH_KEY)
-                            .endClientSecret()
-                            // this is for authorization server tls connection
-                            .withTlsTrustedCertificates(new CertSecretSourceBuilder()
-                                .withSecretName(KeycloakInstance.KEYCLOAK_SECRET_NAME)
-                                .withCertificate(KeycloakInstance.KEYCLOAK_SECRET_CERT)
-                                .build())
-                            .withDisableTlsHostnameVerification(true)
-                        .endKafkaClientAuthenticationOAuth()
-                        .addToConfig(ProducerConfig.ACKS_CONFIG, "all")
-                    .endProducer()
-                .endSpec()
-                .build());
-
-        String mirrorMakerPodName = kubeClient().listPodsByPrefixInName(Environment.TEST_SUITE_NAMESPACE, KafkaMirrorMakerResources.componentName(oauthClusterName)).get(0).getMetadata().getName();
-        String kafkaMirrorMakerLogs = kubeClient().logsInSpecificNamespace(Environment.TEST_SUITE_NAMESPACE, mirrorMakerPodName);
-
-        assertThat(kafkaMirrorMakerLogs,
-            not(containsString("keytool error: java.io.FileNotFoundException: /opt/kafka/consumer-oauth-certs/**/* (No such file or directory)")));
-
-        resourceManager.createResourceWithWait(KafkaUserTemplates.tlsUser(Environment.TEST_SUITE_NAMESPACE, testStorage.getUsername(), oauthClusterName).build());
-        KafkaUserUtils.waitForKafkaUserCreation(Environment.TEST_SUITE_NAMESPACE, testStorage.getUsername());
-
-        LOGGER.info("Creating new client with new consumer-group and also to point on {} cluster", targetKafkaCluster);
-
-        KafkaOauthClients kafkaOauthClientJob = new KafkaOauthClientsBuilder()
-            .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
-            .withProducerName(producerName)
-            .withConsumerName(consumerName)
-            .withClientUserName(testStorage.getUsername())
-            .withBootstrapAddress(KafkaResources.tlsBootstrapAddress(targetKafkaCluster))
-            .withTopicName(testStorage.getTopicName())
-            .withMessageCount(testStorage.getMessageCount())
-            .withOauthClientId(OAUTH_CLIENT_NAME)
-            .withOauthClientSecret(OAUTH_CLIENT_SECRET)
-            .withOauthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
-            .build();
-
-        resourceManager.createResourceWithWait(kafkaOauthClientJob.consumerStrimziOauthTls(targetKafkaCluster));
-
-        ClientUtils.waitForClientSuccess(Environment.TEST_SUITE_NAMESPACE, consumerName, testStorage.getMessageCount());
-    }
-
     @Description("As a OAuth MirrorMaker 2, I am able to replicate Topic data using using encrypted communication")
     @IsolatedTest("Using more tha one Kafka cluster in one Namespace")
     @Tag(MIRROR_MAKER2)
@@ -559,7 +395,7 @@ void testMirrorMaker2() {
         verifyOauthConfiguration(kafkaMirrorMaker2Logs);
 
         TestUtils.waitFor("MirrorMaker2 to copy messages from " + kafkaSourceClusterName + " to " + testStorage.getTargetClusterName(),
-                Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
+                Duration.ofSeconds(30).toMillis(), TestConstants.TIMEOUT_FOR_MIRROR_MAKER_2_COPY_MESSAGES_BETWEEN_BROKERS,
                 () -> {
                     LOGGER.info("Deleting Job: {}/{}", Environment.TEST_SUITE_NAMESPACE, consumerName);
                     JobUtils.deleteJobWithWait(Environment.TEST_SUITE_NAMESPACE, consumerName);
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java b/systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
index 645f252dc88..1e382d3b20d 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
@@ -26,7 +26,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
-import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -47,7 +46,6 @@
 import static io.strimzi.systemtest.TestTags.BRIDGE;
 import static io.strimzi.systemtest.TestTags.CONNECT;
 import static io.strimzi.systemtest.TestTags.CONNECT_COMPONENTS;
-import static io.strimzi.systemtest.TestTags.MIRROR_MAKER;
 import static io.strimzi.systemtest.TestTags.MIRROR_MAKER2;
 import static io.strimzi.systemtest.TestTags.REGRESSION;
 import static io.strimzi.systemtest.TestTags.TRACING;
@@ -57,7 +55,6 @@
 import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_KAFKA_CONNECT_SERVICE;
 import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_KAFKA_STREAMS_SERVICE;
 import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_MIRROR_MAKER2_SERVICE;
-import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_MIRROR_MAKER_SERVICE;
 import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_PRODUCER_SERVICE;
 import static io.strimzi.systemtest.tracing.TracingConstants.JAEGER_QUERY_SERVICE;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -188,73 +185,6 @@ void testProducerConsumerMirrorMaker2Service() {
             "To_" + testStorage.getMirroredSourceTopicName(), JAEGER_QUERY_SERVICE);
     }
 
-    @ParallelNamespaceTest
-    @Tag(MIRROR_MAKER)
-    void testProducerConsumerMirrorMakerService() {
-        final TestStorage testStorage = deployInitialResourcesAndGetTestStorage();
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPool(testStorage.getNamespaceName(), testStorage.getSourceBrokerPoolName(), testStorage.getSourceClusterName(), 3).build(),
-                KafkaNodePoolTemplates.controllerPool(testStorage.getNamespaceName(), testStorage.getSourceControllerPoolName(), testStorage.getSourceClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getSourceClusterName(), 1).build());
-
-        resourceManager.createResourceWithWait(
-            NodePoolsConverter.convertNodePoolsIfNeeded(
-                KafkaNodePoolTemplates.brokerPool(testStorage.getNamespaceName(), testStorage.getTargetBrokerPoolName(), testStorage.getTargetClusterName(), 3).build(),
-                KafkaNodePoolTemplates.controllerPool(testStorage.getNamespaceName(), testStorage.getTargetControllerPoolName(), testStorage.getTargetClusterName(), 1).build()
-            )
-        );
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getNamespaceName(), testStorage.getTargetClusterName(), 1).build());
-
-        // Create topic and deploy clients before Mirror Maker to not wait for MM to find the new topics
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(testStorage.getNamespaceName(), testStorage.getTopicName(), testStorage.getSourceClusterName(), 12, 3).build());
-        resourceManager.createResourceWithWait(KafkaTopicTemplates.topic(testStorage.getNamespaceName(), testStorage.getTargetTopicName(), testStorage.getTargetClusterName(), 12, 3).build());
-
-        LOGGER.info("Setting for Kafka source plain bootstrap: {}", KafkaResources.plainBootstrapAddress(testStorage.getSourceClusterName()));
-
-        final KafkaTracingClients sourceKafkaTracingClient =
-            new KafkaTracingClientsBuilder(testStorage.getTracingClients())
-                .withBootstrapAddress(KafkaResources.plainBootstrapAddress(testStorage.getSourceClusterName()))
-                .build();
-
-        resourceManager.createResourceWithWait(sourceKafkaTracingClient.producerWithTracing());
-
-        LOGGER.info("Setting for Kafka target plain bootstrap: {}", KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()));
-
-        KafkaTracingClients targetKafkaTracingClient =  new KafkaTracingClientsBuilder(testStorage.getTracingClients())
-            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(testStorage.getTargetClusterName()))
-            .build();
-
-        resourceManager.createResourceWithWait(targetKafkaTracingClient.consumerWithTracing());
-
-        resourceManager.createResourceWithWait(KafkaMirrorMakerTemplates.kafkaMirrorMaker(testStorage.getNamespaceName(), testStorage.getClusterName(), testStorage.getSourceClusterName(), testStorage.getTargetClusterName(),
-                ClientUtils.generateRandomConsumerGroup(), 1, false)
-            .editSpec()
-                .withTracing(otelTracing)
-                .withNewTemplate()
-                    .withNewMirrorMakerContainer()
-                        .addNewEnv()
-                            .withName(TracingConstants.OTEL_SERVICE_ENV)
-                            .withValue(JAEGER_MIRROR_MAKER_SERVICE)
-                        .endEnv()
-                        .addNewEnv()
-                            .withName("OTEL_EXPORTER_OTLP_ENDPOINT")
-                            .withValue(JAEGER_COLLECTOR_OTLP_URL)
-                        .endEnv()
-                    .endMirrorMakerContainer()
-                .endTemplate()
-            .endSpec()
-            .build());
-
-        TracingUtils.verify(testStorage.getNamespaceName(), JAEGER_PRODUCER_SERVICE, testStorage.getScraperPodName(), "To_" + testStorage.getTopicName(), JAEGER_QUERY_SERVICE);
-        TracingUtils.verify(testStorage.getNamespaceName(), JAEGER_CONSUMER_SERVICE, testStorage.getScraperPodName(), "From_" + testStorage.getTopicName(), JAEGER_QUERY_SERVICE);
-        TracingUtils.verify(testStorage.getNamespaceName(), JAEGER_MIRROR_MAKER_SERVICE, testStorage.getScraperPodName(), "From_" + testStorage.getTopicName(), JAEGER_QUERY_SERVICE);
-        TracingUtils.verify(testStorage.getNamespaceName(), JAEGER_MIRROR_MAKER_SERVICE, testStorage.getScraperPodName(), "To_" + testStorage.getTopicName(), JAEGER_QUERY_SERVICE);
-    }
-
     @ParallelNamespaceTest
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)
diff --git a/systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java b/systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
index 171263c2942..fdb796d1136 100644
--- a/systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
+++ b/systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
@@ -216,7 +216,7 @@ final void testUserInNamespaceDifferentFromUserOperator(ExtensionContext extensi
     @ParallelTest
     @Tag(MIRROR_MAKER2)
     final void testDeployMirrorMaker2InNamespaceDifferentFromCO(ExtensionContext extensionContext) {
-        LOGGER.info("Deploying KafkaMirrorMaker in different Namespace than CO");
+        LOGGER.info("Deploying KafkaMirrorMaker2 in different Namespace than CO");
         final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
         final String mirrorMakerName = testStorage.getClusterName() + "-mirror-maker-2";
 
diff --git a/test/src/main/java/io/strimzi/test/CrdUtils.java b/test/src/main/java/io/strimzi/test/CrdUtils.java
index b6b73f45b25..29843c5b05b 100644
--- a/test/src/main/java/io/strimzi/test/CrdUtils.java
+++ b/test/src/main/java/io/strimzi/test/CrdUtils.java
@@ -35,11 +35,6 @@ public final class CrdUtils {
      */
     public static final String CRD_KAFKA_USER = TestUtils.USER_PATH + "/../packaging/install/cluster-operator/044-Crd-kafkauser.yaml";
 
-    /**
-     * Path to the KafkaMirrorMaker CRD definition YAML
-     */
-    public static final String CRD_KAFKA_MIRROR_MAKER = TestUtils.USER_PATH + "/../packaging/install/cluster-operator/045-Crd-kafkamirrormaker.yaml";
-
     /**
      * Path to the KafkaBridge CRD definition YAML
      */
