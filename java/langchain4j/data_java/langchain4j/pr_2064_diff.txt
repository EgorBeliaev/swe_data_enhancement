diff --git a/langchain4j-open-ai/pom.xml b/langchain4j-open-ai/pom.xml
index 5899d7fb90f..6eb0573124a 100644
--- a/langchain4j-open-ai/pom.xml
+++ b/langchain4j-open-ai/pom.xml
@@ -55,12 +55,6 @@
             <artifactId>jtokkit</artifactId>
         </dependency>
 
-        <dependency>
-            <groupId>org.projectlombok</groupId>
-            <artifactId>lombok</artifactId>
-            <scope>provided</scope>
-        </dependency>
-
         <dependency>
             <groupId>org.junit.jupiter</groupId>
             <artifactId>junit-jupiter-engine</artifactId>
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/InternalOpenAiHelper.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/InternalOpenAiHelper.java
index 083fd99010c..e9580815718 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/InternalOpenAiHelper.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/InternalOpenAiHelper.java
@@ -85,8 +85,7 @@ public static Message toOpenAiMessage(ChatMessage message) {
             return dev.ai4j.openai4j.chat.SystemMessage.from(((SystemMessage) message).text());
         }
 
-        if (message instanceof UserMessage) {
-            UserMessage userMessage = (UserMessage) message;
+        if (message instanceof UserMessage userMessage) {
 
             if (userMessage.hasSingleText()) {
                 return dev.ai4j.openai4j.chat.UserMessage.builder()
@@ -103,8 +102,7 @@ public static Message toOpenAiMessage(ChatMessage message) {
             }
         }
 
-        if (message instanceof AiMessage) {
-            AiMessage aiMessage = (AiMessage) message;
+        if (message instanceof AiMessage aiMessage) {
 
             if (!aiMessage.hasToolExecutionRequests()) {
                 return AssistantMessage.from(aiMessage.text());
@@ -139,8 +137,7 @@ public static Message toOpenAiMessage(ChatMessage message) {
                     .build();
         }
 
-        if (message instanceof ToolExecutionResultMessage) {
-            ToolExecutionResultMessage toolExecutionResultMessage = (ToolExecutionResultMessage) message;
+        if (message instanceof ToolExecutionResultMessage toolExecutionResultMessage) {
 
             if (toolExecutionResultMessage.id() == null) {
                 return FunctionMessage.from(toolExecutionResultMessage.toolName(), toolExecutionResultMessage.text());
@@ -299,8 +296,7 @@ private static dev.ai4j.openai4j.chat.JsonSchemaElement toOpenAiJsonSchemaElemen
             JsonSchemaElement jsonSchemaElement,
             boolean strict) {
 
-        if (jsonSchemaElement instanceof JsonObjectSchema) {
-            JsonObjectSchema jsonObjectSchema = (JsonObjectSchema) jsonSchemaElement;
+        if (jsonSchemaElement instanceof JsonObjectSchema jsonObjectSchema) {
             dev.ai4j.openai4j.chat.JsonObjectSchema.Builder builder = dev.ai4j.openai4j.chat.JsonObjectSchema.builder()
                     .description(jsonObjectSchema.description())
                     .properties(toOpenAiProperties(jsonObjectSchema.properties(), strict))
@@ -319,40 +315,33 @@ private static dev.ai4j.openai4j.chat.JsonSchemaElement toOpenAiJsonSchemaElemen
                         .additionalProperties(false);
             }
             return builder.build();
-        } else if (jsonSchemaElement instanceof JsonArraySchema) {
-            JsonArraySchema jsonArraySchema = (JsonArraySchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonArraySchema jsonArraySchema) {
             return dev.ai4j.openai4j.chat.JsonArraySchema.builder()
                     .description(jsonArraySchema.description())
                     .items(toOpenAiJsonSchemaElement(jsonArraySchema.items(), strict))
                     .build();
-        } else if (jsonSchemaElement instanceof JsonEnumSchema) {
-            JsonEnumSchema jsonEnumSchema = (JsonEnumSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonEnumSchema jsonEnumSchema) {
             return dev.ai4j.openai4j.chat.JsonEnumSchema.builder()
                     .description(jsonEnumSchema.description())
                     .enumValues(jsonEnumSchema.enumValues())
                     .build();
-        } else if (jsonSchemaElement instanceof JsonStringSchema) {
-            JsonStringSchema jsonStringSchema = (JsonStringSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonStringSchema jsonStringSchema) {
             return dev.ai4j.openai4j.chat.JsonStringSchema.builder()
                     .description(jsonStringSchema.description())
                     .build();
-        } else if (jsonSchemaElement instanceof JsonIntegerSchema) {
-            JsonIntegerSchema jsonIntegerSchema = (JsonIntegerSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonIntegerSchema jsonIntegerSchema) {
             return dev.ai4j.openai4j.chat.JsonIntegerSchema.builder()
                     .description(jsonIntegerSchema.description())
                     .build();
-        } else if (jsonSchemaElement instanceof JsonNumberSchema) {
-            JsonNumberSchema jsonNumberSchema = (JsonNumberSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonNumberSchema jsonNumberSchema) {
             return dev.ai4j.openai4j.chat.JsonNumberSchema.builder()
                     .description(jsonNumberSchema.description())
                     .build();
-        } else if (jsonSchemaElement instanceof JsonBooleanSchema) {
-            JsonBooleanSchema jsonBooleanSchema = (JsonBooleanSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonBooleanSchema jsonBooleanSchema) {
             return dev.ai4j.openai4j.chat.JsonBooleanSchema.builder()
                     .description(jsonBooleanSchema.description())
                     .build();
-        } else if (jsonSchemaElement instanceof JsonReferenceSchema) {
-            JsonReferenceSchema jsonReferenceSchema = (JsonReferenceSchema) jsonSchemaElement;
+        } else if (jsonSchemaElement instanceof JsonReferenceSchema jsonReferenceSchema) {
             return dev.ai4j.openai4j.chat.JsonReferenceSchema.builder()
                     .reference("#/$defs/" + jsonReferenceSchema.reference())
                     .build();
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiChatModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiChatModel.java
index a1c8a9320d3..d7d5ee2fdf4 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiChatModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiChatModel.java
@@ -23,8 +23,7 @@
 import dev.langchain4j.model.chat.response.ChatResponse;
 import dev.langchain4j.model.openai.spi.OpenAiChatModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
-import lombok.extern.slf4j.Slf4j;
+import org.slf4j.Logger;
 
 import java.net.Proxy;
 import java.time.Duration;
@@ -34,6 +33,7 @@
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
+import java.util.StringJoiner;
 import java.util.concurrent.ConcurrentHashMap;
 
 import static dev.ai4j.openai4j.chat.ResponseFormatType.JSON_SCHEMA;
@@ -62,9 +62,9 @@
  * Represents an OpenAI language model with a chat completion interface, such as gpt-3.5-turbo and gpt-4.
  * You can find description of parameters <a href="https://platform.openai.com/docs/api-reference/chat/create">here</a>.
  */
-@Slf4j
 public class OpenAiChatModel implements ChatLanguageModel, TokenCountEstimator {
 
+    private static final Logger log = org.slf4j.LoggerFactory.getLogger(OpenAiChatModel.class);
     private final OpenAiClient client;
     private final String modelName;
     private final Double temperature;
@@ -85,7 +85,6 @@ public class OpenAiChatModel implements ChatLanguageModel, TokenCountEstimator {
     private final Tokenizer tokenizer;
     private final List<ChatModelListener> listeners;
 
-    @Builder
     public OpenAiChatModel(String baseUrl,
                            String apiKey,
                            String organizationId,
@@ -326,9 +325,35 @@ public static OpenAiChatModelBuilder builder() {
 
     public static class OpenAiChatModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Double temperature;
+        private Double topP;
+        private List<String> stop;
+        private Integer maxTokens;
+        private Integer maxCompletionTokens;
+        private Double presencePenalty;
+        private Double frequencyPenalty;
+        private Map<String, Integer> logitBias;
+        private String responseFormat;
+        private Boolean strictJsonSchema;
+        private Integer seed;
+        private String user;
+        private Boolean strictTools;
+        private Boolean parallelToolCalls;
+        private Duration timeout;
+        private Integer maxRetries;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Tokenizer tokenizer;
+        private Map<String, String> customHeaders;
+        private List<ChatModelListener> listeners;
+
         public OpenAiChatModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiChatModelBuilder modelName(String modelName) {
@@ -340,5 +365,192 @@ public OpenAiChatModelBuilder modelName(OpenAiChatModelName modelName) {
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiChatModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder temperature(Double temperature) {
+            this.temperature = temperature;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder topP(Double topP) {
+            this.topP = topP;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder stop(List<String> stop) {
+            this.stop = stop;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder maxTokens(Integer maxTokens) {
+            this.maxTokens = maxTokens;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder maxCompletionTokens(Integer maxCompletionTokens) {
+            this.maxCompletionTokens = maxCompletionTokens;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder presencePenalty(Double presencePenalty) {
+            this.presencePenalty = presencePenalty;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder frequencyPenalty(Double frequencyPenalty) {
+            this.frequencyPenalty = frequencyPenalty;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder logitBias(Map<String, Integer> logitBias) {
+            this.logitBias = logitBias;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder responseFormat(String responseFormat) {
+            this.responseFormat = responseFormat;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder strictJsonSchema(Boolean strictJsonSchema) {
+            this.strictJsonSchema = strictJsonSchema;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder seed(Integer seed) {
+            this.seed = seed;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder user(String user) {
+            this.user = user;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder strictTools(Boolean strictTools) {
+            this.strictTools = strictTools;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder parallelToolCalls(Boolean parallelToolCalls) {
+            this.parallelToolCalls = parallelToolCalls;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder maxRetries(Integer maxRetries) {
+            this.maxRetries = maxRetries;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder tokenizer(Tokenizer tokenizer) {
+            this.tokenizer = tokenizer;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiChatModelBuilder listeners(List<ChatModelListener> listeners) {
+            this.listeners = listeners;
+            return this;
+        }
+
+        public OpenAiChatModel build() {
+            return new OpenAiChatModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.temperature,
+                    this.topP,
+                    this.stop,
+                    this.maxTokens,
+                    this.maxCompletionTokens,
+                    this.presencePenalty,
+                    this.frequencyPenalty,
+                    this.logitBias,
+                    this.responseFormat,
+                    this.strictJsonSchema,
+                    this.seed,
+                    this.user,
+                    this.strictTools,
+                    this.parallelToolCalls,
+                    this.timeout,
+                    this.maxRetries,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.tokenizer,
+                    this.customHeaders,
+                    this.listeners
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiChatModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("temperature=" + temperature)
+                    .add("topP=" + topP)
+                    .add("stop=" + stop)
+                    .add("maxTokens=" + maxTokens)
+                    .add("maxCompletionTokens=" + maxCompletionTokens)
+                    .add("presencePenalty=" + presencePenalty)
+                    .add("frequencyPenalty=" + frequencyPenalty)
+                    .add("logitBias=" + logitBias)
+                    .add("responseFormat='" + responseFormat + "'")
+                    .add("strictJsonSchema=" + strictJsonSchema)
+                    .add("seed=" + seed)
+                    .add("user='" + user + "'")
+                    .add("strictTools=" + strictTools)
+                    .add("parallelToolCalls=" + parallelToolCalls)
+                    .add("timeout=" + timeout)
+                    .add("maxRetries=" + maxRetries)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("tokenizer=" + tokenizer)
+                    .add("customHeaders=" + customHeaders)
+                    .add("listeners=" + listeners)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiEmbeddingModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiEmbeddingModel.java
index 3100c29af1b..db277c5d7d8 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiEmbeddingModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiEmbeddingModel.java
@@ -10,20 +10,23 @@
 import dev.langchain4j.model.embedding.TokenCountEstimator;
 import dev.langchain4j.model.openai.spi.OpenAiEmbeddingModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
 
 import java.net.Proxy;
 import java.time.Duration;
 import java.util.List;
 import java.util.Map;
+import java.util.StringJoiner;
 
 import static dev.langchain4j.internal.RetryUtils.withRetry;
 import static dev.langchain4j.internal.Utils.getOrDefault;
-import static dev.langchain4j.model.openai.InternalOpenAiHelper.*;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.DEFAULT_USER_AGENT;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_DEMO_API_KEY;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_DEMO_URL;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_URL;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.tokenUsageFrom;
 import static dev.langchain4j.model.openai.OpenAiModelName.TEXT_EMBEDDING_ADA_002;
 import static dev.langchain4j.spi.ServiceHelper.loadFactories;
 import static java.time.Duration.ofSeconds;
-import static java.util.stream.Collectors.toList;
 
 /**
  * Represents an OpenAI embedding model, such as text-embedding-ada-002.
@@ -37,7 +40,6 @@ public class OpenAiEmbeddingModel extends DimensionAwareEmbeddingModel implement
     private final Integer maxRetries;
     private final Tokenizer tokenizer;
 
-    @Builder
     public OpenAiEmbeddingModel(String baseUrl,
                                 String apiKey,
                                 String organizationId,
@@ -98,7 +100,7 @@ public Response<List<Embedding>> embedAll(List<TextSegment> textSegments) {
 
         List<String> texts = textSegments.stream()
                 .map(TextSegment::text)
-                .collect(toList());
+                .toList();
 
         return embedTexts(texts);
     }
@@ -116,7 +118,7 @@ private Response<List<Embedding>> embedTexts(List<String> texts) {
 
         List<Embedding> embeddings = response.data().stream()
                 .map(openAiEmbedding -> Embedding.from(openAiEmbedding.embedding()))
-                .collect(toList());
+                .toList();
 
         return Response.from(
                 embeddings,
@@ -148,9 +150,22 @@ public static OpenAiEmbeddingModelBuilder builder() {
 
     public static class OpenAiEmbeddingModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Integer dimensions;
+        private String user;
+        private Duration timeout;
+        private Integer maxRetries;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Tokenizer tokenizer;
+        private Map<String, String> customHeaders;
+
         public OpenAiEmbeddingModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiEmbeddingModelBuilder modelName(String modelName) {
@@ -162,5 +177,101 @@ public OpenAiEmbeddingModelBuilder modelName(OpenAiEmbeddingModelName modelName)
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiEmbeddingModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder dimensions(Integer dimensions) {
+            this.dimensions = dimensions;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder user(String user) {
+            this.user = user;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder maxRetries(Integer maxRetries) {
+            this.maxRetries = maxRetries;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder tokenizer(Tokenizer tokenizer) {
+            this.tokenizer = tokenizer;
+            return this;
+        }
+
+        public OpenAiEmbeddingModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiEmbeddingModel build() {
+            return new OpenAiEmbeddingModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.dimensions,
+                    this.user,
+                    this.timeout,
+                    this.maxRetries,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.tokenizer,
+                    this.customHeaders
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiEmbeddingModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("dimensions=" + dimensions)
+                    .add("user='" + user + "'")
+                    .add("timeout=" + timeout)
+                    .add("maxRetries=" + maxRetries)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("tokenizer=" + tokenizer)
+                    .add("customHeaders=" + customHeaders)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiImageModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiImageModel.java
index 03d86880ba4..3e6fc3965f6 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiImageModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiImageModel.java
@@ -8,13 +8,13 @@
 import dev.langchain4j.model.image.ImageModel;
 import dev.langchain4j.model.openai.spi.OpenAiImageModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
 
 import java.net.Proxy;
 import java.nio.file.Path;
 import java.time.Duration;
 import java.util.List;
 import java.util.Map;
+import java.util.StringJoiner;
 import java.util.stream.Collectors;
 
 import static dev.langchain4j.internal.RetryUtils.withRetry;
@@ -53,7 +53,6 @@ public class OpenAiImageModel implements ImageModel {
      *                       The URL within <code>dev.ai4j.openai4j.image.GenerateImagesResponse</code> will contain
      *                       the URL to local images then.
      */
-    @Builder
     @SuppressWarnings("rawtypes")
     public OpenAiImageModel(
             String baseUrl,
@@ -139,9 +138,26 @@ public static OpenAiImageModelBuilder builder() {
     }
 
     public static class OpenAiImageModelBuilder {
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private String size;
+        private String quality;
+        private String style;
+        private String user;
+        private String responseFormat;
+        private Duration timeout;
+        private Integer maxRetries;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Boolean withPersisting;
+        private Path persistTo;
+        private Map<String, String> customHeaders;
+
         public OpenAiImageModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiImageModelBuilder modelName(String modelName) {
@@ -162,6 +178,125 @@ public OpenAiImageModelBuilder withPersisting(Boolean withPersisting) {
             this.withPersisting = withPersisting;
             return this;
         }
+
+        public OpenAiImageModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder size(String size) {
+            this.size = size;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder quality(String quality) {
+            this.quality = quality;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder style(String style) {
+            this.style = style;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder user(String user) {
+            this.user = user;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder responseFormat(String responseFormat) {
+            this.responseFormat = responseFormat;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder maxRetries(Integer maxRetries) {
+            this.maxRetries = maxRetries;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder persistTo(Path persistTo) {
+            this.persistTo = persistTo;
+            return this;
+        }
+
+        public OpenAiImageModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiImageModel build() {
+            return new OpenAiImageModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.size,
+                    this.quality,
+                    this.style,
+                    this.user,
+                    this.responseFormat,
+                    this.timeout,
+                    this.maxRetries,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.withPersisting,
+                    this.persistTo,
+                    this.customHeaders
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiImageModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("size='" + size + "'")
+                    .add("quality='" + quality + "'")
+                    .add("style='" + style + "'")
+                    .add("user='" + user + "'")
+                    .add("responseFormat='" + responseFormat + "'")
+                    .add("timeout=" + timeout)
+                    .add("maxRetries=" + maxRetries)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("withPersisting=" + withPersisting)
+                    .add("persistTo=" + persistTo)
+                    .add("customHeaders=" + customHeaders)
+                    .toString();
+        }
     }
 
     /**
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiLanguageModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiLanguageModel.java
index 1025759e681..9b1078ae8b2 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiLanguageModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiLanguageModel.java
@@ -9,15 +9,18 @@
 import dev.langchain4j.model.language.TokenCountEstimator;
 import dev.langchain4j.model.openai.spi.OpenAiLanguageModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
 
 import java.net.Proxy;
 import java.time.Duration;
 import java.util.Map;
+import java.util.StringJoiner;
 
 import static dev.langchain4j.internal.RetryUtils.withRetry;
 import static dev.langchain4j.internal.Utils.getOrDefault;
-import static dev.langchain4j.model.openai.InternalOpenAiHelper.*;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.DEFAULT_USER_AGENT;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_URL;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.finishReasonFrom;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.tokenUsageFrom;
 import static dev.langchain4j.model.openai.OpenAiModelName.GPT_3_5_TURBO_INSTRUCT;
 import static dev.langchain4j.spi.ServiceHelper.loadFactories;
 import static java.time.Duration.ofSeconds;
@@ -35,7 +38,6 @@ public class OpenAiLanguageModel implements LanguageModel, TokenCountEstimator {
     private final Integer maxRetries;
     private final Tokenizer tokenizer;
 
-    @Builder
     public OpenAiLanguageModel(String baseUrl,
                                String apiKey,
                                String organizationId,
@@ -116,11 +118,27 @@ public static OpenAiLanguageModelBuilder builder() {
         return new OpenAiLanguageModelBuilder();
     }
 
+    /**
+     * Builder class for constructing instances of {@code OpenAiLanguageModel}.
+     * Provides a fluent interface to configure various parameters for the language model.
+     */
     public static class OpenAiLanguageModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Double temperature;
+        private Duration timeout;
+        private Integer maxRetries;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Tokenizer tokenizer;
+        private Map<String, String> customHeaders;
+
         public OpenAiLanguageModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiLanguageModelBuilder modelName(String modelName) {
@@ -132,5 +150,94 @@ public OpenAiLanguageModelBuilder modelName(OpenAiLanguageModelName modelName) {
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiLanguageModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder temperature(Double temperature) {
+            this.temperature = temperature;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder maxRetries(Integer maxRetries) {
+            this.maxRetries = maxRetries;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder tokenizer(Tokenizer tokenizer) {
+            this.tokenizer = tokenizer;
+            return this;
+        }
+
+        public OpenAiLanguageModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiLanguageModel build() {
+            return new OpenAiLanguageModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.temperature,
+                    this.timeout,
+                    this.maxRetries,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.tokenizer,
+                    this.customHeaders
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiLanguageModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("temperature=" + temperature)
+                    .add("timeout=" + timeout)
+                    .add("maxRetries=" + maxRetries)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("tokenizer=" + tokenizer)
+                    .add("customHeaders=" + customHeaders)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiModerationModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiModerationModel.java
index fd30c510570..d04370a3839 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiModerationModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiModerationModel.java
@@ -9,21 +9,23 @@
 import dev.langchain4j.model.moderation.ModerationModel;
 import dev.langchain4j.model.openai.spi.OpenAiModerationModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
 
 import java.net.Proxy;
 import java.time.Duration;
 import java.util.List;
 import java.util.Map;
+import java.util.StringJoiner;
 
 import static dev.langchain4j.internal.RetryUtils.withRetry;
 import static dev.langchain4j.internal.Utils.getOrDefault;
-import static dev.langchain4j.model.openai.InternalOpenAiHelper.*;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.DEFAULT_USER_AGENT;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_DEMO_API_KEY;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_DEMO_URL;
+import static dev.langchain4j.model.openai.InternalOpenAiHelper.OPENAI_URL;
 import static dev.langchain4j.model.openai.OpenAiModelName.TEXT_MODERATION_LATEST;
 import static dev.langchain4j.spi.ServiceHelper.loadFactories;
 import static java.time.Duration.ofSeconds;
 import static java.util.Collections.singletonList;
-import static java.util.stream.Collectors.toList;
 
 /**
  * Represents an OpenAI moderation model, such as text-moderation-latest.
@@ -34,7 +36,6 @@ public class OpenAiModerationModel implements ModerationModel {
     private final String modelName;
     private final Integer maxRetries;
 
-    @Builder
     public OpenAiModerationModel(String baseUrl,
                                  String apiKey,
                                  String organizationId,
@@ -91,7 +92,7 @@ private Response<Moderation> moderateInternal(List<String> inputs) {
 
         int i = 0;
         for (ModerationResult moderationResult : response.results()) {
-            if (moderationResult.isFlagged()) {
+            if (Boolean.TRUE.equals(moderationResult.isFlagged())) {
                 return Response.from(Moderation.flagged(inputs.get(i)));
             }
             i++;
@@ -105,7 +106,7 @@ private Response<Moderation> moderateInternal(List<String> inputs) {
     public Response<Moderation> moderate(List<ChatMessage> messages) {
         List<String> inputs = messages.stream()
                 .map(ChatMessage::text)
-                .collect(toList());
+                .toList();
 
         return moderateInternal(inputs);
     }
@@ -129,9 +130,19 @@ public static OpenAiModerationModelBuilder builder() {
 
     public static class OpenAiModerationModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Duration timeout;
+        private Integer maxRetries;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Map<String, String> customHeaders;
+
         public OpenAiModerationModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiModerationModelBuilder modelName(String modelName) {
@@ -143,5 +154,80 @@ public OpenAiModerationModelBuilder modelName(OpenAiModerationModelName modelNam
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiModerationModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder maxRetries(Integer maxRetries) {
+            this.maxRetries = maxRetries;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiModerationModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiModerationModel build() {
+            return new OpenAiModerationModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.timeout,
+                    this.maxRetries,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.customHeaders
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiModerationModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("timeout=" + timeout)
+                    .add("maxRetries=" + maxRetries)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("customHeaders=" + customHeaders)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingChatModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingChatModel.java
index a9459c07948..1735c611eb8 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingChatModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingChatModel.java
@@ -23,8 +23,7 @@
 import dev.langchain4j.model.chat.listener.ChatModelResponseContext;
 import dev.langchain4j.model.openai.spi.OpenAiStreamingChatModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
-import lombok.extern.slf4j.Slf4j;
+import org.slf4j.Logger;
 
 import java.net.Proxy;
 import java.time.Duration;
@@ -32,6 +31,7 @@
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
+import java.util.StringJoiner;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicReference;
 
@@ -55,9 +55,9 @@
  * The model's response is streamed token by token and should be handled with {@link StreamingResponseHandler}.
  * You can find description of parameters <a href="https://platform.openai.com/docs/api-reference/chat/create">here</a>.
  */
-@Slf4j
 public class OpenAiStreamingChatModel implements StreamingChatLanguageModel, TokenCountEstimator {
 
+    private static final Logger log = org.slf4j.LoggerFactory.getLogger(OpenAiStreamingChatModel.class);
     private final OpenAiClient client;
     private final String modelName;
     private final Double temperature;
@@ -76,7 +76,6 @@ public class OpenAiStreamingChatModel implements StreamingChatLanguageModel, Tok
     private final Tokenizer tokenizer;
     private final List<ChatModelListener> listeners;
 
-    @Builder
     public OpenAiStreamingChatModel(String baseUrl,
                                     String apiKey,
                                     String organizationId,
@@ -308,9 +307,33 @@ public static OpenAiStreamingChatModelBuilder builder() {
 
     public static class OpenAiStreamingChatModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Double temperature;
+        private Double topP;
+        private List<String> stop;
+        private Integer maxTokens;
+        private Integer maxCompletionTokens;
+        private Double presencePenalty;
+        private Double frequencyPenalty;
+        private Map<String, Integer> logitBias;
+        private String responseFormat;
+        private Integer seed;
+        private String user;
+        private Boolean strictTools;
+        private Boolean parallelToolCalls;
+        private Duration timeout;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Tokenizer tokenizer;
+        private Map<String, String> customHeaders;
+        private List<ChatModelListener> listeners;
+
         public OpenAiStreamingChatModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiStreamingChatModelBuilder modelName(String modelName) {
@@ -322,5 +345,178 @@ public OpenAiStreamingChatModelBuilder modelName(OpenAiChatModelName modelName)
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiStreamingChatModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder temperature(Double temperature) {
+            this.temperature = temperature;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder topP(Double topP) {
+            this.topP = topP;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder stop(List<String> stop) {
+            this.stop = stop;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder maxTokens(Integer maxTokens) {
+            this.maxTokens = maxTokens;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder maxCompletionTokens(Integer maxCompletionTokens) {
+            this.maxCompletionTokens = maxCompletionTokens;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder presencePenalty(Double presencePenalty) {
+            this.presencePenalty = presencePenalty;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder frequencyPenalty(Double frequencyPenalty) {
+            this.frequencyPenalty = frequencyPenalty;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder logitBias(Map<String, Integer> logitBias) {
+            this.logitBias = logitBias;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder responseFormat(String responseFormat) {
+            this.responseFormat = responseFormat;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder seed(Integer seed) {
+            this.seed = seed;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder user(String user) {
+            this.user = user;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder strictTools(Boolean strictTools) {
+            this.strictTools = strictTools;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder parallelToolCalls(Boolean parallelToolCalls) {
+            this.parallelToolCalls = parallelToolCalls;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder tokenizer(Tokenizer tokenizer) {
+            this.tokenizer = tokenizer;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiStreamingChatModelBuilder listeners(List<ChatModelListener> listeners) {
+            this.listeners = listeners;
+            return this;
+        }
+
+        public OpenAiStreamingChatModel build() {
+            return new OpenAiStreamingChatModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.temperature,
+                    this.topP,
+                    this.stop,
+                    this.maxTokens,
+                    this.maxCompletionTokens,
+                    this.presencePenalty,
+                    this.frequencyPenalty,
+                    this.logitBias,
+                    this.responseFormat,
+                    this.seed,
+                    this.user,
+                    this.strictTools,
+                    this.parallelToolCalls,
+                    this.timeout,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.tokenizer,
+                    this.customHeaders,
+                    this.listeners
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiStreamingChatModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("temperature=" + temperature)
+                    .add("topP=" + topP)
+                    .add("stop=" + stop)
+                    .add("maxTokens=" + maxTokens)
+                    .add("maxCompletionTokens=" + maxCompletionTokens)
+                    .add("presencePenalty=" + presencePenalty)
+                    .add("frequencyPenalty=" + frequencyPenalty)
+                    .add("logitBias=" + logitBias)
+                    .add("responseFormat='" + responseFormat + "'")
+                    .add("seed=" + seed)
+                    .add("user='" + user + "'")
+                    .add("strictTools=" + strictTools)
+                    .add("parallelToolCalls=" + parallelToolCalls)
+                    .add("timeout=" + timeout)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("tokenizer=" + tokenizer)
+                    .add("customHeaders=" + customHeaders)
+                    .add("listeners=" + listeners)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModel.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModel.java
index f84faf41927..7c88f9b4398 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModel.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModel.java
@@ -11,11 +11,11 @@
 import dev.langchain4j.model.language.TokenCountEstimator;
 import dev.langchain4j.model.openai.spi.OpenAiStreamingLanguageModelBuilderFactory;
 import dev.langchain4j.model.output.Response;
-import lombok.Builder;
 
 import java.net.Proxy;
 import java.time.Duration;
 import java.util.Map;
+import java.util.StringJoiner;
 
 import static dev.langchain4j.internal.Utils.getOrDefault;
 import static dev.langchain4j.internal.Utils.isNotNullOrEmpty;
@@ -38,7 +38,6 @@ public class OpenAiStreamingLanguageModel implements StreamingLanguageModel, Tok
     private final Double temperature;
     private final Tokenizer tokenizer;
 
-    @Builder
     public OpenAiStreamingLanguageModel(String baseUrl,
                                         String apiKey,
                                         String organizationId,
@@ -137,9 +136,20 @@ public static OpenAiStreamingLanguageModelBuilder builder() {
 
     public static class OpenAiStreamingLanguageModelBuilder {
 
+        private String baseUrl;
+        private String apiKey;
+        private String organizationId;
+        private String modelName;
+        private Double temperature;
+        private Duration timeout;
+        private Proxy proxy;
+        private Boolean logRequests;
+        private Boolean logResponses;
+        private Tokenizer tokenizer;
+        private Map<String, String> customHeaders;
+
         public OpenAiStreamingLanguageModelBuilder() {
             // This is public so it can be extended
-            // By default with Lombok it becomes package private
         }
 
         public OpenAiStreamingLanguageModelBuilder modelName(String modelName) {
@@ -151,5 +161,87 @@ public OpenAiStreamingLanguageModelBuilder modelName(OpenAiLanguageModelName mod
             this.modelName = modelName.toString();
             return this;
         }
+
+        public OpenAiStreamingLanguageModelBuilder baseUrl(String baseUrl) {
+            this.baseUrl = baseUrl;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder apiKey(String apiKey) {
+            this.apiKey = apiKey;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder organizationId(String organizationId) {
+            this.organizationId = organizationId;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder temperature(Double temperature) {
+            this.temperature = temperature;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder timeout(Duration timeout) {
+            this.timeout = timeout;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder proxy(Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder logRequests(Boolean logRequests) {
+            this.logRequests = logRequests;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder logResponses(Boolean logResponses) {
+            this.logResponses = logResponses;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder tokenizer(Tokenizer tokenizer) {
+            this.tokenizer = tokenizer;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModelBuilder customHeaders(Map<String, String> customHeaders) {
+            this.customHeaders = customHeaders;
+            return this;
+        }
+
+        public OpenAiStreamingLanguageModel build() {
+            return new OpenAiStreamingLanguageModel(
+                    this.baseUrl,
+                    this.apiKey,
+                    this.organizationId,
+                    this.modelName,
+                    this.temperature,
+                    this.timeout,
+                    this.proxy,
+                    this.logRequests,
+                    this.logResponses,
+                    this.tokenizer,
+                    this.customHeaders
+            );
+        }
+
+        @Override
+        public String toString() {
+            return new StringJoiner(", ", OpenAiStreamingLanguageModelBuilder.class.getSimpleName() + "[", "]")
+                    .add("baseUrl='" + baseUrl + "'")
+                    .add("organizationId='" + organizationId + "'")
+                    .add("modelName='" + modelName + "'")
+                    .add("temperature=" + temperature)
+                    .add("timeout=" + timeout)
+                    .add("proxy=" + proxy)
+                    .add("logRequests=" + logRequests)
+                    .add("logResponses=" + logResponses)
+                    .add("tokenizer=" + tokenizer)
+                    .add("customHeaders=" + customHeaders)
+                    .toString();
+        }
     }
 }
diff --git a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiTokenizer.java b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiTokenizer.java
index 062743477bf..dd126875545 100644
--- a/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiTokenizer.java
+++ b/langchain4j-open-ai/src/main/java/dev/langchain4j/model/openai/OpenAiTokenizer.java
@@ -49,6 +49,7 @@ public class OpenAiTokenizer implements Tokenizer {
     /**
      * Creates an instance of the {@code OpenAiTokenizer} for the "gpt-3.5-turbo" model.
      * <s>It should be suitable for all current OpenAI models, as they all use the same cl100k_base encoding.</s>
+     *
      * @deprecated Please use other constructors and specify the model name explicitly.
      */
     @Deprecated(forRemoval = true)
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelIT.java
index 05c3d55c2ce..5c1ae6364b8 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelIT.java
@@ -14,6 +14,7 @@
 import dev.langchain4j.model.output.Response;
 import dev.langchain4j.model.output.TokenUsage;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import java.util.Base64;
 import java.util.List;
@@ -30,6 +31,7 @@
 import static java.util.Collections.singletonList;
 import static org.assertj.core.api.Assertions.assertThat;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiChatModelIT {
 
     static final String CAT_IMAGE_URL = "https://upload.wikimedia.org/wikipedia/commons/e/e9/Felis_silvestris_silvestris_small_gradual_decrease_of_quality.png";
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelListenerIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelListenerIT.java
index a716797fb02..f36ab34e92d 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelListenerIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiChatModelListenerIT.java
@@ -4,10 +4,12 @@
 import dev.langchain4j.model.chat.ChatLanguageModel;
 import dev.langchain4j.model.chat.ChatModelListenerIT;
 import dev.langchain4j.model.chat.listener.ChatModelListener;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import static dev.langchain4j.model.openai.OpenAiChatModelName.GPT_4_O_MINI;
 import static java.util.Collections.singletonList;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiChatModelListenerIT extends ChatModelListenerIT {
 
     @Override
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiEmbeddingModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiEmbeddingModelIT.java
index f8aeaaa4d56..f4d2a4b5b34 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiEmbeddingModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiEmbeddingModelIT.java
@@ -6,6 +6,7 @@
 import dev.langchain4j.model.output.Response;
 import dev.langchain4j.model.output.TokenUsage;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import java.util.List;
 
@@ -13,6 +14,7 @@
 import static java.util.Arrays.asList;
 import static org.assertj.core.api.Assertions.assertThat;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiEmbeddingModelIT {
 
     EmbeddingModel model = OpenAiEmbeddingModel.builder()
@@ -100,4 +102,4 @@ void should_embed_text_with_embedding_shortening() {
 
         assertThat(response.finishReason()).isNull();
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiImageModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiImageModelIT.java
index d83793890b3..e43fc40b50a 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiImageModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiImageModelIT.java
@@ -4,6 +4,7 @@
 import dev.langchain4j.model.output.Response;
 import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -11,7 +12,9 @@
 import java.net.URI;
 import java.util.List;
 
-import static dev.ai4j.openai4j.image.ImageModel.*;
+import static dev.ai4j.openai4j.image.ImageModel.DALL_E_QUALITY_HD;
+import static dev.ai4j.openai4j.image.ImageModel.DALL_E_RESPONSE_FORMAT_B64_JSON;
+import static dev.ai4j.openai4j.image.ImageModel.DALL_E_SIZE_256_x_256;
 import static dev.langchain4j.model.openai.OpenAiImageModelName.DALL_E_2;
 import static org.assertj.core.api.Assertions.assertThat;
 
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiLanguageModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiLanguageModelIT.java
index 57458082a1f..bdd859a7c04 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiLanguageModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiLanguageModelIT.java
@@ -4,11 +4,13 @@
 import dev.langchain4j.model.output.Response;
 import dev.langchain4j.model.output.TokenUsage;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import static dev.langchain4j.model.openai.OpenAiLanguageModelName.GPT_3_5_TURBO_INSTRUCT;
 import static dev.langchain4j.model.output.FinishReason.STOP;
 import static org.assertj.core.api.Assertions.assertThat;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiLanguageModelIT {
 
     LanguageModel model = OpenAiLanguageModel.builder()
@@ -56,4 +58,4 @@ void should_use_enum_as_model_name() {
         // then
         assertThat(response).containsIgnoringCase("Berlin");
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiModerationModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiModerationModelIT.java
index 8766ff70cb9..200484ab990 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiModerationModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiModerationModelIT.java
@@ -3,10 +3,13 @@
 import dev.langchain4j.model.moderation.Moderation;
 import dev.langchain4j.model.moderation.ModerationModel;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import static dev.langchain4j.model.openai.OpenAiModerationModelName.TEXT_MODERATION_LATEST;
 import static org.assertj.core.api.Assertions.assertThat;
 
+
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiModerationModelIT {
 
     ModerationModel model = OpenAiModerationModel.builder()
@@ -46,4 +49,4 @@ void should_use_enum_as_model_name() {
         // then
         assertThat(moderation.flagged()).isFalse();
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelIT.java
index be9b20fd6ef..ac5851671d1 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelIT.java
@@ -16,6 +16,7 @@
 import dev.langchain4j.model.output.Response;
 import dev.langchain4j.model.output.TokenUsage;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 import org.junit.jupiter.params.ParameterizedTest;
 import org.junit.jupiter.params.provider.EnumSource;
 
@@ -38,6 +39,7 @@
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.jupiter.params.provider.EnumSource.Mode.EXCLUDE;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiStreamingChatModelIT {
 
     OpenAiStreamingChatModel model = OpenAiStreamingChatModel.builder()
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelListenerIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelListenerIT.java
index 5e7f669f7ca..42d4793d4af 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelListenerIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingChatModelListenerIT.java
@@ -4,10 +4,12 @@
 import dev.langchain4j.model.chat.StreamingChatLanguageModel;
 import dev.langchain4j.model.chat.StreamingChatModelListenerIT;
 import dev.langchain4j.model.chat.listener.ChatModelListener;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import static dev.langchain4j.model.openai.OpenAiChatModelName.GPT_4_O_MINI;
 import static java.util.Collections.singletonList;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiStreamingChatModelListenerIT extends StreamingChatModelListenerIT {
 
     @Override
@@ -45,4 +47,4 @@ protected StreamingChatLanguageModel createFailingModel(ChatModelListener listen
     protected Class<? extends Exception> expectedExceptionClass() {
         return OpenAiHttpException.class;
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModelIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModelIT.java
index c068cabec83..41f1c92cd85 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModelIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiStreamingLanguageModelIT.java
@@ -6,6 +6,7 @@
 import dev.langchain4j.model.output.Response;
 import dev.langchain4j.model.output.TokenUsage;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;
 
 import java.util.concurrent.CompletableFuture;
 
@@ -14,6 +15,7 @@
 import static java.util.concurrent.TimeUnit.SECONDS;
 import static org.assertj.core.api.Assertions.assertThat;
 
+@EnabledIfEnvironmentVariable(named = "OPENAI_API_KEY", matches = ".+")
 class OpenAiStreamingLanguageModelIT {
 
     StreamingLanguageModel model = OpenAiStreamingLanguageModel.builder()
@@ -90,4 +92,4 @@ void should_use_enum_as_model_name() {
         // then
         assertThat(response.content()).containsIgnoringCase("Berlin");
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerIT.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerIT.java
index 38fddc0c351..80a7507c1bd 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerIT.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerIT.java
@@ -19,8 +19,21 @@
 import java.util.Set;
 import java.util.stream.Stream;
 
-import static dev.ai4j.openai4j.chat.ChatCompletionModel.*;
-import static dev.langchain4j.agent.tool.JsonSchemaProperty.*;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_3_5_TURBO;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_3_5_TURBO_0125;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_3_5_TURBO_1106;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_0125_PREVIEW;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_1106_PREVIEW;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_32K;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_32K_0314;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_32K_0613;
+import static dev.ai4j.openai4j.chat.ChatCompletionModel.GPT_4_TURBO_PREVIEW;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.ARRAY;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.INTEGER;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.STRING;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.description;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.enums;
+import static dev.langchain4j.agent.tool.JsonSchemaProperty.items;
 import static dev.langchain4j.data.message.AiMessage.aiMessage;
 import static dev.langchain4j.data.message.SystemMessage.systemMessage;
 import static dev.langchain4j.data.message.ToolExecutionResultMessage.toolExecutionResultMessage;
@@ -1753,4 +1766,4 @@ static Stream<Arguments> should_count_tokens_in_multiple_tool_execution_requests
                         )
                 ));
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerTest.java b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerTest.java
index c3edc418d7c..86664bda4f6 100644
--- a/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerTest.java
+++ b/langchain4j-open-ai/src/test/java/dev/langchain4j/model/openai/OpenAiTokenizerTest.java
@@ -46,7 +46,7 @@ void should_count_tokens_in_short_texts() {
         assertThat(tokenizer.estimateTokenCountInText("Hello!")).isEqualTo(2);
         assertThat(tokenizer.estimateTokenCountInText("Hello, how are you?")).isEqualTo(6);
 
-        assertThat(tokenizer.estimateTokenCountInText("")).isEqualTo(0);
+        assertThat(tokenizer.estimateTokenCountInText("")).isZero();
         assertThat(tokenizer.estimateTokenCountInText("\n")).isEqualTo(1);
         assertThat(tokenizer.estimateTokenCountInText("\n\n")).isEqualTo(1);
         assertThat(tokenizer.estimateTokenCountInText("\n \n\n")).isEqualTo(2);
@@ -78,11 +78,11 @@ void should_count_tokens_in_large_text() {
 
     @Test
     void should_count_arguments() {
-        assertThat(countArguments(null)).isEqualTo(0);
-        assertThat(countArguments("")).isEqualTo(0);
-        assertThat(countArguments(" ")).isEqualTo(0);
-        assertThat(countArguments("{}")).isEqualTo(0);
-        assertThat(countArguments("{ }")).isEqualTo(0);
+        assertThat(countArguments(null)).isZero();
+        assertThat(countArguments("")).isZero();
+        assertThat(countArguments(" ")).isZero();
+        assertThat(countArguments("{}")).isZero();
+        assertThat(countArguments("{ }")).isZero();
 
         assertThat(countArguments("{\"one\":1}")).isEqualTo(1);
         assertThat(countArguments("{\"one\": 1}")).isEqualTo(1);
@@ -188,4 +188,4 @@ static List<String> repeat(String strings, int n) {
         }
         return result;
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/main/java/dev/langchain4j/classification/EmbeddingModelTextClassifier.java b/langchain4j/src/main/java/dev/langchain4j/classification/EmbeddingModelTextClassifier.java
index 68f9de3b544..817c5189dea 100644
--- a/langchain4j/src/main/java/dev/langchain4j/classification/EmbeddingModelTextClassifier.java
+++ b/langchain4j/src/main/java/dev/langchain4j/classification/EmbeddingModelTextClassifier.java
@@ -98,11 +98,11 @@ public EmbeddingModelTextClassifier(EmbeddingModel embeddingModel,
 
         this.exampleEmbeddingsByLabel = new HashMap<>();
         examplesByLabel.forEach((label, examples) ->
-            exampleEmbeddingsByLabel.put(label, embeddingModel.embedAll(
-                examples.stream()
-                    .map(TextSegment::from)
-                    .collect(toList())).content()
-            )
+                exampleEmbeddingsByLabel.put(label, embeddingModel.embedAll(
+                        examples.stream()
+                                .map(TextSegment::from)
+                                .collect(toList())).content()
+                )
         );
 
         this.maxResults = ensureGreaterThanZero(maxResults, "maxResults");
@@ -135,11 +135,11 @@ public ClassificationResult<L> classifyWithScores(String text) {
         });
 
         return new ClassificationResult<>(
-            scoredLabels.stream()
-                // sorting in descending order to return highest score first
-                .sorted(comparingDouble(classificationResult -> 1 - classificationResult.score()))
-                .limit(maxResults)
-                .collect(toList())
+                scoredLabels.stream()
+                        // sorting in descending order to return highest score first
+                        .sorted(comparingDouble(classificationResult -> 1 - classificationResult.score()))
+                        .limit(maxResults)
+                        .collect(toList())
         );
     }
 
diff --git a/langchain4j/src/main/java/dev/langchain4j/classification/TextClassifier.java b/langchain4j/src/main/java/dev/langchain4j/classification/TextClassifier.java
index d781ac33292..b87f4c1ddb3 100644
--- a/langchain4j/src/main/java/dev/langchain4j/classification/TextClassifier.java
+++ b/langchain4j/src/main/java/dev/langchain4j/classification/TextClassifier.java
@@ -23,8 +23,8 @@ public interface TextClassifier<L> {
      */
     default List<L> classify(String text) {
         return classifyWithScores(text).scoredLabels().stream()
-            .map(ScoredLabel::label)
-            .collect(toList());
+                .map(ScoredLabel::label)
+                .collect(toList());
     }
 
     /**
diff --git a/langchain4j/src/main/java/dev/langchain4j/data/document/loader/UrlDocumentLoader.java b/langchain4j/src/main/java/dev/langchain4j/data/document/loader/UrlDocumentLoader.java
index 0e82285c497..9942157b07e 100644
--- a/langchain4j/src/main/java/dev/langchain4j/data/document/loader/UrlDocumentLoader.java
+++ b/langchain4j/src/main/java/dev/langchain4j/data/document/loader/UrlDocumentLoader.java
@@ -35,6 +35,7 @@ public static Document load(String url, DocumentParser documentParser) {
 
     /**
      * Creates a URL from the specified string.
+     *
      * @param url The URL string.
      * @return the URL
      * @throws IllegalArgumentException If specified URL is malformed.
diff --git a/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitter.java b/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitter.java
index 1f70fa8ef85..f55ae50f3f7 100644
--- a/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitter.java
+++ b/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitter.java
@@ -42,6 +42,7 @@ private HierarchicalDocumentSplitter getOverlapSentenceSplitter() {
 
     /**
      * Creates a new instance of {@link HierarchicalDocumentSplitter}.
+     *
      * @param maxSegmentSizeInChars The maximum size of a segment in characters.
      * @param maxOverlapSizeInChars The maximum size of the overlap between segments in characters.
      */
@@ -51,9 +52,10 @@ protected HierarchicalDocumentSplitter(int maxSegmentSizeInChars, int maxOverlap
 
     /**
      * Creates a new instance of {@link HierarchicalDocumentSplitter}.
+     *
      * @param maxSegmentSizeInChars The maximum size of a segment in characters.
      * @param maxOverlapSizeInChars The maximum size of the overlap between segments in characters.
-     * @param subSplitter The sub-splitter to use when a single segment is too long.
+     * @param subSplitter           The sub-splitter to use when a single segment is too long.
      */
     protected HierarchicalDocumentSplitter(int maxSegmentSizeInChars,
                                            int maxOverlapSizeInChars,
@@ -63,9 +65,10 @@ protected HierarchicalDocumentSplitter(int maxSegmentSizeInChars,
 
     /**
      * Creates a new instance of {@link HierarchicalDocumentSplitter}.
+     *
      * @param maxSegmentSizeInTokens The maximum size of a segment in tokens.
      * @param maxOverlapSizeInTokens The maximum size of the overlap between segments in tokens.
-     * @param tokenizer The tokenizer to use to estimate the number of tokens in a text.
+     * @param tokenizer              The tokenizer to use to estimate the number of tokens in a text.
      */
     protected HierarchicalDocumentSplitter(int maxSegmentSizeInTokens,
                                            int maxOverlapSizeInTokens,
@@ -75,10 +78,11 @@ protected HierarchicalDocumentSplitter(int maxSegmentSizeInTokens,
 
     /**
      * Creates a new instance of {@link HierarchicalDocumentSplitter}.
+     *
      * @param maxSegmentSizeInTokens The maximum size of a segment in tokens.
      * @param maxOverlapSizeInTokens The maximum size of the overlap between segments in tokens.
-     * @param tokenizer The tokenizer to use to estimate the number of tokens in a text.
-     * @param subSplitter The sub-splitter to use when a single segment is too long.
+     * @param tokenizer              The tokenizer to use to estimate the number of tokens in a text.
+     * @param subSplitter            The sub-splitter to use when a single segment is too long.
      */
     protected HierarchicalDocumentSplitter(int maxSegmentSizeInTokens,
                                            int maxOverlapSizeInTokens,
@@ -93,6 +97,7 @@ protected HierarchicalDocumentSplitter(int maxSegmentSizeInTokens,
     /**
      * Splits the provided text into parts.
      * Implementation API.
+     *
      * @param text The text to be split.
      * @return An array of parts.
      */
@@ -100,12 +105,14 @@ protected HierarchicalDocumentSplitter(int maxSegmentSizeInTokens,
 
     /**
      * Delimiter string to use to re-join the parts.
+     *
      * @return The delimiter.
      */
     protected abstract String joinDelimiter();
 
     /**
      * The default sub-splitter to use when a single segment is too long.
+     *
      * @return The default sub-splitter.
      */
     protected abstract DocumentSplitter defaultSubSplitter();
@@ -182,6 +189,7 @@ public List<TextSegment> split(Document document) {
 
     /**
      * Returns the overlap region at the end of the provided segment text.
+     *
      * @param segmentText The segment text.
      * @return The overlap region, or an empty string if there is no overlap.
      */
@@ -228,9 +236,9 @@ int estimateSize(String text) {
      * <p>The segment inherits all metadata from the document. The segment also includes
      * an "index" metadata key representing the segment position within the document.
      *
-     * @param text The text of the segment.
+     * @param text     The text of the segment.
      * @param document The document to which the segment belongs.
-     * @param index The index of the segment within the document.
+     * @param index    The index of the segment within the document.
      */
     static TextSegment createSegment(String text, Document document, int index) {
         Metadata metadata = document.metadata().copy().put(INDEX, String.valueOf(index));
diff --git a/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java b/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java
index e8deadebf88..74468b4372b 100644
--- a/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java
+++ b/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java
@@ -18,9 +18,10 @@ class SegmentBuilder {
 
     /**
      * Creates a new instance of {@link SegmentBuilder}.
+     *
      * @param maxSegmentSize The maximum size of a segment.
-     * @param sizeFunction The function to use to estimate the size of a text.
-     * @param joinSeparator The separator to use when joining multiple texts into a single segment.
+     * @param sizeFunction   The function to use to estimate the size of a text.
+     * @param joinSeparator  The separator to use when joining multiple texts into a single segment.
      */
     public SegmentBuilder(int maxSegmentSize, Function<String, Integer> sizeFunction, String joinSeparator) {
         this.maxSegmentSize = ensureGreaterThanZero(maxSegmentSize, "maxSegmentSize");
@@ -31,6 +32,7 @@ public SegmentBuilder(int maxSegmentSize, Function<String, Integer> sizeFunction
 
     /**
      * Returns the current size of the segment (as returned by the {@code sizeFunction}).
+     *
      * @return The current size of the segment.
      */
     public int getSize() {
@@ -39,6 +41,7 @@ public int getSize() {
 
     /**
      * Returns {@code true} if the provided text can be added to the current segment.
+     *
      * @param text The text to check.
      * @return {@code true} if the provided text can be added to the current segment.
      */
@@ -52,6 +55,7 @@ public boolean hasSpaceFor(String text) {
 
     /**
      * Returns {@code true} if the provided size can be added to the current segment.
+     *
      * @param size The size to check.
      * @return {@code true} if the provided size can be added to the current segment.
      */
@@ -65,6 +69,7 @@ public boolean hasSpaceFor(int size) {
 
     /**
      * Returns the size of the provided text (as returned by the {@code sizeFunction}).
+     *
      * @param text The text to check.
      * @return The size of the provided text.
      */
@@ -74,6 +79,7 @@ public int sizeOf(String text) {
 
     /**
      * Appends the provided text to the current segment.
+     *
      * @param text The text to append.
      */
     public void append(String text) {
@@ -86,6 +92,7 @@ public void append(String text) {
 
     /**
      * Prepends the provided text to the current segment.
+     *
      * @param text The text to prepend.
      */
     public void prepend(String text) {
@@ -99,6 +106,7 @@ public void prepend(String text) {
 
     /**
      * Returns {@code true} if the current segment is not empty.
+     *
      * @return {@code true} if the current segment is not empty.
      */
     public boolean isNotEmpty() {
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java b/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java
index e83bbd1ce82..9b5c79bcd23 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java
@@ -398,15 +398,14 @@ public AiServices<T> tools(Map<ToolSpecification, ToolExecutor> tools) {
     }
 
     /**
+     * @param retriever The retriever to be used by the AI Service.
+     * @return builder
      * @deprecated Use {@link #contentRetriever(ContentRetriever)}
      * (e.g. {@link EmbeddingStoreContentRetriever}) instead.
      * <br>
      * Configures a retriever that will be invoked on every method call to fetch relevant information
      * related to the current user message from an underlying source (e.g., embedding store).
      * This relevant information is automatically injected into the message sent to the LLM.
-     *
-     * @param retriever The retriever to be used by the AI Service.
-     * @return builder
      */
     @Deprecated(forRemoval = true)
     public AiServices<T> retriever(Retriever<TextSegment> retriever) {
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/Result.java b/langchain4j/src/main/java/dev/langchain4j/service/Result.java
index a0efd53dd0f..6407a3ed8c1 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/Result.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/Result.java
@@ -4,7 +4,6 @@
 import dev.langchain4j.model.output.TokenUsage;
 import dev.langchain4j.rag.content.Content;
 import dev.langchain4j.service.tool.ToolExecution;
-
 import java.util.List;
 
 import static dev.langchain4j.internal.Utils.copyIfNotNull;
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/TypeUtils.java b/langchain4j/src/main/java/dev/langchain4j/service/TypeUtils.java
index 9cc66b3e235..d12e976d461 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/TypeUtils.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/TypeUtils.java
@@ -57,11 +57,10 @@ private static Type[] getTypeArguments(Type returnType) {
             throw new IllegalArgumentException("returnType parameter cannot be null.");
         }
 
-        if (!(returnType instanceof ParameterizedType)) {
+        if (!(returnType instanceof ParameterizedType type)) {
             return new Type[0];
         }
 
-        ParameterizedType type = (ParameterizedType) returnType;
         Type[] typeArguments = type.getActualTypeArguments();
 
         if (typeArguments.length == 0) {
@@ -94,16 +93,15 @@ private static Type[] getTypeArguments(Type returnType) {
      * </ul>*
      *
      * @param methodName the method name
-     * @param type the return type
+     * @param type       the return type
      */
     public static void validateReturnTypesAreProperlyParametrized(String methodName, Type type) {
         TypeUtils.validateReturnTypesAreProperlyParametrized(methodName, type, new ArrayList<>());
     }
 
     private static void validateReturnTypesAreProperlyParametrized(String methodName, Type type, List<Type> typeChain) {
-        if (type instanceof ParameterizedType) {
+        if (type instanceof ParameterizedType parameterizedType) {
             // Recursively check all parametrized types
-            ParameterizedType parameterizedType = (ParameterizedType) type;
             for (Type actualTypeArgument : parameterizedType.getActualTypeArguments()) {
                 typeChain.add(parameterizedType);
                 validateReturnTypesAreProperlyParametrized(methodName, actualTypeArgument, typeChain);
@@ -116,16 +114,14 @@ private static void validateReturnTypesAreProperlyParametrized(String methodName
             // Type variable: Result<T> ask(String question)
             typeChain.add(type);
             throw genericNotProperlySpecifiedException(methodName, typeChain);
-        } else if (type instanceof Class<?>) {
-            Class<?> clazz = (Class<?>) type;
-            if (clazz.getTypeParameters().length > 0) {
-                //  Raw type:  Result ask(String question)
-                typeChain.add(type);
-                throw genericNotProperlySpecifiedException(methodName, typeChain);
-            }
+        } else if (type instanceof Class<?> clazz && clazz.getTypeParameters().length > 0) {
+            //  Raw type:  Result ask(String question)
+            typeChain.add(type);
+            throw genericNotProperlySpecifiedException(methodName, typeChain);
         }
     }
 
+
     private static IllegalArgumentException genericNotProperlySpecifiedException(String methodName, List<Type> typeChain) {
 
         String actualDeclaration = getActualDeclaration(typeChain);
@@ -146,9 +142,7 @@ private static String getActualDeclaration(List<Type> typeChain) {
                 return TypeUtils.getRawClass(type).getSimpleName();
             }
         }).collect(Collectors.joining("<")));
-        for (int i = 0; i < typeChain.size() - 1; i++) {
-            actualDeclaration.append(">");
-        }
+        actualDeclaration.append(">".repeat(Math.max(0, typeChain.size() - 1)));
         return actualDeclaration.toString();
     }
 
@@ -156,9 +150,7 @@ private static String getExemplarDeclaration(List<Type> typeChain, String forTyp
         List<Type> rawTypesOnly = typeChain.stream().filter(type -> !(type instanceof WildcardType || type instanceof TypeVariable)).collect(toList());
         StringBuilder declarationExample = new StringBuilder(rawTypesOnly.stream().map(type -> TypeUtils.getRawClass(type).getSimpleName()).collect(Collectors.joining("<")));
         declarationExample.append("<").append(forType);
-        for (int i = 0; i < rawTypesOnly.size(); i++) {
-            declarationExample.append(">");
-        }
+        declarationExample.append(">".repeat(rawTypesOnly.size()));
         return declarationExample.toString();
     }
 
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/output/JsonSchemas.java b/langchain4j/src/main/java/dev/langchain4j/service/output/JsonSchemas.java
index 6f0242e01f8..314d59ee027 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/output/JsonSchemas.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/output/JsonSchemas.java
@@ -63,10 +63,6 @@ private static boolean isPojo(Type returnType) {
         Class<?> typeArgumentClass = TypeUtils.resolveFirstGenericParameterClass(returnType);
 
         Optional<OutputParser<?>> outputParser = new DefaultOutputParserFactory().get(rawClass, typeArgumentClass);
-        if (outputParser.isPresent()) {
-            return false;
-        }
-
-        return true;
+        return outputParser.isEmpty();
     }
 }
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/output/OutputParser.java b/langchain4j/src/main/java/dev/langchain4j/service/output/OutputParser.java
index 9a3d2cfc078..bc8780a32d5 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/output/OutputParser.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/output/OutputParser.java
@@ -2,12 +2,14 @@
 
 /**
  * Represents an output parser.
+ *
  * @param <T> the type of the output.
  */
 interface OutputParser<T> {
 
     /**
      * Parse the given text.
+     *
      * @param text the text to parse.
      * @return the parsed output.
      */
@@ -15,6 +17,7 @@ interface OutputParser<T> {
 
     /**
      * Description of the text format.
+     *
      * @return the description of the text format.
      */
     String formatInstructions();
diff --git a/langchain4j/src/main/java/dev/langchain4j/service/output/ServiceOutputParser.java b/langchain4j/src/main/java/dev/langchain4j/service/output/ServiceOutputParser.java
index 7c1658f7eb1..fe8ce39f069 100644
--- a/langchain4j/src/main/java/dev/langchain4j/service/output/ServiceOutputParser.java
+++ b/langchain4j/src/main/java/dev/langchain4j/service/output/ServiceOutputParser.java
@@ -170,8 +170,7 @@ private static String descriptionFor(Field field, Set<Class<?>> visited) {
     private static String typeOf(Field field, Set<Class<?>> visited) {
         Type type = field.getGenericType();
 
-        if (type instanceof ParameterizedType) {
-            ParameterizedType parameterizedType = (ParameterizedType) type;
+        if (type instanceof ParameterizedType parameterizedType) {
             Type[] typeArguments = parameterizedType.getActualTypeArguments();
 
             if (parameterizedType.getRawType().equals(List.class)
diff --git a/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalChainTest.java b/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalChainTest.java
index be4136cae25..e11d2af4f7e 100644
--- a/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalChainTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalChainTest.java
@@ -13,7 +13,11 @@
 
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
-import static org.mockito.Mockito.*;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.spy;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.verifyNoMoreInteractions;
 
 class ConversationalChainTest {
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalRetrievalChainTest.java b/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalRetrievalChainTest.java
index 395e7263cb4..35d02c63819 100644
--- a/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalRetrievalChainTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/chain/ConversationalRetrievalChainTest.java
@@ -9,9 +9,9 @@
 import dev.langchain4j.model.chat.ChatLanguageModel;
 import dev.langchain4j.model.input.PromptTemplate;
 import dev.langchain4j.model.output.Response;
-import dev.langchain4j.rag.content.injector.DefaultContentInjector;
 import dev.langchain4j.rag.DefaultRetrievalAugmentor;
 import dev.langchain4j.rag.content.Content;
+import dev.langchain4j.rag.content.injector.DefaultContentInjector;
 import dev.langchain4j.rag.content.retriever.ContentRetriever;
 import dev.langchain4j.retriever.Retriever;
 import org.junit.jupiter.api.BeforeEach;
@@ -28,7 +28,10 @@
 import static dev.langchain4j.data.message.AiMessage.aiMessage;
 import static java.util.Arrays.asList;
 import static org.assertj.core.api.Assertions.assertThat;
-import static org.mockito.Mockito.*;
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.anyList;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.when;
 
 @ExtendWith(MockitoExtension.class)
 class ConversationalRetrievalChainTest {
diff --git a/langchain4j/src/test/java/dev/langchain4j/classification/TextClassifierTest.java b/langchain4j/src/test/java/dev/langchain4j/classification/TextClassifierTest.java
index 00336c3eab5..fbe04439300 100644
--- a/langchain4j/src/test/java/dev/langchain4j/classification/TextClassifierTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/classification/TextClassifierTest.java
@@ -40,7 +40,7 @@ void test_classify() {
         assertThat(classifier.classify("cat fish")).containsOnly(Categories.CAT, Categories.FISH);
 
         assertThat(classifier.classify(TextSegment.from("dog fish")))
-            .containsOnly(Categories.DOG, Categories.FISH);
+                .containsOnly(Categories.DOG, Categories.FISH);
 
         assertThat(classifier.classify(Document.from("dog cat"))).containsOnly(Categories.CAT, Categories.DOG);
     }
@@ -51,26 +51,26 @@ void test_classify_with_scores() {
 
         ClassificationResult<Categories> results = classifier.classifyWithScores("cat fish");
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::label)
-            .collect(Collectors.toList())).containsOnly(Categories.CAT, Categories.FISH);
+                .map(ScoredLabel::label)
+                .collect(Collectors.toList())).containsOnly(Categories.CAT, Categories.FISH);
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::score)
-            .collect(Collectors.toList())).allMatch(score -> score == 1.0);
+                .map(ScoredLabel::score)
+                .collect(Collectors.toList())).allMatch(score -> score == 1.0);
 
         results = classifier.classifyWithScores(TextSegment.from("cat fish"));
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::label)
-            .collect(Collectors.toList())).containsOnly(Categories.CAT, Categories.FISH);
+                .map(ScoredLabel::label)
+                .collect(Collectors.toList())).containsOnly(Categories.CAT, Categories.FISH);
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::score)
-            .collect(Collectors.toList())).allMatch(score -> score == 1.0);
+                .map(ScoredLabel::score)
+                .collect(Collectors.toList())).allMatch(score -> score == 1.0);
 
         results = classifier.classifyWithScores(Document.from("dog cat"));
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::label)
-            .collect(Collectors.toList())).containsOnly(Categories.DOG, Categories.CAT);
+                .map(ScoredLabel::label)
+                .collect(Collectors.toList())).containsOnly(Categories.DOG, Categories.CAT);
         assertThat(results.scoredLabels().stream()
-            .map(ScoredLabel::score)
-            .collect(Collectors.toList())).allMatch(score -> score == 1.0);
+                .map(ScoredLabel::score)
+                .collect(Collectors.toList())).allMatch(score -> score == 1.0);
     }
 }
diff --git a/langchain4j/src/test/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoaderTest.java b/langchain4j/src/test/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoaderTest.java
index 3c83874858c..39fee2a50d8 100644
--- a/langchain4j/src/test/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoaderTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoaderTest.java
@@ -11,10 +11,16 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URISyntaxException;
-import java.nio.file.*;
+import java.nio.file.FileSystems;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.PathMatcher;
+import java.nio.file.Paths;
 import java.util.List;
 
-import static dev.langchain4j.data.document.loader.FileSystemDocumentLoader.*;
+import static dev.langchain4j.data.document.loader.FileSystemDocumentLoader.loadDocument;
+import static dev.langchain4j.data.document.loader.FileSystemDocumentLoader.loadDocuments;
+import static dev.langchain4j.data.document.loader.FileSystemDocumentLoader.loadDocumentsRecursively;
 import static java.util.stream.Collectors.toList;
 
 class FileSystemDocumentLoaderTest implements WithAssertions {
@@ -78,7 +84,7 @@ void should_load_documents_including_unknown_document_types() {
         // then
         List<String> fileNames = documents.stream()
                 .map(document -> document.metadata("file_name"))
-                .collect(toList());
+                .toList();
         assertThat(fileNames).containsExactlyInAnyOrder(
                 "miles-of-smiles-terms-of-use.txt",
                 "test-file.banana",
@@ -139,7 +145,7 @@ void should_load_matching_documents(String syntaxAndPattern) {
         // then
         List<String> fileNames = documents.stream()
                 .map(document -> document.metadata("file_name"))
-                .collect(toList());
+                .toList();
         assertThat(fileNames).containsExactlyInAnyOrder("test-file.banana");
 
         // when-then
@@ -162,7 +168,7 @@ void should_recursively_load_documents() {
         // then
         List<String> fileNames = documents.stream()
                 .map(document -> document.metadata("file_name"))
-                .collect(toList());
+                .toList();
         assertThat(fileNames).containsExactlyInAnyOrder(
                 "miles-of-smiles-terms-of-use.txt",
                 "test-file.banana",
@@ -196,7 +202,7 @@ void should_recursively_load_matching_documents() {
         // then
         List<String> fileNames = documents.stream()
                 .map(document -> document.metadata("file_name"))
-                .collect(toList());
+                .toList();
         assertThat(fileNames).containsExactlyInAnyOrder("test-file.banana");
 
         // when-then
@@ -244,7 +250,7 @@ void should_recursively_load_matching_documents_with_glob_specifying_concrete_di
         // then
         List<String> fileNames = documents.stream()
                 .map(document -> document.metadata("file_name"))
-                .collect(toList());
+                .toList();
         assertThat(fileNames).containsExactlyInAnyOrder("test-file-2.banana");
 
         // when-then
@@ -271,4 +277,4 @@ private Path toPath(String fileName) {
             throw new RuntimeException(e);
         }
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/data/document/loader/UrlDocumentLoaderTest.java b/langchain4j/src/test/java/dev/langchain4j/data/document/loader/UrlDocumentLoaderTest.java
index 7265109a9da..8c06632b29a 100644
--- a/langchain4j/src/test/java/dev/langchain4j/data/document/loader/UrlDocumentLoaderTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/data/document/loader/UrlDocumentLoaderTest.java
@@ -11,8 +11,8 @@ void test_bad_url() {
         String url = "bad_url";
 
         assertThatExceptionOfType(IllegalArgumentException.class)
-            .isThrownBy(() -> UrlDocumentLoader.load(url, new TextDocumentParser()))
-            .withMessageContaining("no protocol");
+                .isThrownBy(() -> UrlDocumentLoader.load(url, new TextDocumentParser()))
+                .withMessageContaining("no protocol");
     }
 
     @Test
@@ -24,4 +24,4 @@ void should_load_text_document() {
         assertThat(document.text()).isEqualTo("test\ncontent");
         assertThat(document.metadata("url")).isEqualTo(url);
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/data/document/parser/TextDocumentParserTest.java b/langchain4j/src/test/java/dev/langchain4j/data/document/parser/TextDocumentParserTest.java
index 26faa82794e..9a5503302d6 100644
--- a/langchain4j/src/test/java/dev/langchain4j/data/document/parser/TextDocumentParserTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/data/document/parser/TextDocumentParserTest.java
@@ -1,7 +1,7 @@
 package dev.langchain4j.data.document.parser;
 
-import dev.langchain4j.data.document.Document;
 import dev.langchain4j.data.document.BlankDocumentException;
+import dev.langchain4j.data.document.Document;
 import dev.langchain4j.data.document.DocumentParser;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.params.ParameterizedTest;
@@ -11,7 +11,9 @@
 import java.io.InputStream;
 
 import static java.nio.charset.StandardCharsets.ISO_8859_1;
-import static org.assertj.core.api.Assertions.*;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
 class TextDocumentParserTest {
 
@@ -67,4 +69,4 @@ public int read() throws IOException {
                 .withCauseInstanceOf(IOException.class)
                 .withMessageContaining("test exception");
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitterTest.java b/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitterTest.java
index 31a8c579da5..873362d22d1 100644
--- a/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitterTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/HierarchicalDocumentSplitterTest.java
@@ -41,7 +41,7 @@ protected DocumentSplitter defaultSubSplitter() {
     }
 
     @Test
-    public void test_constructor() {
+    void test_constructor() {
         {
             ExampleImpl splitter = new ExampleImpl(1, 1);
             assertThat(splitter.maxSegmentSize).isEqualTo(1);
@@ -83,4 +83,4 @@ public void test_constructor() {
             assertThat(splitter.estimateSize("abc def")).isEqualTo(2);
         }
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/SegmentBuilderTest.java b/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/SegmentBuilderTest.java
index 89772531d63..3762fa879ad 100644
--- a/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/SegmentBuilderTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/data/document/splitter/SegmentBuilderTest.java
@@ -15,7 +15,7 @@ void shouldAppendText() {
     }
 
     @Test
-    public void test_by_words() {
+    void test_by_words() {
         SegmentBuilder builder = new SegmentBuilder(10,
                 text -> text.split(" ").length,
                 " ; ");
diff --git a/langchain4j/src/test/java/dev/langchain4j/exception/IllegalConfigurationExceptionTest.java b/langchain4j/src/test/java/dev/langchain4j/exception/IllegalConfigurationExceptionTest.java
index 7961c78e6e3..52d6186cfce 100644
--- a/langchain4j/src/test/java/dev/langchain4j/exception/IllegalConfigurationExceptionTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/exception/IllegalConfigurationExceptionTest.java
@@ -5,10 +5,10 @@
 
 class IllegalConfigurationExceptionTest implements WithAssertions {
     @Test
-    public void test_constructors() {
+    void test_constructors() {
         assertThat(new IllegalConfigurationException("message abc 123"))
                 .isInstanceOf(IllegalConfigurationException.class)
-                        .hasMessage("message abc 123");
+                .hasMessage("message abc 123");
 
         assertThat(IllegalConfigurationException.illegalConfiguration("message abc 123"))
                 .isInstanceOf(IllegalConfigurationException.class)
@@ -18,4 +18,4 @@ public void test_constructors() {
                 .isInstanceOf(IllegalConfigurationException.class)
                 .hasMessage("message abc 123");
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesIT.java b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesIT.java
index 3a5e8dfa7a2..7f0469bface 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesIT.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesIT.java
@@ -861,8 +861,8 @@ void should_return_result() {
 
         TokenUsage tokenUsage = result.tokenUsage();
         assertThat(tokenUsage).isNotNull();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsIT.java b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsIT.java
index 15c6084e4e3..e8e21279854 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsIT.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsIT.java
@@ -160,8 +160,8 @@ void should_execute_a_tool_then_answer(ChatLanguageModel chatLanguageModel) {
         assertThat(response.content().text()).contains("11.1");
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -229,8 +229,8 @@ void should_execute_multiple_tools_sequentially_then_answer(ChatLanguageModel ch
         assertThat(response.content().text()).contains("11.1", "22.2");
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -317,8 +317,8 @@ void should_execute_multiple_tools_in_parallel_then_answer(ChatLanguageModel cha
         assertThat(response.content().text()).contains("11.1", "22.2");
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsWithoutMemoryIT.java b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsWithoutMemoryIT.java
index 7d5cd84636f..49e5eb67202 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsWithoutMemoryIT.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/AiServicesWithToolsWithoutMemoryIT.java
@@ -67,8 +67,8 @@ void should_execute_a_tool_then_answer() {
         assertThat(response.content().text()).contains("6.97");
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -137,8 +137,8 @@ void should_execute_multiple_tools_in_parallel_then_answer() {
         assertThat(response.content().text()).contains("6.97", "9.89");
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesIT.java b/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesIT.java
index 933d370e75d..99df62e6b7e 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesIT.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesIT.java
@@ -84,8 +84,8 @@ void should_stream_answer(StreamingChatLanguageModel model) throws Exception {
         assertThat(response.content().text()).isEqualTo(answer);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -227,8 +227,8 @@ void should_execute_a_tool_then_stream_answer(StreamingChatLanguageModel model)
         assertThat(response.content().text()).isEqualTo(answer);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -311,8 +311,8 @@ void should_execute_multiple_tools_sequentially_then_answer() throws Exception {
         assertThat(response.content().text()).isEqualTo(answer);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0); // TODO
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive(); // TODO
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -407,8 +407,8 @@ void should_execute_multiple_tools_in_parallel_then_answer() throws Exception {
         assertThat(response.content().text()).isEqualTo(answer);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0); // TODO
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive(); // TODO
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesWithToolsWithoutMemoryIT.java b/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesWithToolsWithoutMemoryIT.java
index 3434c85235a..e8372ed3c78 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesWithToolsWithoutMemoryIT.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/StreamingAiServicesWithToolsWithoutMemoryIT.java
@@ -88,8 +88,8 @@ void should_execute_a_tool_then_answer() throws Exception {
         assertThat(response.finishReason()).isEqualTo(STOP);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -156,8 +156,8 @@ void should_execute_multiple_tools_sequentially_then_answer() throws Exception {
         assertThat(response.finishReason()).isEqualTo(STOP);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
@@ -220,8 +220,8 @@ void should_execute_multiple_tools_in_parallel_then_answer() throws Exception {
         assertThat(response.finishReason()).isEqualTo(STOP);
 
         TokenUsage tokenUsage = response.tokenUsage();
-        assertThat(tokenUsage.inputTokenCount()).isGreaterThan(0);
-        assertThat(tokenUsage.outputTokenCount()).isGreaterThan(0);
+        assertThat(tokenUsage.inputTokenCount()).isPositive();
+        assertThat(tokenUsage.outputTokenCount()).isPositive();
         assertThat(tokenUsage.totalTokenCount())
                 .isEqualTo(tokenUsage.inputTokenCount() + tokenUsage.outputTokenCount());
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/TypeUtilsTest.java b/langchain4j/src/test/java/dev/langchain4j/service/TypeUtilsTest.java
index d044971cebe..257abdbc4d0 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/TypeUtilsTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/TypeUtilsTest.java
@@ -2,7 +2,7 @@
 
 import com.google.gson.reflect.TypeToken;
 import dev.langchain4j.model.chat.ChatLanguageModel;
-import dev.langchain4j.model.chat.mock.ChatModelMock;
+import dev.langchain4j.model.chat.mock.ChatModelMock;
 import org.junit.jupiter.api.Test;
 
 import java.lang.reflect.Type;
@@ -10,8 +10,8 @@
 import java.util.Set;
 
 import static org.assertj.core.api.Assertions.assertThat;
-import static org.junit.jupiter.api.Assertions.assertThrows;
-
+import static org.junit.jupiter.api.Assertions.assertThrows;
+
 class TypeUtilsTest {
 
     /**********************************************************************************************
@@ -22,9 +22,10 @@ class TypeUtilsTest {
      **********************************************************************************************/
 
     @Test
-    public void testIntegerReturnType() {
+    void testIntegerReturnType() {
         // Given Integer
-        Type returnType = new TypeToken<Integer>() {}.getType();
+        Type returnType = new TypeToken<Integer>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(Integer.class);
@@ -33,9 +34,10 @@ public void testIntegerReturnType() {
     }
 
     @Test
-    public void testStringReturnType() {
+    void testStringReturnType() {
         // Given String
-        Type returnType = new TypeToken<String>() {}.getType();
+        Type returnType = new TypeToken<String>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(String.class);
@@ -44,9 +46,10 @@ public void testStringReturnType() {
     }
 
     @Test
-    public void testResultStringReturnType() {
+    void testResultStringReturnType() {
         // Given Result<String>
-        Type returnType = new TypeToken<Result<String>>() {}.getType();
+        Type returnType = new TypeToken<Result<String>>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(Result.class);
@@ -55,9 +58,10 @@ public void testResultStringReturnType() {
     }
 
     @Test
-    public void testListOfStringsReturnType() {
+    void testListOfStringsReturnType() {
         // Given List<String>
-        Type returnType = new TypeToken<List<String>>() {}.getType();
+        Type returnType = new TypeToken<List<String>>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(List.class);
@@ -66,9 +70,10 @@ public void testListOfStringsReturnType() {
     }
 
     @Test
-    public void testSetOfIntegersReturnType() {
+    void testSetOfIntegersReturnType() {
         // Given Set<Integer>
-        Type returnType = new TypeToken<Set<Integer>>() {}.getType();
+        Type returnType = new TypeToken<Set<Integer>>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(Set.class);
@@ -77,9 +82,10 @@ public void testSetOfIntegersReturnType() {
     }
 
     @Test
-    public void testResultSetOfIntegersReturnType() {
+    void testResultSetOfIntegersReturnType() {
         // Given Result<Set<Integer>
-        Type returnType = new TypeToken<Result<Set<Integer>>>() {}.getType();
+        Type returnType = new TypeToken<Result<Set<Integer>>>() {
+        }.getType();
 
         // Then
         assertThat(TypeUtils.getRawClass(returnType)).isEqualTo(Result.class);
@@ -98,7 +104,7 @@ interface ListNoParametrizedTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testListNoParametrizedTypeInvalidServiceDefinition() {
+    void testListNoParametrizedTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -119,7 +125,7 @@ interface SetNoParametrizedTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testSetNoParametrizedTypeInvalidServiceDefinition() {
+    void testSetNoParametrizedTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -139,7 +145,7 @@ interface ResultNoParametrizedTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testResultNoParametrizedTypeInvalidServiceDefinition() {
+    void testResultNoParametrizedTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -159,7 +165,7 @@ interface ResultListNoParametrizedTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testResultListNoParametrizedTypeInvalidServiceDefinition() {
+    void testResultListNoParametrizedTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -179,7 +185,7 @@ interface ListWildcardTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testListWildcardTypeInvalidServiceDefinition() {
+    void testListWildcardTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -199,7 +205,7 @@ interface ResultListWildcardTypeInvalidServiceDefinition {
     }
 
     @Test
-    public void testResultListWildcardTypeInvalidServiceDefinition() {
+    void testResultListWildcardTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -219,7 +225,7 @@ interface ResultListTypeParamTypeInvalidServiceDefinition<MY_TYPE extends Object
     }
 
     @Test
-    public void testResultListTypeParamTypeInvalidServiceDefinition() {
+    void testResultListTypeParamTypeInvalidServiceDefinition() {
         // Given
         ChatLanguageModel stubModel = ChatModelMock.thatAlwaysResponds("Hello there!");
 
@@ -234,4 +240,4 @@ public void testResultListTypeParamTypeInvalidServiceDefinition() {
         assertThat(illegalArgumentException.getMessage()).isEqualTo("The return type 'Result<List<MY_TYPE>>' of the method 'ask' must be parameterized with a concrete type, for example: Result<List<String>> or Result<List<MyCustomPojo>>");
     }
 
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/service/tool/ToolExecutionRequestUtilTest.java b/langchain4j/src/test/java/dev/langchain4j/service/tool/ToolExecutionRequestUtilTest.java
index fbf526308b1..861d3a48bfd 100644
--- a/langchain4j/src/test/java/dev/langchain4j/service/tool/ToolExecutionRequestUtilTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/service/tool/ToolExecutionRequestUtilTest.java
@@ -12,9 +12,8 @@
 import java.util.Map;
 import java.util.stream.Stream;
 
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.junit.jupiter.api.Assertions.assertTrue;
 import static org.junit.jupiter.api.Assertions.assertInstanceOf;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 class ToolExecutionRequestUtilTest implements WithAssertions {
 
@@ -140,4 +139,4 @@ private static Stream<Arguments> should_remove_trailing_comma() {
                 )
         );
     }
-}
\ No newline at end of file
+}
diff --git a/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreRemovalTest.java b/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreRemovalTest.java
index 4a655cd52b5..c9cfc54cdf9 100644
--- a/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreRemovalTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreRemovalTest.java
@@ -1,8 +1,8 @@
 package dev.langchain4j.store.embedding.inmemory;
 
 import dev.langchain4j.data.segment.TextSegment;
-import dev.langchain4j.model.embedding.onnx.allminilml6v2q.AllMiniLmL6V2QuantizedEmbeddingModel;
 import dev.langchain4j.model.embedding.EmbeddingModel;
+import dev.langchain4j.model.embedding.onnx.allminilml6v2q.AllMiniLmL6V2QuantizedEmbeddingModel;
 import dev.langchain4j.store.embedding.EmbeddingStore;
 import dev.langchain4j.store.embedding.EmbeddingStoreWithRemovalIT;
 
diff --git a/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreTest.java b/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreTest.java
index d2fd53693cf..635adbd854e 100644
--- a/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreTest.java
+++ b/langchain4j/src/test/java/dev/langchain4j/store/embedding/inmemory/InMemoryEmbeddingStoreTest.java
@@ -3,8 +3,8 @@
 import dev.langchain4j.data.document.Metadata;
 import dev.langchain4j.data.embedding.Embedding;
 import dev.langchain4j.data.segment.TextSegment;
-import dev.langchain4j.model.embedding.onnx.allminilml6v2q.AllMiniLmL6V2QuantizedEmbeddingModel;
 import dev.langchain4j.model.embedding.EmbeddingModel;
+import dev.langchain4j.model.embedding.onnx.allminilml6v2q.AllMiniLmL6V2QuantizedEmbeddingModel;
 import dev.langchain4j.store.embedding.EmbeddingMatch;
 import dev.langchain4j.store.embedding.EmbeddingStore;
 import dev.langchain4j.store.embedding.EmbeddingStoreWithFilteringIT;
